{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ae64ae82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                                   \n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                              \u001b[39m"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import $ivy.`org.apache.spark::spark-sql:2.4.0` \n",
    "import $ivy.`sh.almond::almond-spark:0.3.0`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "af9ac90d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading spark-stubs\n",
      "Getting spark JARs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "log4j:WARN No appenders could be found for logger (org.eclipse.jetty.util.log).\n",
      "log4j:WARN Please initialize the log4j system properly.\n",
      "log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating SparkSession\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "21/06/10 14:13:54 WARN Utils: Your hostname, MainPC-Huawei resolves to a loopback address: 127.0.1.1; using 192.168.15.53 instead (on interface eth0)\n",
      "21/06/10 14:13:54 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "21/06/10 14:13:55 INFO SparkContext: Running Spark version 2.4.0\n",
      "21/06/10 14:13:56 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "21/06/10 14:13:56 INFO SparkContext: Submitted application: cb10df9d-24bb-4b99-a268-3bdb7ef008f3\n",
      "21/06/10 14:13:56 INFO SecurityManager: Changing view acls to: yoichiro\n",
      "21/06/10 14:13:56 INFO SecurityManager: Changing modify acls to: yoichiro\n",
      "21/06/10 14:13:56 INFO SecurityManager: Changing view acls groups to: \n",
      "21/06/10 14:13:56 INFO SecurityManager: Changing modify acls groups to: \n",
      "21/06/10 14:13:56 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(yoichiro); groups with view permissions: Set(); users  with modify permissions: Set(yoichiro); groups with modify permissions: Set()\n",
      "21/06/10 14:13:56 INFO Utils: Successfully started service 'sparkDriver' on port 36201.\n",
      "21/06/10 14:13:56 INFO SparkEnv: Registering MapOutputTracker\n",
      "21/06/10 14:13:56 INFO SparkEnv: Registering BlockManagerMaster\n",
      "21/06/10 14:13:56 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information\n",
      "21/06/10 14:13:56 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up\n",
      "21/06/10 14:13:56 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-0c48bdf2-5062-410c-a696-a9254336db2c\n",
      "21/06/10 14:13:56 INFO MemoryStore: MemoryStore started with capacity 1002.0 MB\n",
      "21/06/10 14:13:56 INFO SparkEnv: Registering OutputCommitCoordinator\n",
      "21/06/10 14:13:57 INFO Utils: Successfully started service 'SparkUI' on port 4040.\n",
      "21/06/10 14:13:57 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://192.168.15.53:4040\n",
      "21/06/10 14:13:57 INFO SparkContext: Added JAR file:/home/yoichiro/.cache/coursier/v1/https/jitpack.io/com/github/jupyter/jvm-repr/0.4.0/jvm-repr-0.4.0-sources.jar at spark://192.168.15.53:36201/jars/jvm-repr-0.4.0-sources.jar with timestamp 1623302037227\n",
      "21/06/10 14:13:57 INFO SparkContext: Added JAR file:/home/yoichiro/.cache/coursier/v1/https/jitpack.io/com/github/jupyter/jvm-repr/0.4.0/jvm-repr-0.4.0.jar at spark://192.168.15.53:36201/jars/jvm-repr-0.4.0.jar with timestamp 1623302037227\n",
      "21/06/10 14:13:57 INFO SparkContext: Added JAR file:/home/yoichiro/.cache/coursier/v1/https/repo1.maven.org/maven2/com/github/javaparser/javaparser-core/3.2.5/javaparser-core-3.2.5-sources.jar at spark://192.168.15.53:36201/jars/javaparser-core-3.2.5-sources.jar with timestamp 1623302037227\n",
      "21/06/10 14:13:57 INFO SparkContext: Added JAR file:/home/yoichiro/.cache/coursier/v1/https/repo1.maven.org/maven2/com/github/javaparser/javaparser-core/3.2.5/javaparser-core-3.2.5.jar at spark://192.168.15.53:36201/jars/javaparser-core-3.2.5.jar with timestamp 1623302037228\n",
      "21/06/10 14:13:57 INFO SparkContext: Added JAR file:/home/yoichiro/.cache/coursier/v1/https/repo1.maven.org/maven2/com/lihaoyi/ammonite-compiler-interface_2.12/2.3.8-36-1cce53f3/ammonite-compiler-interface_2.12-2.3.8-36-1cce53f3-sources.jar at spark://192.168.15.53:36201/jars/ammonite-compiler-interface_2.12-2.3.8-36-1cce53f3-sources.jar with timestamp 1623302037228\n",
      "21/06/10 14:13:57 INFO SparkContext: Added JAR file:/home/yoichiro/.cache/coursier/v1/https/repo1.maven.org/maven2/com/lihaoyi/ammonite-compiler-interface_2.12/2.3.8-36-1cce53f3/ammonite-compiler-interface_2.12-2.3.8-36-1cce53f3.jar at spark://192.168.15.53:36201/jars/ammonite-compiler-interface_2.12-2.3.8-36-1cce53f3.jar with timestamp 1623302037228\n",
      "21/06/10 14:13:57 INFO SparkContext: Added JAR file:/home/yoichiro/.cache/coursier/v1/https/repo1.maven.org/maven2/com/lihaoyi/ammonite-compiler_2.12.12/2.3.8-36-1cce53f3/ammonite-compiler_2.12.12-2.3.8-36-1cce53f3-sources.jar at spark://192.168.15.53:36201/jars/ammonite-compiler_2.12.12-2.3.8-36-1cce53f3-sources.jar with timestamp 1623302037228\n",
      "21/06/10 14:13:57 INFO SparkContext: Added JAR file:/home/yoichiro/.cache/coursier/v1/https/repo1.maven.org/maven2/com/lihaoyi/ammonite-compiler_2.12.12/2.3.8-36-1cce53f3/ammonite-compiler_2.12.12-2.3.8-36-1cce53f3.jar at spark://192.168.15.53:36201/jars/ammonite-compiler_2.12.12-2.3.8-36-1cce53f3.jar with timestamp 1623302037228\n",
      "21/06/10 14:13:57 INFO SparkContext: Added JAR file:/home/yoichiro/.cache/coursier/v1/https/repo1.maven.org/maven2/com/lihaoyi/ammonite-interp-api_2.12.12/2.3.8-36-1cce53f3/ammonite-interp-api_2.12.12-2.3.8-36-1cce53f3-sources.jar at spark://192.168.15.53:36201/jars/ammonite-interp-api_2.12.12-2.3.8-36-1cce53f3-sources.jar with timestamp 1623302037228\n",
      "21/06/10 14:13:57 INFO SparkContext: Added JAR file:/home/yoichiro/.cache/coursier/v1/https/repo1.maven.org/maven2/com/lihaoyi/ammonite-interp-api_2.12.12/2.3.8-36-1cce53f3/ammonite-interp-api_2.12.12-2.3.8-36-1cce53f3.jar at spark://192.168.15.53:36201/jars/ammonite-interp-api_2.12.12-2.3.8-36-1cce53f3.jar with timestamp 1623302037228\n",
      "21/06/10 14:13:57 INFO SparkContext: Added JAR file:/home/yoichiro/.cache/coursier/v1/https/repo1.maven.org/maven2/com/lihaoyi/ammonite-ops_2.12/2.3.8-36-1cce53f3/ammonite-ops_2.12-2.3.8-36-1cce53f3-sources.jar at spark://192.168.15.53:36201/jars/ammonite-ops_2.12-2.3.8-36-1cce53f3-sources.jar with timestamp 1623302037228\n",
      "21/06/10 14:13:57 INFO SparkContext: Added JAR file:/home/yoichiro/.cache/coursier/v1/https/repo1.maven.org/maven2/com/lihaoyi/ammonite-ops_2.12/2.3.8-36-1cce53f3/ammonite-ops_2.12-2.3.8-36-1cce53f3.jar at spark://192.168.15.53:36201/jars/ammonite-ops_2.12-2.3.8-36-1cce53f3.jar with timestamp 1623302037229\n",
      "21/06/10 14:13:57 INFO SparkContext: Added JAR file:/home/yoichiro/.cache/coursier/v1/https/repo1.maven.org/maven2/com/lihaoyi/ammonite-repl-api_2.12.12/2.3.8-36-1cce53f3/ammonite-repl-api_2.12.12-2.3.8-36-1cce53f3-sources.jar at spark://192.168.15.53:36201/jars/ammonite-repl-api_2.12.12-2.3.8-36-1cce53f3-sources.jar with timestamp 1623302037229\n",
      "21/06/10 14:13:57 INFO SparkContext: Added JAR file:/home/yoichiro/.cache/coursier/v1/https/repo1.maven.org/maven2/com/lihaoyi/ammonite-repl-api_2.12.12/2.3.8-36-1cce53f3/ammonite-repl-api_2.12.12-2.3.8-36-1cce53f3.jar at spark://192.168.15.53:36201/jars/ammonite-repl-api_2.12.12-2.3.8-36-1cce53f3.jar with timestamp 1623302037229\n",
      "21/06/10 14:13:57 INFO SparkContext: Added JAR file:/home/yoichiro/.cache/coursier/v1/https/repo1.maven.org/maven2/com/lihaoyi/ammonite-util_2.12/2.3.8-36-1cce53f3/ammonite-util_2.12-2.3.8-36-1cce53f3-sources.jar at spark://192.168.15.53:36201/jars/ammonite-util_2.12-2.3.8-36-1cce53f3-sources.jar with timestamp 1623302037229\n",
      "21/06/10 14:13:57 INFO SparkContext: Added JAR file:/home/yoichiro/.cache/coursier/v1/https/repo1.maven.org/maven2/com/lihaoyi/ammonite-util_2.12/2.3.8-36-1cce53f3/ammonite-util_2.12-2.3.8-36-1cce53f3.jar at spark://192.168.15.53:36201/jars/ammonite-util_2.12-2.3.8-36-1cce53f3.jar with timestamp 1623302037230\n",
      "21/06/10 14:13:57 INFO SparkContext: Added JAR file:/home/yoichiro/.cache/coursier/v1/https/repo1.maven.org/maven2/com/lihaoyi/fansi_2.12/0.2.9/fansi_2.12-0.2.9-sources.jar at spark://192.168.15.53:36201/jars/fansi_2.12-0.2.9-sources.jar with timestamp 1623302037230\n",
      "21/06/10 14:13:57 INFO SparkContext: Added JAR file:/home/yoichiro/.cache/coursier/v1/https/repo1.maven.org/maven2/com/lihaoyi/fansi_2.12/0.2.9/fansi_2.12-0.2.9.jar at spark://192.168.15.53:36201/jars/fansi_2.12-0.2.9.jar with timestamp 1623302037230\n",
      "21/06/10 14:13:57 INFO SparkContext: Added JAR file:/home/yoichiro/.cache/coursier/v1/https/repo1.maven.org/maven2/com/lihaoyi/fastparse_2.12/2.3.0/fastparse_2.12-2.3.0-sources.jar at spark://192.168.15.53:36201/jars/fastparse_2.12-2.3.0-sources.jar with timestamp 1623302037230\n",
      "21/06/10 14:13:57 INFO SparkContext: Added JAR file:/home/yoichiro/.cache/coursier/v1/https/repo1.maven.org/maven2/com/lihaoyi/fastparse_2.12/2.3.0/fastparse_2.12-2.3.0.jar at spark://192.168.15.53:36201/jars/fastparse_2.12-2.3.0.jar with timestamp 1623302037231\n",
      "21/06/10 14:13:57 INFO SparkContext: Added JAR file:/home/yoichiro/.cache/coursier/v1/https/repo1.maven.org/maven2/com/lihaoyi/geny_2.12/0.6.5/geny_2.12-0.6.5-sources.jar at spark://192.168.15.53:36201/jars/geny_2.12-0.6.5-sources.jar with timestamp 1623302037231\n",
      "21/06/10 14:13:57 INFO SparkContext: Added JAR file:/home/yoichiro/.cache/coursier/v1/https/repo1.maven.org/maven2/com/lihaoyi/geny_2.12/0.6.5/geny_2.12-0.6.5.jar at spark://192.168.15.53:36201/jars/geny_2.12-0.6.5.jar with timestamp 1623302037231\n",
      "21/06/10 14:13:57 INFO SparkContext: Added JAR file:/home/yoichiro/.cache/coursier/v1/https/repo1.maven.org/maven2/com/lihaoyi/mainargs_2.12/0.1.4/mainargs_2.12-0.1.4-sources.jar at spark://192.168.15.53:36201/jars/mainargs_2.12-0.1.4-sources.jar with timestamp 1623302037232\n",
      "21/06/10 14:13:57 INFO SparkContext: Added JAR file:/home/yoichiro/.cache/coursier/v1/https/repo1.maven.org/maven2/com/lihaoyi/mainargs_2.12/0.1.4/mainargs_2.12-0.1.4.jar at spark://192.168.15.53:36201/jars/mainargs_2.12-0.1.4.jar with timestamp 1623302037232\n",
      "21/06/10 14:13:57 INFO SparkContext: Added JAR file:/home/yoichiro/.cache/coursier/v1/https/repo1.maven.org/maven2/com/lihaoyi/os-lib_2.12/0.7.1/os-lib_2.12-0.7.1-sources.jar at spark://192.168.15.53:36201/jars/os-lib_2.12-0.7.1-sources.jar with timestamp 1623302037232\n",
      "21/06/10 14:13:57 INFO SparkContext: Added JAR file:/home/yoichiro/.cache/coursier/v1/https/repo1.maven.org/maven2/com/lihaoyi/os-lib_2.12/0.7.1/os-lib_2.12-0.7.1.jar at spark://192.168.15.53:36201/jars/os-lib_2.12-0.7.1.jar with timestamp 1623302037233\n",
      "21/06/10 14:13:57 INFO SparkContext: Added JAR file:/home/yoichiro/.cache/coursier/v1/https/repo1.maven.org/maven2/com/lihaoyi/pprint_2.12/0.6.0/pprint_2.12-0.6.0-sources.jar at spark://192.168.15.53:36201/jars/pprint_2.12-0.6.0-sources.jar with timestamp 1623302037233\n",
      "21/06/10 14:13:57 INFO SparkContext: Added JAR file:/home/yoichiro/.cache/coursier/v1/https/repo1.maven.org/maven2/com/lihaoyi/pprint_2.12/0.6.0/pprint_2.12-0.6.0.jar at spark://192.168.15.53:36201/jars/pprint_2.12-0.6.0.jar with timestamp 1623302037234\n",
      "21/06/10 14:13:57 INFO SparkContext: Added JAR file:/home/yoichiro/.cache/coursier/v1/https/repo1.maven.org/maven2/com/lihaoyi/scalaparse_2.12/2.3.0/scalaparse_2.12-2.3.0-sources.jar at spark://192.168.15.53:36201/jars/scalaparse_2.12-2.3.0-sources.jar with timestamp 1623302037234\n",
      "21/06/10 14:13:57 INFO SparkContext: Added JAR file:/home/yoichiro/.cache/coursier/v1/https/repo1.maven.org/maven2/com/lihaoyi/scalaparse_2.12/2.3.0/scalaparse_2.12-2.3.0.jar at spark://192.168.15.53:36201/jars/scalaparse_2.12-2.3.0.jar with timestamp 1623302037235\n",
      "21/06/10 14:13:57 INFO SparkContext: Added JAR file:/home/yoichiro/.cache/coursier/v1/https/repo1.maven.org/maven2/com/lihaoyi/sourcecode_2.12/0.2.3/sourcecode_2.12-0.2.3-sources.jar at spark://192.168.15.53:36201/jars/sourcecode_2.12-0.2.3-sources.jar with timestamp 1623302037235\n",
      "21/06/10 14:13:57 INFO SparkContext: Added JAR file:/home/yoichiro/.cache/coursier/v1/https/repo1.maven.org/maven2/com/lihaoyi/sourcecode_2.12/0.2.3/sourcecode_2.12-0.2.3.jar at spark://192.168.15.53:36201/jars/sourcecode_2.12-0.2.3.jar with timestamp 1623302037235\n",
      "21/06/10 14:13:57 INFO SparkContext: Added JAR file:/home/yoichiro/.cache/coursier/v1/https/repo1.maven.org/maven2/io/get-coursier/interface/1.0.3/interface-1.0.3-sources.jar at spark://192.168.15.53:36201/jars/interface-1.0.3-sources.jar with timestamp 1623302037236\n",
      "21/06/10 14:13:57 INFO SparkContext: Added JAR file:/home/yoichiro/.cache/coursier/v1/https/repo1.maven.org/maven2/io/get-coursier/interface/1.0.3/interface-1.0.3.jar at spark://192.168.15.53:36201/jars/interface-1.0.3.jar with timestamp 1623302037236\n",
      "21/06/10 14:13:57 INFO SparkContext: Added JAR file:/home/yoichiro/.cache/coursier/v1/https/repo1.maven.org/maven2/org/javassist/javassist/3.21.0-GA/javassist-3.21.0-GA-sources.jar at spark://192.168.15.53:36201/jars/javassist-3.21.0-GA-sources.jar with timestamp 1623302037237\n",
      "21/06/10 14:13:57 INFO SparkContext: Added JAR file:/home/yoichiro/.cache/coursier/v1/https/repo1.maven.org/maven2/org/javassist/javassist/3.21.0-GA/javassist-3.21.0-GA.jar at spark://192.168.15.53:36201/jars/javassist-3.21.0-GA.jar with timestamp 1623302037237\n",
      "21/06/10 14:13:57 INFO SparkContext: Added JAR file:/home/yoichiro/.cache/coursier/v1/https/repo1.maven.org/maven2/org/scala-lang/modules/scala-collection-compat_2.12/2.4.2/scala-collection-compat_2.12-2.4.2-sources.jar at spark://192.168.15.53:36201/jars/scala-collection-compat_2.12-2.4.2-sources.jar with timestamp 1623302037237\n",
      "21/06/10 14:13:57 INFO SparkContext: Added JAR file:/home/yoichiro/.cache/coursier/v1/https/repo1.maven.org/maven2/org/scala-lang/modules/scala-collection-compat_2.12/2.4.2/scala-collection-compat_2.12-2.4.2.jar at spark://192.168.15.53:36201/jars/scala-collection-compat_2.12-2.4.2.jar with timestamp 1623302037237\n",
      "21/06/10 14:13:57 INFO SparkContext: Added JAR file:/home/yoichiro/.cache/coursier/v1/https/repo1.maven.org/maven2/org/scala-lang/modules/scala-xml_2.12/2.0.0-M3/scala-xml_2.12-2.0.0-M3-sources.jar at spark://192.168.15.53:36201/jars/scala-xml_2.12-2.0.0-M3-sources.jar with timestamp 1623302037237\n",
      "21/06/10 14:13:57 INFO SparkContext: Added JAR file:/home/yoichiro/.cache/coursier/v1/https/repo1.maven.org/maven2/org/scala-lang/modules/scala-xml_2.12/2.0.0-M3/scala-xml_2.12-2.0.0-M3.jar at spark://192.168.15.53:36201/jars/scala-xml_2.12-2.0.0-M3.jar with timestamp 1623302037238\n",
      "21/06/10 14:13:57 INFO SparkContext: Added JAR file:/home/yoichiro/.cache/coursier/v1/https/repo1.maven.org/maven2/org/scala-lang/scala-compiler/2.12.12/scala-compiler-2.12.12-sources.jar at spark://192.168.15.53:36201/jars/scala-compiler-2.12.12-sources.jar with timestamp 1623302037238\n",
      "21/06/10 14:13:57 INFO SparkContext: Added JAR file:/home/yoichiro/.cache/coursier/v1/https/repo1.maven.org/maven2/org/scala-lang/scala-library/2.12.12/scala-library-2.12.12-sources.jar at spark://192.168.15.53:36201/jars/scala-library-2.12.12-sources.jar with timestamp 1623302037238\n",
      "21/06/10 14:13:57 INFO SparkContext: Added JAR file:/home/yoichiro/.cache/coursier/v1/https/repo1.maven.org/maven2/org/scala-lang/scala-reflect/2.12.12/scala-reflect-2.12.12-sources.jar at spark://192.168.15.53:36201/jars/scala-reflect-2.12.12-sources.jar with timestamp 1623302037238\n",
      "21/06/10 14:13:57 INFO SparkContext: Added JAR file:/home/yoichiro/.cache/coursier/v1/https/repo1.maven.org/maven2/sh/almond/interpreter-api_2.12/0.11.1/interpreter-api_2.12-0.11.1-sources.jar at spark://192.168.15.53:36201/jars/interpreter-api_2.12-0.11.1-sources.jar with timestamp 1623302037238\n",
      "21/06/10 14:13:57 INFO SparkContext: Added JAR file:/home/yoichiro/.cache/coursier/v1/https/repo1.maven.org/maven2/sh/almond/interpreter-api_2.12/0.11.1/interpreter-api_2.12-0.11.1.jar at spark://192.168.15.53:36201/jars/interpreter-api_2.12-0.11.1.jar with timestamp 1623302037238\n",
      "21/06/10 14:13:57 INFO SparkContext: Added JAR file:/home/yoichiro/.cache/coursier/v1/https/repo1.maven.org/maven2/sh/almond/jupyter-api_2.12/0.11.1/jupyter-api_2.12-0.11.1-sources.jar at spark://192.168.15.53:36201/jars/jupyter-api_2.12-0.11.1-sources.jar with timestamp 1623302037239\n",
      "21/06/10 14:13:57 INFO SparkContext: Added JAR file:/home/yoichiro/.cache/coursier/v1/https/repo1.maven.org/maven2/sh/almond/jupyter-api_2.12/0.11.1/jupyter-api_2.12-0.11.1.jar at spark://192.168.15.53:36201/jars/jupyter-api_2.12-0.11.1.jar with timestamp 1623302037239\n",
      "21/06/10 14:13:57 INFO SparkContext: Added JAR file:/home/yoichiro/.cache/coursier/v1/https/repo1.maven.org/maven2/sh/almond/scala-kernel-api_2.12.12/0.11.1/scala-kernel-api_2.12.12-0.11.1-sources.jar at spark://192.168.15.53:36201/jars/scala-kernel-api_2.12.12-0.11.1-sources.jar with timestamp 1623302037239\n",
      "21/06/10 14:13:57 INFO SparkContext: Added JAR file:/home/yoichiro/.cache/coursier/v1/https/repo1.maven.org/maven2/sh/almond/scala-kernel-api_2.12.12/0.11.1/scala-kernel-api_2.12.12-0.11.1.jar at spark://192.168.15.53:36201/jars/scala-kernel-api_2.12.12-0.11.1.jar with timestamp 1623302037239\n",
      "21/06/10 14:13:57 INFO SparkContext: Added JAR file:/home/yoichiro/.cache/coursier/v1/https/repo1.maven.org/maven2/org/scala-lang/scala-library/2.12.13/scala-library-2.12.13.jar at spark://192.168.15.53:36201/jars/scala-library-2.12.13.jar with timestamp 1623302037239\n",
      "21/06/10 14:13:57 INFO SparkContext: Added JAR file:/home/yoichiro/.cache/coursier/v1/https/repo1.maven.org/maven2/sh/almond/almond-spark_2.12/0.3.0/almond-spark_2.12-0.3.0.jar at spark://192.168.15.53:36201/jars/almond-spark_2.12-0.3.0.jar with timestamp 1623302037239\n",
      "21/06/10 14:13:57 INFO SparkContext: Added JAR file:/home/yoichiro/.cache/coursier/v1/https/repo1.maven.org/maven2/sh/almond/ammonite-spark_2.12/0.3.0/ammonite-spark_2.12-0.3.0.jar at spark://192.168.15.53:36201/jars/ammonite-spark_2.12-0.3.0.jar with timestamp 1623302037240\n",
      "21/06/10 14:13:57 INFO SparkContext: Added JAR file:/home/yoichiro/.cache/coursier/v1/https/repo1.maven.org/maven2/com/github/alexarchambault/argonaut-shapeless_6.2_2.12/1.2.0-M9/argonaut-shapeless_6.2_2.12-1.2.0-M9.jar at spark://192.168.15.53:36201/jars/argonaut-shapeless_6.2_2.12-1.2.0-M9.jar with timestamp 1623302037240\n",
      "21/06/10 14:13:57 INFO SparkContext: Added JAR file:/home/yoichiro/.cache/coursier/v1/https/repo1.maven.org/maven2/org/eclipse/jetty/jetty-server/8.2.0.v20160908/jetty-server-8.2.0.v20160908.jar at spark://192.168.15.53:36201/jars/jetty-server-8.2.0.v20160908.jar with timestamp 1623302037240\n",
      "21/06/10 14:13:57 INFO SparkContext: Added JAR file:/home/yoichiro/.cache/coursier/v1/https/repo1.maven.org/maven2/io/argonaut/argonaut_2.12/6.2.2/argonaut_2.12-6.2.2.jar at spark://192.168.15.53:36201/jars/argonaut_2.12-6.2.2.jar with timestamp 1623302037241\n",
      "21/06/10 14:13:57 INFO SparkContext: Added JAR file:/home/yoichiro/.cache/coursier/v1/https/repo1.maven.org/maven2/com/chuusai/shapeless_2.12/2.3.3/shapeless_2.12-2.3.3.jar at spark://192.168.15.53:36201/jars/shapeless_2.12-2.3.3.jar with timestamp 1623302037241\n",
      "21/06/10 14:13:57 INFO SparkContext: Added JAR file:/home/yoichiro/.cache/coursier/v1/https/repo1.maven.org/maven2/org/eclipse/jetty/orbit/javax.servlet/3.0.0.v201112011016/javax.servlet-3.0.0.v201112011016.jar at spark://192.168.15.53:36201/jars/javax.servlet-3.0.0.v201112011016.jar with timestamp 1623302037241\n",
      "21/06/10 14:13:57 INFO SparkContext: Added JAR file:/home/yoichiro/.cache/coursier/v1/https/repo1.maven.org/maven2/org/eclipse/jetty/jetty-continuation/8.2.0.v20160908/jetty-continuation-8.2.0.v20160908.jar at spark://192.168.15.53:36201/jars/jetty-continuation-8.2.0.v20160908.jar with timestamp 1623302037241\n",
      "21/06/10 14:13:57 INFO SparkContext: Added JAR file:/home/yoichiro/.cache/coursier/v1/https/repo1.maven.org/maven2/org/eclipse/jetty/jetty-http/8.2.0.v20160908/jetty-http-8.2.0.v20160908.jar at spark://192.168.15.53:36201/jars/jetty-http-8.2.0.v20160908.jar with timestamp 1623302037241\n",
      "21/06/10 14:13:57 INFO SparkContext: Added JAR file:/home/yoichiro/.cache/coursier/v1/https/repo1.maven.org/maven2/org/typelevel/macro-compat_2.12/1.1.1/macro-compat_2.12-1.1.1.jar at spark://192.168.15.53:36201/jars/macro-compat_2.12-1.1.1.jar with timestamp 1623302037241\n",
      "21/06/10 14:13:57 INFO SparkContext: Added JAR file:/home/yoichiro/.cache/coursier/v1/https/repo1.maven.org/maven2/org/eclipse/jetty/jetty-io/8.2.0.v20160908/jetty-io-8.2.0.v20160908.jar at spark://192.168.15.53:36201/jars/jetty-io-8.2.0.v20160908.jar with timestamp 1623302037242\n",
      "21/06/10 14:13:57 INFO SparkContext: Added JAR file:/home/yoichiro/.cache/coursier/v1/https/repo1.maven.org/maven2/org/eclipse/jetty/jetty-util/8.2.0.v20160908/jetty-util-8.2.0.v20160908.jar at spark://192.168.15.53:36201/jars/jetty-util-8.2.0.v20160908.jar with timestamp 1623302037242\n",
      "21/06/10 14:13:57 INFO Executor: Starting executor ID driver on host localhost\n",
      "21/06/10 14:13:57 INFO Executor: Using REPL class URI: http://127.0.1.1:43225\n",
      "21/06/10 14:13:57 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 41049.\n",
      "21/06/10 14:13:57 INFO NettyBlockTransferService: Server created on 192.168.15.53:41049\n",
      "21/06/10 14:13:57 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy\n",
      "21/06/10 14:13:57 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 192.168.15.53, 41049, None)\n",
      "21/06/10 14:13:57 INFO BlockManagerMasterEndpoint: Registering block manager 192.168.15.53:41049 with 1002.0 MB RAM, BlockManagerId(driver, 192.168.15.53, 41049, None)\n",
      "21/06/10 14:13:57 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 192.168.15.53, 41049, None)\n",
      "21/06/10 14:13:57 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 192.168.15.53, 41049, None)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<a target=\"_blank\" href=\"http://192.168.15.53:4040\">Spark UI</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.sql._\n",
       "\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.sql.functions.col\n",
       "\n",
       "\u001b[39m\n",
       "\u001b[36mspark\u001b[39m: \u001b[32mSparkSession\u001b[39m = org.apache.spark.sql.SparkSession@6251eb24"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql._\n",
    "\n",
    "import org.apache.spark.sql.functions.col\n",
    "\n",
    "val spark = NotebookSparkSession.builder().master(\"local[*]\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "85babc1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/06/10 14:14:43 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/home/yoichiro/develop/analysis/spark-warehouse/').\n",
      "21/06/10 14:14:43 INFO SharedState: Warehouse path is 'file:/home/yoichiro/develop/analysis/spark-warehouse/'.\n",
      "21/06/10 14:14:43 INFO StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint\n",
      "21/06/10 14:14:45 INFO FileSourceStrategy: Pruning directories with: \n",
      "21/06/10 14:14:45 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)\n",
      "21/06/10 14:14:45 INFO FileSourceStrategy: Output Data Schema: struct<value: string>\n",
      "21/06/10 14:14:45 INFO FileSourceScanExec: Pushed Filters: \n",
      "21/06/10 14:14:45 INFO CodeGenerator: Code generated in 239.6373 ms\n",
      "21/06/10 14:14:45 INFO CodeGenerator: Code generated in 28.3391 ms\n",
      "21/06/10 14:14:45 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 121.9 KB, free 1001.9 MB)\n",
      "21/06/10 14:14:45 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.1 KB, free 1001.9 MB)\n",
      "21/06/10 14:14:45 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 192.168.15.53:41049 (size: 23.1 KB, free: 1002.0 MB)\n",
      "21/06/10 14:14:45 INFO SparkContext: Created broadcast 0 from load at cmd51.sc:1\n",
      "21/06/10 14:14:45 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "21/06/10 14:14:46 INFO SparkContext: Starting job: load at cmd51.sc:1\n",
      "21/06/10 14:14:46 INFO DAGScheduler: Got job 0 (load at cmd51.sc:1) with 1 output partitions\n",
      "21/06/10 14:14:46 INFO DAGScheduler: Final stage: ResultStage 0 (load at cmd51.sc:1)\n",
      "21/06/10 14:14:46 INFO DAGScheduler: Parents of final stage: List()\n",
      "21/06/10 14:14:46 INFO DAGScheduler: Missing parents: List()\n",
      "21/06/10 14:14:46 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at load at cmd51.sc:1), which has no missing parents\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<script>\n",
       "var comm = Jupyter.notebook.kernel.comm_manager.new_comm('cancel-stage-01dcfddc-3ebb-4c9e-9d44-838a067f7449', {});\n",
       "\n",
       "function cancelStage(stageId) {\n",
       "  console.log('Cancelling stage ' + stageId);\n",
       "  comm.send({ 'stageId': stageId });\n",
       "}\n",
       "</script>\n",
       "          "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "  <span style=\"float: left;\">load at cmd51.sc:1</span>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"progress\">\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: blue; width: 100%; word-wrap: normal; white-space: nowrap; text-align: center; color: white\" aria-valuenow=\"100\" aria-valuemin=\"0\" aria-valuemax=\"100\">\n",
       "    1 / 1\n",
       "  </div>\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: red; width: 0%\" aria-valuenow=\"0\" aria-valuemin=\"0\" aria-valuemax=\"100\"></div>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/06/10 14:14:46 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 10.2 KB, free 1001.8 MB)\n",
      "21/06/10 14:14:46 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.0 KB, free 1001.8 MB)\n",
      "21/06/10 14:14:46 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 192.168.15.53:41049 (size: 5.0 KB, free: 1002.0 MB)\n",
      "21/06/10 14:14:46 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1161\n",
      "21/06/10 14:14:46 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at load at cmd51.sc:1) (first 15 tasks are for partitions Vector(0))\n",
      "21/06/10 14:14:46 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks\n",
      "21/06/10 14:14:46 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 7805 bytes)\n",
      "21/06/10 14:14:46 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)\n",
      "21/06/10 14:14:46 INFO Executor: Fetching spark://192.168.15.53:36201/jars/scala-xml_2.12-2.0.0-M3.jar with timestamp 1623302037238\n",
      "21/06/10 14:14:46 INFO TransportClientFactory: Successfully created connection to /192.168.15.53:36201 after 44 ms (0 ms spent in bootstraps)\n",
      "21/06/10 14:14:46 INFO Utils: Fetching spark://192.168.15.53:36201/jars/scala-xml_2.12-2.0.0-M3.jar to /tmp/spark-1dcd54f4-e6ff-42c8-9236-849f5b204a68/userFiles-2adad0f1-897b-45d9-967a-b7efef557be4/fetchFileTemp16682406160444603801.tmp\n",
      "21/06/10 14:14:46 INFO Executor: Adding file:/tmp/spark-1dcd54f4-e6ff-42c8-9236-849f5b204a68/userFiles-2adad0f1-897b-45d9-967a-b7efef557be4/scala-xml_2.12-2.0.0-M3.jar to class loader\n",
      "21/06/10 14:14:46 INFO Executor: Fetching spark://192.168.15.53:36201/jars/almond-spark_2.12-0.3.0.jar with timestamp 1623302037239\n",
      "21/06/10 14:14:46 INFO Utils: Fetching spark://192.168.15.53:36201/jars/almond-spark_2.12-0.3.0.jar to /tmp/spark-1dcd54f4-e6ff-42c8-9236-849f5b204a68/userFiles-2adad0f1-897b-45d9-967a-b7efef557be4/fetchFileTemp11391654897389233642.tmp\n",
      "21/06/10 14:14:46 INFO Executor: Adding file:/tmp/spark-1dcd54f4-e6ff-42c8-9236-849f5b204a68/userFiles-2adad0f1-897b-45d9-967a-b7efef557be4/almond-spark_2.12-0.3.0.jar to class loader\n",
      "21/06/10 14:14:46 INFO Executor: Fetching spark://192.168.15.53:36201/jars/interpreter-api_2.12-0.11.1.jar with timestamp 1623302037238\n",
      "21/06/10 14:14:46 INFO Utils: Fetching spark://192.168.15.53:36201/jars/interpreter-api_2.12-0.11.1.jar to /tmp/spark-1dcd54f4-e6ff-42c8-9236-849f5b204a68/userFiles-2adad0f1-897b-45d9-967a-b7efef557be4/fetchFileTemp11286294532363055113.tmp\n",
      "21/06/10 14:14:46 INFO Executor: Adding file:/tmp/spark-1dcd54f4-e6ff-42c8-9236-849f5b204a68/userFiles-2adad0f1-897b-45d9-967a-b7efef557be4/interpreter-api_2.12-0.11.1.jar to class loader\n",
      "21/06/10 14:14:46 INFO Executor: Fetching spark://192.168.15.53:36201/jars/jupyter-api_2.12-0.11.1.jar with timestamp 1623302037239\n",
      "21/06/10 14:14:46 INFO Utils: Fetching spark://192.168.15.53:36201/jars/jupyter-api_2.12-0.11.1.jar to /tmp/spark-1dcd54f4-e6ff-42c8-9236-849f5b204a68/userFiles-2adad0f1-897b-45d9-967a-b7efef557be4/fetchFileTemp2209429997013966605.tmp\n",
      "21/06/10 14:14:46 INFO Executor: Adding file:/tmp/spark-1dcd54f4-e6ff-42c8-9236-849f5b204a68/userFiles-2adad0f1-897b-45d9-967a-b7efef557be4/jupyter-api_2.12-0.11.1.jar to class loader\n",
      "21/06/10 14:14:46 INFO Executor: Fetching spark://192.168.15.53:36201/jars/geny_2.12-0.6.5-sources.jar with timestamp 1623302037231\n",
      "21/06/10 14:14:46 INFO Utils: Fetching spark://192.168.15.53:36201/jars/geny_2.12-0.6.5-sources.jar to /tmp/spark-1dcd54f4-e6ff-42c8-9236-849f5b204a68/userFiles-2adad0f1-897b-45d9-967a-b7efef557be4/fetchFileTemp14129220374275345583.tmp\n",
      "21/06/10 14:14:46 INFO Executor: Adding file:/tmp/spark-1dcd54f4-e6ff-42c8-9236-849f5b204a68/userFiles-2adad0f1-897b-45d9-967a-b7efef557be4/geny_2.12-0.6.5-sources.jar to class loader\n",
      "21/06/10 14:14:46 INFO Executor: Fetching spark://192.168.15.53:36201/jars/ammonite-util_2.12-2.3.8-36-1cce53f3.jar with timestamp 1623302037230\n",
      "21/06/10 14:14:46 INFO Utils: Fetching spark://192.168.15.53:36201/jars/ammonite-util_2.12-2.3.8-36-1cce53f3.jar to /tmp/spark-1dcd54f4-e6ff-42c8-9236-849f5b204a68/userFiles-2adad0f1-897b-45d9-967a-b7efef557be4/fetchFileTemp2349750771248221440.tmp\n",
      "21/06/10 14:14:46 INFO Executor: Adding file:/tmp/spark-1dcd54f4-e6ff-42c8-9236-849f5b204a68/userFiles-2adad0f1-897b-45d9-967a-b7efef557be4/ammonite-util_2.12-2.3.8-36-1cce53f3.jar to class loader\n",
      "21/06/10 14:14:46 INFO Executor: Fetching spark://192.168.15.53:36201/jars/scala-xml_2.12-2.0.0-M3-sources.jar with timestamp 1623302037237\n",
      "21/06/10 14:14:46 INFO Utils: Fetching spark://192.168.15.53:36201/jars/scala-xml_2.12-2.0.0-M3-sources.jar to /tmp/spark-1dcd54f4-e6ff-42c8-9236-849f5b204a68/userFiles-2adad0f1-897b-45d9-967a-b7efef557be4/fetchFileTemp14020216245534135776.tmp\n",
      "21/06/10 14:14:46 INFO Executor: Adding file:/tmp/spark-1dcd54f4-e6ff-42c8-9236-849f5b204a68/userFiles-2adad0f1-897b-45d9-967a-b7efef557be4/scala-xml_2.12-2.0.0-M3-sources.jar to class loader\n",
      "21/06/10 14:14:46 INFO Executor: Fetching spark://192.168.15.53:36201/jars/scala-reflect-2.12.12-sources.jar with timestamp 1623302037238\n",
      "21/06/10 14:14:46 INFO Utils: Fetching spark://192.168.15.53:36201/jars/scala-reflect-2.12.12-sources.jar to /tmp/spark-1dcd54f4-e6ff-42c8-9236-849f5b204a68/userFiles-2adad0f1-897b-45d9-967a-b7efef557be4/fetchFileTemp13553304556884181367.tmp\n",
      "21/06/10 14:14:46 INFO Executor: Adding file:/tmp/spark-1dcd54f4-e6ff-42c8-9236-849f5b204a68/userFiles-2adad0f1-897b-45d9-967a-b7efef557be4/scala-reflect-2.12.12-sources.jar to class loader\n",
      "21/06/10 14:14:46 INFO Executor: Fetching spark://192.168.15.53:36201/jars/mainargs_2.12-0.1.4.jar with timestamp 1623302037232\n",
      "21/06/10 14:14:46 INFO Utils: Fetching spark://192.168.15.53:36201/jars/mainargs_2.12-0.1.4.jar to /tmp/spark-1dcd54f4-e6ff-42c8-9236-849f5b204a68/userFiles-2adad0f1-897b-45d9-967a-b7efef557be4/fetchFileTemp11153298704454704979.tmp\n",
      "21/06/10 14:14:46 INFO Executor: Adding file:/tmp/spark-1dcd54f4-e6ff-42c8-9236-849f5b204a68/userFiles-2adad0f1-897b-45d9-967a-b7efef557be4/mainargs_2.12-0.1.4.jar to class loader\n",
      "21/06/10 14:14:46 INFO Executor: Fetching spark://192.168.15.53:36201/jars/ammonite-compiler-interface_2.12-2.3.8-36-1cce53f3.jar with timestamp 1623302037228\n",
      "21/06/10 14:14:46 INFO Utils: Fetching spark://192.168.15.53:36201/jars/ammonite-compiler-interface_2.12-2.3.8-36-1cce53f3.jar to /tmp/spark-1dcd54f4-e6ff-42c8-9236-849f5b204a68/userFiles-2adad0f1-897b-45d9-967a-b7efef557be4/fetchFileTemp16484015672462803171.tmp\n",
      "21/06/10 14:14:46 INFO Executor: Adding file:/tmp/spark-1dcd54f4-e6ff-42c8-9236-849f5b204a68/userFiles-2adad0f1-897b-45d9-967a-b7efef557be4/ammonite-compiler-interface_2.12-2.3.8-36-1cce53f3.jar to class loader\n",
      "21/06/10 14:14:46 INFO Executor: Fetching spark://192.168.15.53:36201/jars/ammonite-compiler_2.12.12-2.3.8-36-1cce53f3.jar with timestamp 1623302037228\n",
      "21/06/10 14:14:46 INFO Utils: Fetching spark://192.168.15.53:36201/jars/ammonite-compiler_2.12.12-2.3.8-36-1cce53f3.jar to /tmp/spark-1dcd54f4-e6ff-42c8-9236-849f5b204a68/userFiles-2adad0f1-897b-45d9-967a-b7efef557be4/fetchFileTemp13894703681388880336.tmp\n",
      "21/06/10 14:14:46 INFO Executor: Adding file:/tmp/spark-1dcd54f4-e6ff-42c8-9236-849f5b204a68/userFiles-2adad0f1-897b-45d9-967a-b7efef557be4/ammonite-compiler_2.12.12-2.3.8-36-1cce53f3.jar to class loader\n",
      "21/06/10 14:14:46 INFO Executor: Fetching spark://192.168.15.53:36201/jars/ammonite-compiler_2.12.12-2.3.8-36-1cce53f3-sources.jar with timestamp 1623302037228\n",
      "21/06/10 14:14:46 INFO Utils: Fetching spark://192.168.15.53:36201/jars/ammonite-compiler_2.12.12-2.3.8-36-1cce53f3-sources.jar to /tmp/spark-1dcd54f4-e6ff-42c8-9236-849f5b204a68/userFiles-2adad0f1-897b-45d9-967a-b7efef557be4/fetchFileTemp12658350525828943222.tmp\n",
      "21/06/10 14:14:46 INFO Executor: Adding file:/tmp/spark-1dcd54f4-e6ff-42c8-9236-849f5b204a68/userFiles-2adad0f1-897b-45d9-967a-b7efef557be4/ammonite-compiler_2.12.12-2.3.8-36-1cce53f3-sources.jar to class loader\n",
      "21/06/10 14:14:46 INFO Executor: Fetching spark://192.168.15.53:36201/jars/ammonite-compiler-interface_2.12-2.3.8-36-1cce53f3-sources.jar with timestamp 1623302037228\n",
      "21/06/10 14:14:46 INFO Utils: Fetching spark://192.168.15.53:36201/jars/ammonite-compiler-interface_2.12-2.3.8-36-1cce53f3-sources.jar to /tmp/spark-1dcd54f4-e6ff-42c8-9236-849f5b204a68/userFiles-2adad0f1-897b-45d9-967a-b7efef557be4/fetchFileTemp2797376963043873014.tmp\n",
      "21/06/10 14:14:46 INFO Executor: Adding file:/tmp/spark-1dcd54f4-e6ff-42c8-9236-849f5b204a68/userFiles-2adad0f1-897b-45d9-967a-b7efef557be4/ammonite-compiler-interface_2.12-2.3.8-36-1cce53f3-sources.jar to class loader\n",
      "21/06/10 14:14:46 INFO Executor: Fetching spark://192.168.15.53:36201/jars/os-lib_2.12-0.7.1-sources.jar with timestamp 1623302037232\n",
      "21/06/10 14:14:46 INFO Utils: Fetching spark://192.168.15.53:36201/jars/os-lib_2.12-0.7.1-sources.jar to /tmp/spark-1dcd54f4-e6ff-42c8-9236-849f5b204a68/userFiles-2adad0f1-897b-45d9-967a-b7efef557be4/fetchFileTemp13302303346376642224.tmp\n",
      "21/06/10 14:14:46 INFO Executor: Adding file:/tmp/spark-1dcd54f4-e6ff-42c8-9236-849f5b204a68/userFiles-2adad0f1-897b-45d9-967a-b7efef557be4/os-lib_2.12-0.7.1-sources.jar to class loader\n",
      "21/06/10 14:14:46 INFO Executor: Fetching spark://192.168.15.53:36201/jars/os-lib_2.12-0.7.1.jar with timestamp 1623302037233\n",
      "21/06/10 14:14:46 INFO Utils: Fetching spark://192.168.15.53:36201/jars/os-lib_2.12-0.7.1.jar to /tmp/spark-1dcd54f4-e6ff-42c8-9236-849f5b204a68/userFiles-2adad0f1-897b-45d9-967a-b7efef557be4/fetchFileTemp9384635447416364217.tmp\n",
      "21/06/10 14:14:46 INFO Executor: Adding file:/tmp/spark-1dcd54f4-e6ff-42c8-9236-849f5b204a68/userFiles-2adad0f1-897b-45d9-967a-b7efef557be4/os-lib_2.12-0.7.1.jar to class loader\n",
      "21/06/10 14:14:46 INFO Executor: Fetching spark://192.168.15.53:36201/jars/scala-collection-compat_2.12-2.4.2.jar with timestamp 1623302037237\n",
      "21/06/10 14:14:46 INFO Utils: Fetching spark://192.168.15.53:36201/jars/scala-collection-compat_2.12-2.4.2.jar to /tmp/spark-1dcd54f4-e6ff-42c8-9236-849f5b204a68/userFiles-2adad0f1-897b-45d9-967a-b7efef557be4/fetchFileTemp5853700681142858137.tmp\n",
      "21/06/10 14:14:46 INFO Executor: Adding file:/tmp/spark-1dcd54f4-e6ff-42c8-9236-849f5b204a68/userFiles-2adad0f1-897b-45d9-967a-b7efef557be4/scala-collection-compat_2.12-2.4.2.jar to class loader\n",
      "21/06/10 14:14:46 INFO Executor: Fetching spark://192.168.15.53:36201/jars/jetty-server-8.2.0.v20160908.jar with timestamp 1623302037240\n",
      "21/06/10 14:14:46 INFO Utils: Fetching spark://192.168.15.53:36201/jars/jetty-server-8.2.0.v20160908.jar to /tmp/spark-1dcd54f4-e6ff-42c8-9236-849f5b204a68/userFiles-2adad0f1-897b-45d9-967a-b7efef557be4/fetchFileTemp8252343188803105525.tmp\n",
      "21/06/10 14:14:46 INFO Executor: Adding file:/tmp/spark-1dcd54f4-e6ff-42c8-9236-849f5b204a68/userFiles-2adad0f1-897b-45d9-967a-b7efef557be4/jetty-server-8.2.0.v20160908.jar to class loader\n",
      "21/06/10 14:14:46 INFO Executor: Fetching spark://192.168.15.53:36201/jars/javaparser-core-3.2.5.jar with timestamp 1623302037228\n",
      "21/06/10 14:14:46 INFO Utils: Fetching spark://192.168.15.53:36201/jars/javaparser-core-3.2.5.jar to /tmp/spark-1dcd54f4-e6ff-42c8-9236-849f5b204a68/userFiles-2adad0f1-897b-45d9-967a-b7efef557be4/fetchFileTemp16672346813392464359.tmp\n",
      "21/06/10 14:14:46 INFO Executor: Adding file:/tmp/spark-1dcd54f4-e6ff-42c8-9236-849f5b204a68/userFiles-2adad0f1-897b-45d9-967a-b7efef557be4/javaparser-core-3.2.5.jar to class loader\n",
      "21/06/10 14:14:46 INFO Executor: Fetching spark://192.168.15.53:36201/jars/javax.servlet-3.0.0.v201112011016.jar with timestamp 1623302037241\n",
      "21/06/10 14:14:46 INFO Utils: Fetching spark://192.168.15.53:36201/jars/javax.servlet-3.0.0.v201112011016.jar to /tmp/spark-1dcd54f4-e6ff-42c8-9236-849f5b204a68/userFiles-2adad0f1-897b-45d9-967a-b7efef557be4/fetchFileTemp11103140889673807939.tmp\n",
      "21/06/10 14:14:46 INFO Executor: Adding file:/tmp/spark-1dcd54f4-e6ff-42c8-9236-849f5b204a68/userFiles-2adad0f1-897b-45d9-967a-b7efef557be4/javax.servlet-3.0.0.v201112011016.jar to class loader\n",
      "21/06/10 14:14:46 INFO Executor: Fetching spark://192.168.15.53:36201/jars/ammonite-util_2.12-2.3.8-36-1cce53f3-sources.jar with timestamp 1623302037229\n",
      "21/06/10 14:14:46 INFO Utils: Fetching spark://192.168.15.53:36201/jars/ammonite-util_2.12-2.3.8-36-1cce53f3-sources.jar to /tmp/spark-1dcd54f4-e6ff-42c8-9236-849f5b204a68/userFiles-2adad0f1-897b-45d9-967a-b7efef557be4/fetchFileTemp17135123822740250595.tmp\n",
      "21/06/10 14:14:46 INFO Executor: Adding file:/tmp/spark-1dcd54f4-e6ff-42c8-9236-849f5b204a68/userFiles-2adad0f1-897b-45d9-967a-b7efef557be4/ammonite-util_2.12-2.3.8-36-1cce53f3-sources.jar to class loader\n",
      "21/06/10 14:14:46 INFO Executor: Fetching spark://192.168.15.53:36201/jars/jupyter-api_2.12-0.11.1-sources.jar with timestamp 1623302037239\n",
      "21/06/10 14:14:46 INFO Utils: Fetching spark://192.168.15.53:36201/jars/jupyter-api_2.12-0.11.1-sources.jar to /tmp/spark-1dcd54f4-e6ff-42c8-9236-849f5b204a68/userFiles-2adad0f1-897b-45d9-967a-b7efef557be4/fetchFileTemp13863499435963596785.tmp\n",
      "21/06/10 14:14:46 INFO Executor: Adding file:/tmp/spark-1dcd54f4-e6ff-42c8-9236-849f5b204a68/userFiles-2adad0f1-897b-45d9-967a-b7efef557be4/jupyter-api_2.12-0.11.1-sources.jar to class loader\n",
      "21/06/10 14:14:46 INFO Executor: Fetching spark://192.168.15.53:36201/jars/ammonite-ops_2.12-2.3.8-36-1cce53f3.jar with timestamp 1623302037229\n",
      "21/06/10 14:14:46 INFO Utils: Fetching spark://192.168.15.53:36201/jars/ammonite-ops_2.12-2.3.8-36-1cce53f3.jar to /tmp/spark-1dcd54f4-e6ff-42c8-9236-849f5b204a68/userFiles-2adad0f1-897b-45d9-967a-b7efef557be4/fetchFileTemp7498651724534906420.tmp\n",
      "21/06/10 14:14:46 INFO Executor: Adding file:/tmp/spark-1dcd54f4-e6ff-42c8-9236-849f5b204a68/userFiles-2adad0f1-897b-45d9-967a-b7efef557be4/ammonite-ops_2.12-2.3.8-36-1cce53f3.jar to class loader\n",
      "21/06/10 14:14:46 INFO Executor: Fetching spark://192.168.15.53:36201/jars/ammonite-repl-api_2.12.12-2.3.8-36-1cce53f3-sources.jar with timestamp 1623302037229\n",
      "21/06/10 14:14:46 INFO Utils: Fetching spark://192.168.15.53:36201/jars/ammonite-repl-api_2.12.12-2.3.8-36-1cce53f3-sources.jar to /tmp/spark-1dcd54f4-e6ff-42c8-9236-849f5b204a68/userFiles-2adad0f1-897b-45d9-967a-b7efef557be4/fetchFileTemp11512843605090169314.tmp\n",
      "21/06/10 14:14:46 INFO Executor: Adding file:/tmp/spark-1dcd54f4-e6ff-42c8-9236-849f5b204a68/userFiles-2adad0f1-897b-45d9-967a-b7efef557be4/ammonite-repl-api_2.12.12-2.3.8-36-1cce53f3-sources.jar to class loader\n",
      "21/06/10 14:14:46 INFO Executor: Fetching spark://192.168.15.53:36201/jars/interpreter-api_2.12-0.11.1-sources.jar with timestamp 1623302037238\n",
      "21/06/10 14:14:46 INFO Utils: Fetching spark://192.168.15.53:36201/jars/interpreter-api_2.12-0.11.1-sources.jar to /tmp/spark-1dcd54f4-e6ff-42c8-9236-849f5b204a68/userFiles-2adad0f1-897b-45d9-967a-b7efef557be4/fetchFileTemp13814099051219275463.tmp\n",
      "21/06/10 14:14:46 INFO Executor: Adding file:/tmp/spark-1dcd54f4-e6ff-42c8-9236-849f5b204a68/userFiles-2adad0f1-897b-45d9-967a-b7efef557be4/interpreter-api_2.12-0.11.1-sources.jar to class loader\n",
      "21/06/10 14:14:46 INFO Executor: Fetching spark://192.168.15.53:36201/jars/javassist-3.21.0-GA.jar with timestamp 1623302037237\n",
      "21/06/10 14:14:46 INFO Utils: Fetching spark://192.168.15.53:36201/jars/javassist-3.21.0-GA.jar to /tmp/spark-1dcd54f4-e6ff-42c8-9236-849f5b204a68/userFiles-2adad0f1-897b-45d9-967a-b7efef557be4/fetchFileTemp14330542718217095938.tmp\n",
      "21/06/10 14:14:46 INFO Executor: Adding file:/tmp/spark-1dcd54f4-e6ff-42c8-9236-849f5b204a68/userFiles-2adad0f1-897b-45d9-967a-b7efef557be4/javassist-3.21.0-GA.jar to class loader\n",
      "21/06/10 14:14:46 INFO Executor: Fetching spark://192.168.15.53:36201/jars/sourcecode_2.12-0.2.3-sources.jar with timestamp 1623302037235\n",
      "21/06/10 14:14:46 INFO Utils: Fetching spark://192.168.15.53:36201/jars/sourcecode_2.12-0.2.3-sources.jar to /tmp/spark-1dcd54f4-e6ff-42c8-9236-849f5b204a68/userFiles-2adad0f1-897b-45d9-967a-b7efef557be4/fetchFileTemp14976298514842571068.tmp\n",
      "21/06/10 14:14:46 INFO Executor: Adding file:/tmp/spark-1dcd54f4-e6ff-42c8-9236-849f5b204a68/userFiles-2adad0f1-897b-45d9-967a-b7efef557be4/sourcecode_2.12-0.2.3-sources.jar to class loader\n",
      "21/06/10 14:14:46 INFO Executor: Fetching spark://192.168.15.53:36201/jars/pprint_2.12-0.6.0-sources.jar with timestamp 1623302037233\n",
      "21/06/10 14:14:46 INFO Utils: Fetching spark://192.168.15.53:36201/jars/pprint_2.12-0.6.0-sources.jar to /tmp/spark-1dcd54f4-e6ff-42c8-9236-849f5b204a68/userFiles-2adad0f1-897b-45d9-967a-b7efef557be4/fetchFileTemp6936006627856523593.tmp\n",
      "21/06/10 14:14:46 INFO Executor: Adding file:/tmp/spark-1dcd54f4-e6ff-42c8-9236-849f5b204a68/userFiles-2adad0f1-897b-45d9-967a-b7efef557be4/pprint_2.12-0.6.0-sources.jar to class loader\n",
      "21/06/10 14:14:46 INFO Executor: Fetching spark://192.168.15.53:36201/jars/shapeless_2.12-2.3.3.jar with timestamp 1623302037241\n",
      "21/06/10 14:14:46 INFO Utils: Fetching spark://192.168.15.53:36201/jars/shapeless_2.12-2.3.3.jar to /tmp/spark-1dcd54f4-e6ff-42c8-9236-849f5b204a68/userFiles-2adad0f1-897b-45d9-967a-b7efef557be4/fetchFileTemp2482533489894580325.tmp\n",
      "21/06/10 14:14:46 INFO Executor: Adding file:/tmp/spark-1dcd54f4-e6ff-42c8-9236-849f5b204a68/userFiles-2adad0f1-897b-45d9-967a-b7efef557be4/shapeless_2.12-2.3.3.jar to class loader\n",
      "21/06/10 14:14:46 INFO Executor: Fetching spark://192.168.15.53:36201/jars/argonaut-shapeless_6.2_2.12-1.2.0-M9.jar with timestamp 1623302037240\n",
      "21/06/10 14:14:46 INFO Utils: Fetching spark://192.168.15.53:36201/jars/argonaut-shapeless_6.2_2.12-1.2.0-M9.jar to /tmp/spark-1dcd54f4-e6ff-42c8-9236-849f5b204a68/userFiles-2adad0f1-897b-45d9-967a-b7efef557be4/fetchFileTemp5071451812897300271.tmp\n",
      "21/06/10 14:14:47 INFO Executor: Adding file:/tmp/spark-1dcd54f4-e6ff-42c8-9236-849f5b204a68/userFiles-2adad0f1-897b-45d9-967a-b7efef557be4/argonaut-shapeless_6.2_2.12-1.2.0-M9.jar to class loader\n",
      "21/06/10 14:14:47 INFO Executor: Fetching spark://192.168.15.53:36201/jars/scala-collection-compat_2.12-2.4.2-sources.jar with timestamp 1623302037237\n",
      "21/06/10 14:14:47 INFO Utils: Fetching spark://192.168.15.53:36201/jars/scala-collection-compat_2.12-2.4.2-sources.jar to /tmp/spark-1dcd54f4-e6ff-42c8-9236-849f5b204a68/userFiles-2adad0f1-897b-45d9-967a-b7efef557be4/fetchFileTemp11723833969147176332.tmp\n",
      "21/06/10 14:14:47 INFO Executor: Adding file:/tmp/spark-1dcd54f4-e6ff-42c8-9236-849f5b204a68/userFiles-2adad0f1-897b-45d9-967a-b7efef557be4/scala-collection-compat_2.12-2.4.2-sources.jar to class loader\n",
      "21/06/10 14:14:47 INFO Executor: Fetching spark://192.168.15.53:36201/jars/fastparse_2.12-2.3.0.jar with timestamp 1623302037231\n",
      "21/06/10 14:14:47 INFO Utils: Fetching spark://192.168.15.53:36201/jars/fastparse_2.12-2.3.0.jar to /tmp/spark-1dcd54f4-e6ff-42c8-9236-849f5b204a68/userFiles-2adad0f1-897b-45d9-967a-b7efef557be4/fetchFileTemp11040831940272178536.tmp\n",
      "21/06/10 14:14:47 INFO Executor: Adding file:/tmp/spark-1dcd54f4-e6ff-42c8-9236-849f5b204a68/userFiles-2adad0f1-897b-45d9-967a-b7efef557be4/fastparse_2.12-2.3.0.jar to class loader\n",
      "21/06/10 14:14:47 INFO Executor: Fetching spark://192.168.15.53:36201/jars/fansi_2.12-0.2.9.jar with timestamp 1623302037230\n",
      "21/06/10 14:14:47 INFO Utils: Fetching spark://192.168.15.53:36201/jars/fansi_2.12-0.2.9.jar to /tmp/spark-1dcd54f4-e6ff-42c8-9236-849f5b204a68/userFiles-2adad0f1-897b-45d9-967a-b7efef557be4/fetchFileTemp3861541771866140108.tmp\n",
      "21/06/10 14:14:47 INFO Executor: Adding file:/tmp/spark-1dcd54f4-e6ff-42c8-9236-849f5b204a68/userFiles-2adad0f1-897b-45d9-967a-b7efef557be4/fansi_2.12-0.2.9.jar to class loader\n",
      "21/06/10 14:14:47 INFO Executor: Fetching spark://192.168.15.53:36201/jars/ammonite-interp-api_2.12.12-2.3.8-36-1cce53f3-sources.jar with timestamp 1623302037228\n",
      "21/06/10 14:14:47 INFO Utils: Fetching spark://192.168.15.53:36201/jars/ammonite-interp-api_2.12.12-2.3.8-36-1cce53f3-sources.jar to /tmp/spark-1dcd54f4-e6ff-42c8-9236-849f5b204a68/userFiles-2adad0f1-897b-45d9-967a-b7efef557be4/fetchFileTemp8479334902392500700.tmp\n",
      "21/06/10 14:14:47 INFO Executor: Adding file:/tmp/spark-1dcd54f4-e6ff-42c8-9236-849f5b204a68/userFiles-2adad0f1-897b-45d9-967a-b7efef557be4/ammonite-interp-api_2.12.12-2.3.8-36-1cce53f3-sources.jar to class loader\n",
      "21/06/10 14:14:47 INFO Executor: Fetching spark://192.168.15.53:36201/jars/ammonite-repl-api_2.12.12-2.3.8-36-1cce53f3.jar with timestamp 1623302037229\n",
      "21/06/10 14:14:47 INFO Utils: Fetching spark://192.168.15.53:36201/jars/ammonite-repl-api_2.12.12-2.3.8-36-1cce53f3.jar to /tmp/spark-1dcd54f4-e6ff-42c8-9236-849f5b204a68/userFiles-2adad0f1-897b-45d9-967a-b7efef557be4/fetchFileTemp7635293086301621820.tmp\n",
      "21/06/10 14:14:47 INFO Executor: Adding file:/tmp/spark-1dcd54f4-e6ff-42c8-9236-849f5b204a68/userFiles-2adad0f1-897b-45d9-967a-b7efef557be4/ammonite-repl-api_2.12.12-2.3.8-36-1cce53f3.jar to class loader\n",
      "21/06/10 14:14:47 INFO Executor: Fetching spark://192.168.15.53:36201/jars/fansi_2.12-0.2.9-sources.jar with timestamp 1623302037230\n",
      "21/06/10 14:14:47 INFO Utils: Fetching spark://192.168.15.53:36201/jars/fansi_2.12-0.2.9-sources.jar to /tmp/spark-1dcd54f4-e6ff-42c8-9236-849f5b204a68/userFiles-2adad0f1-897b-45d9-967a-b7efef557be4/fetchFileTemp11206844443098372328.tmp\n",
      "21/06/10 14:14:47 INFO Executor: Adding file:/tmp/spark-1dcd54f4-e6ff-42c8-9236-849f5b204a68/userFiles-2adad0f1-897b-45d9-967a-b7efef557be4/fansi_2.12-0.2.9-sources.jar to class loader\n",
      "21/06/10 14:14:47 INFO Executor: Fetching spark://192.168.15.53:36201/jars/jetty-continuation-8.2.0.v20160908.jar with timestamp 1623302037241\n",
      "21/06/10 14:14:47 INFO Utils: Fetching spark://192.168.15.53:36201/jars/jetty-continuation-8.2.0.v20160908.jar to /tmp/spark-1dcd54f4-e6ff-42c8-9236-849f5b204a68/userFiles-2adad0f1-897b-45d9-967a-b7efef557be4/fetchFileTemp5792351308291340218.tmp\n",
      "21/06/10 14:14:47 INFO Executor: Adding file:/tmp/spark-1dcd54f4-e6ff-42c8-9236-849f5b204a68/userFiles-2adad0f1-897b-45d9-967a-b7efef557be4/jetty-continuation-8.2.0.v20160908.jar to class loader\n",
      "21/06/10 14:14:47 INFO Executor: Fetching spark://192.168.15.53:36201/jars/jvm-repr-0.4.0-sources.jar with timestamp 1623302037227\n",
      "21/06/10 14:14:47 INFO Utils: Fetching spark://192.168.15.53:36201/jars/jvm-repr-0.4.0-sources.jar to /tmp/spark-1dcd54f4-e6ff-42c8-9236-849f5b204a68/userFiles-2adad0f1-897b-45d9-967a-b7efef557be4/fetchFileTemp3082183429584808778.tmp\n",
      "21/06/10 14:14:47 INFO Executor: Adding file:/tmp/spark-1dcd54f4-e6ff-42c8-9236-849f5b204a68/userFiles-2adad0f1-897b-45d9-967a-b7efef557be4/jvm-repr-0.4.0-sources.jar to class loader\n",
      "21/06/10 14:14:47 INFO Executor: Fetching spark://192.168.15.53:36201/jars/mainargs_2.12-0.1.4-sources.jar with timestamp 1623302037232\n",
      "21/06/10 14:14:47 INFO Utils: Fetching spark://192.168.15.53:36201/jars/mainargs_2.12-0.1.4-sources.jar to /tmp/spark-1dcd54f4-e6ff-42c8-9236-849f5b204a68/userFiles-2adad0f1-897b-45d9-967a-b7efef557be4/fetchFileTemp11591754517924379455.tmp\n",
      "21/06/10 14:14:47 INFO Executor: Adding file:/tmp/spark-1dcd54f4-e6ff-42c8-9236-849f5b204a68/userFiles-2adad0f1-897b-45d9-967a-b7efef557be4/mainargs_2.12-0.1.4-sources.jar to class loader\n",
      "21/06/10 14:14:47 INFO Executor: Fetching spark://192.168.15.53:36201/jars/scala-library-2.12.13.jar with timestamp 1623302037239\n",
      "21/06/10 14:14:47 INFO Utils: Fetching spark://192.168.15.53:36201/jars/scala-library-2.12.13.jar to /tmp/spark-1dcd54f4-e6ff-42c8-9236-849f5b204a68/userFiles-2adad0f1-897b-45d9-967a-b7efef557be4/fetchFileTemp13351129348446215907.tmp\n",
      "21/06/10 14:14:47 INFO Executor: Adding file:/tmp/spark-1dcd54f4-e6ff-42c8-9236-849f5b204a68/userFiles-2adad0f1-897b-45d9-967a-b7efef557be4/scala-library-2.12.13.jar to class loader\n",
      "21/06/10 14:14:47 INFO Executor: Fetching spark://192.168.15.53:36201/jars/jetty-http-8.2.0.v20160908.jar with timestamp 1623302037241\n",
      "21/06/10 14:14:47 INFO Utils: Fetching spark://192.168.15.53:36201/jars/jetty-http-8.2.0.v20160908.jar to /tmp/spark-1dcd54f4-e6ff-42c8-9236-849f5b204a68/userFiles-2adad0f1-897b-45d9-967a-b7efef557be4/fetchFileTemp6596057526552527382.tmp\n",
      "21/06/10 14:14:47 INFO Executor: Adding file:/tmp/spark-1dcd54f4-e6ff-42c8-9236-849f5b204a68/userFiles-2adad0f1-897b-45d9-967a-b7efef557be4/jetty-http-8.2.0.v20160908.jar to class loader\n",
      "21/06/10 14:14:47 INFO Executor: Fetching spark://192.168.15.53:36201/jars/scala-compiler-2.12.12-sources.jar with timestamp 1623302037238\n",
      "21/06/10 14:14:47 INFO Utils: Fetching spark://192.168.15.53:36201/jars/scala-compiler-2.12.12-sources.jar to /tmp/spark-1dcd54f4-e6ff-42c8-9236-849f5b204a68/userFiles-2adad0f1-897b-45d9-967a-b7efef557be4/fetchFileTemp4358401400345866834.tmp\n",
      "21/06/10 14:14:47 INFO Executor: Adding file:/tmp/spark-1dcd54f4-e6ff-42c8-9236-849f5b204a68/userFiles-2adad0f1-897b-45d9-967a-b7efef557be4/scala-compiler-2.12.12-sources.jar to class loader\n",
      "21/06/10 14:14:47 INFO Executor: Fetching spark://192.168.15.53:36201/jars/scalaparse_2.12-2.3.0.jar with timestamp 1623302037235\n",
      "21/06/10 14:14:47 INFO Utils: Fetching spark://192.168.15.53:36201/jars/scalaparse_2.12-2.3.0.jar to /tmp/spark-1dcd54f4-e6ff-42c8-9236-849f5b204a68/userFiles-2adad0f1-897b-45d9-967a-b7efef557be4/fetchFileTemp5801365573616270100.tmp\n",
      "21/06/10 14:14:47 INFO Executor: Adding file:/tmp/spark-1dcd54f4-e6ff-42c8-9236-849f5b204a68/userFiles-2adad0f1-897b-45d9-967a-b7efef557be4/scalaparse_2.12-2.3.0.jar to class loader\n",
      "21/06/10 14:14:47 INFO Executor: Fetching spark://192.168.15.53:36201/jars/fastparse_2.12-2.3.0-sources.jar with timestamp 1623302037230\n",
      "21/06/10 14:14:47 INFO Utils: Fetching spark://192.168.15.53:36201/jars/fastparse_2.12-2.3.0-sources.jar to /tmp/spark-1dcd54f4-e6ff-42c8-9236-849f5b204a68/userFiles-2adad0f1-897b-45d9-967a-b7efef557be4/fetchFileTemp9670270500808597804.tmp\n",
      "21/06/10 14:14:47 INFO Executor: Adding file:/tmp/spark-1dcd54f4-e6ff-42c8-9236-849f5b204a68/userFiles-2adad0f1-897b-45d9-967a-b7efef557be4/fastparse_2.12-2.3.0-sources.jar to class loader\n",
      "21/06/10 14:14:47 INFO Executor: Fetching spark://192.168.15.53:36201/jars/javassist-3.21.0-GA-sources.jar with timestamp 1623302037237\n",
      "21/06/10 14:14:47 INFO Utils: Fetching spark://192.168.15.53:36201/jars/javassist-3.21.0-GA-sources.jar to /tmp/spark-1dcd54f4-e6ff-42c8-9236-849f5b204a68/userFiles-2adad0f1-897b-45d9-967a-b7efef557be4/fetchFileTemp7328405778453015780.tmp\n",
      "21/06/10 14:14:47 INFO Executor: Adding file:/tmp/spark-1dcd54f4-e6ff-42c8-9236-849f5b204a68/userFiles-2adad0f1-897b-45d9-967a-b7efef557be4/javassist-3.21.0-GA-sources.jar to class loader\n",
      "21/06/10 14:14:47 INFO Executor: Fetching spark://192.168.15.53:36201/jars/javaparser-core-3.2.5-sources.jar with timestamp 1623302037227\n",
      "21/06/10 14:14:47 INFO Utils: Fetching spark://192.168.15.53:36201/jars/javaparser-core-3.2.5-sources.jar to /tmp/spark-1dcd54f4-e6ff-42c8-9236-849f5b204a68/userFiles-2adad0f1-897b-45d9-967a-b7efef557be4/fetchFileTemp18019773944094966641.tmp\n",
      "21/06/10 14:14:47 INFO Executor: Adding file:/tmp/spark-1dcd54f4-e6ff-42c8-9236-849f5b204a68/userFiles-2adad0f1-897b-45d9-967a-b7efef557be4/javaparser-core-3.2.5-sources.jar to class loader\n",
      "21/06/10 14:14:47 INFO Executor: Fetching spark://192.168.15.53:36201/jars/interface-1.0.3-sources.jar with timestamp 1623302037236\n",
      "21/06/10 14:14:47 INFO Utils: Fetching spark://192.168.15.53:36201/jars/interface-1.0.3-sources.jar to /tmp/spark-1dcd54f4-e6ff-42c8-9236-849f5b204a68/userFiles-2adad0f1-897b-45d9-967a-b7efef557be4/fetchFileTemp10754895356526001157.tmp\n",
      "21/06/10 14:14:47 INFO Executor: Adding file:/tmp/spark-1dcd54f4-e6ff-42c8-9236-849f5b204a68/userFiles-2adad0f1-897b-45d9-967a-b7efef557be4/interface-1.0.3-sources.jar to class loader\n",
      "21/06/10 14:14:47 INFO Executor: Fetching spark://192.168.15.53:36201/jars/ammonite-spark_2.12-0.3.0.jar with timestamp 1623302037240\n",
      "21/06/10 14:14:47 INFO Utils: Fetching spark://192.168.15.53:36201/jars/ammonite-spark_2.12-0.3.0.jar to /tmp/spark-1dcd54f4-e6ff-42c8-9236-849f5b204a68/userFiles-2adad0f1-897b-45d9-967a-b7efef557be4/fetchFileTemp1277139245040694009.tmp\n",
      "21/06/10 14:14:47 INFO Executor: Adding file:/tmp/spark-1dcd54f4-e6ff-42c8-9236-849f5b204a68/userFiles-2adad0f1-897b-45d9-967a-b7efef557be4/ammonite-spark_2.12-0.3.0.jar to class loader\n",
      "21/06/10 14:14:47 INFO Executor: Fetching spark://192.168.15.53:36201/jars/ammonite-ops_2.12-2.3.8-36-1cce53f3-sources.jar with timestamp 1623302037228\n",
      "21/06/10 14:14:47 INFO Utils: Fetching spark://192.168.15.53:36201/jars/ammonite-ops_2.12-2.3.8-36-1cce53f3-sources.jar to /tmp/spark-1dcd54f4-e6ff-42c8-9236-849f5b204a68/userFiles-2adad0f1-897b-45d9-967a-b7efef557be4/fetchFileTemp14077999971194111114.tmp\n",
      "21/06/10 14:14:47 INFO Executor: Adding file:/tmp/spark-1dcd54f4-e6ff-42c8-9236-849f5b204a68/userFiles-2adad0f1-897b-45d9-967a-b7efef557be4/ammonite-ops_2.12-2.3.8-36-1cce53f3-sources.jar to class loader\n",
      "21/06/10 14:14:47 INFO Executor: Fetching spark://192.168.15.53:36201/jars/sourcecode_2.12-0.2.3.jar with timestamp 1623302037235\n",
      "21/06/10 14:14:47 INFO Utils: Fetching spark://192.168.15.53:36201/jars/sourcecode_2.12-0.2.3.jar to /tmp/spark-1dcd54f4-e6ff-42c8-9236-849f5b204a68/userFiles-2adad0f1-897b-45d9-967a-b7efef557be4/fetchFileTemp6886037444384939232.tmp\n",
      "21/06/10 14:14:47 INFO Executor: Adding file:/tmp/spark-1dcd54f4-e6ff-42c8-9236-849f5b204a68/userFiles-2adad0f1-897b-45d9-967a-b7efef557be4/sourcecode_2.12-0.2.3.jar to class loader\n",
      "21/06/10 14:14:47 INFO Executor: Fetching spark://192.168.15.53:36201/jars/scala-kernel-api_2.12.12-0.11.1-sources.jar with timestamp 1623302037239\n",
      "21/06/10 14:14:47 INFO Utils: Fetching spark://192.168.15.53:36201/jars/scala-kernel-api_2.12.12-0.11.1-sources.jar to /tmp/spark-1dcd54f4-e6ff-42c8-9236-849f5b204a68/userFiles-2adad0f1-897b-45d9-967a-b7efef557be4/fetchFileTemp11880515658241173198.tmp\n",
      "21/06/10 14:14:47 INFO Executor: Adding file:/tmp/spark-1dcd54f4-e6ff-42c8-9236-849f5b204a68/userFiles-2adad0f1-897b-45d9-967a-b7efef557be4/scala-kernel-api_2.12.12-0.11.1-sources.jar to class loader\n",
      "21/06/10 14:14:47 INFO Executor: Fetching spark://192.168.15.53:36201/jars/jetty-io-8.2.0.v20160908.jar with timestamp 1623302037242\n",
      "21/06/10 14:14:47 INFO Utils: Fetching spark://192.168.15.53:36201/jars/jetty-io-8.2.0.v20160908.jar to /tmp/spark-1dcd54f4-e6ff-42c8-9236-849f5b204a68/userFiles-2adad0f1-897b-45d9-967a-b7efef557be4/fetchFileTemp8590567951853825458.tmp\n",
      "21/06/10 14:14:47 INFO Executor: Adding file:/tmp/spark-1dcd54f4-e6ff-42c8-9236-849f5b204a68/userFiles-2adad0f1-897b-45d9-967a-b7efef557be4/jetty-io-8.2.0.v20160908.jar to class loader\n",
      "21/06/10 14:14:47 INFO Executor: Fetching spark://192.168.15.53:36201/jars/jvm-repr-0.4.0.jar with timestamp 1623302037227\n",
      "21/06/10 14:14:47 INFO Utils: Fetching spark://192.168.15.53:36201/jars/jvm-repr-0.4.0.jar to /tmp/spark-1dcd54f4-e6ff-42c8-9236-849f5b204a68/userFiles-2adad0f1-897b-45d9-967a-b7efef557be4/fetchFileTemp12839052085463801757.tmp\n",
      "21/06/10 14:14:47 INFO Executor: Adding file:/tmp/spark-1dcd54f4-e6ff-42c8-9236-849f5b204a68/userFiles-2adad0f1-897b-45d9-967a-b7efef557be4/jvm-repr-0.4.0.jar to class loader\n",
      "21/06/10 14:14:47 INFO Executor: Fetching spark://192.168.15.53:36201/jars/scalaparse_2.12-2.3.0-sources.jar with timestamp 1623302037234\n",
      "21/06/10 14:14:47 INFO Utils: Fetching spark://192.168.15.53:36201/jars/scalaparse_2.12-2.3.0-sources.jar to /tmp/spark-1dcd54f4-e6ff-42c8-9236-849f5b204a68/userFiles-2adad0f1-897b-45d9-967a-b7efef557be4/fetchFileTemp16996270709731594588.tmp\n",
      "21/06/10 14:14:47 INFO Executor: Adding file:/tmp/spark-1dcd54f4-e6ff-42c8-9236-849f5b204a68/userFiles-2adad0f1-897b-45d9-967a-b7efef557be4/scalaparse_2.12-2.3.0-sources.jar to class loader\n",
      "21/06/10 14:14:47 INFO Executor: Fetching spark://192.168.15.53:36201/jars/pprint_2.12-0.6.0.jar with timestamp 1623302037234\n",
      "21/06/10 14:14:47 INFO Utils: Fetching spark://192.168.15.53:36201/jars/pprint_2.12-0.6.0.jar to /tmp/spark-1dcd54f4-e6ff-42c8-9236-849f5b204a68/userFiles-2adad0f1-897b-45d9-967a-b7efef557be4/fetchFileTemp15627377839684184522.tmp\n",
      "21/06/10 14:14:47 INFO Executor: Adding file:/tmp/spark-1dcd54f4-e6ff-42c8-9236-849f5b204a68/userFiles-2adad0f1-897b-45d9-967a-b7efef557be4/pprint_2.12-0.6.0.jar to class loader\n",
      "21/06/10 14:14:47 INFO Executor: Fetching spark://192.168.15.53:36201/jars/macro-compat_2.12-1.1.1.jar with timestamp 1623302037241\n",
      "21/06/10 14:14:47 INFO Utils: Fetching spark://192.168.15.53:36201/jars/macro-compat_2.12-1.1.1.jar to /tmp/spark-1dcd54f4-e6ff-42c8-9236-849f5b204a68/userFiles-2adad0f1-897b-45d9-967a-b7efef557be4/fetchFileTemp6552338965152912596.tmp\n",
      "21/06/10 14:14:47 INFO Executor: Adding file:/tmp/spark-1dcd54f4-e6ff-42c8-9236-849f5b204a68/userFiles-2adad0f1-897b-45d9-967a-b7efef557be4/macro-compat_2.12-1.1.1.jar to class loader\n",
      "21/06/10 14:14:47 INFO Executor: Fetching spark://192.168.15.53:36201/jars/geny_2.12-0.6.5.jar with timestamp 1623302037231\n",
      "21/06/10 14:14:47 INFO Utils: Fetching spark://192.168.15.53:36201/jars/geny_2.12-0.6.5.jar to /tmp/spark-1dcd54f4-e6ff-42c8-9236-849f5b204a68/userFiles-2adad0f1-897b-45d9-967a-b7efef557be4/fetchFileTemp7216730817583006070.tmp\n",
      "21/06/10 14:14:47 INFO Executor: Adding file:/tmp/spark-1dcd54f4-e6ff-42c8-9236-849f5b204a68/userFiles-2adad0f1-897b-45d9-967a-b7efef557be4/geny_2.12-0.6.5.jar to class loader\n",
      "21/06/10 14:14:47 INFO Executor: Fetching spark://192.168.15.53:36201/jars/argonaut_2.12-6.2.2.jar with timestamp 1623302037241\n",
      "21/06/10 14:14:47 INFO Utils: Fetching spark://192.168.15.53:36201/jars/argonaut_2.12-6.2.2.jar to /tmp/spark-1dcd54f4-e6ff-42c8-9236-849f5b204a68/userFiles-2adad0f1-897b-45d9-967a-b7efef557be4/fetchFileTemp8039735990014019601.tmp\n",
      "21/06/10 14:14:47 INFO Executor: Adding file:/tmp/spark-1dcd54f4-e6ff-42c8-9236-849f5b204a68/userFiles-2adad0f1-897b-45d9-967a-b7efef557be4/argonaut_2.12-6.2.2.jar to class loader\n",
      "21/06/10 14:14:47 INFO Executor: Fetching spark://192.168.15.53:36201/jars/scala-library-2.12.12-sources.jar with timestamp 1623302037238\n",
      "21/06/10 14:14:47 INFO Utils: Fetching spark://192.168.15.53:36201/jars/scala-library-2.12.12-sources.jar to /tmp/spark-1dcd54f4-e6ff-42c8-9236-849f5b204a68/userFiles-2adad0f1-897b-45d9-967a-b7efef557be4/fetchFileTemp5539289977962630601.tmp\n",
      "21/06/10 14:14:47 INFO Executor: Adding file:/tmp/spark-1dcd54f4-e6ff-42c8-9236-849f5b204a68/userFiles-2adad0f1-897b-45d9-967a-b7efef557be4/scala-library-2.12.12-sources.jar to class loader\n",
      "21/06/10 14:14:47 INFO Executor: Fetching spark://192.168.15.53:36201/jars/interface-1.0.3.jar with timestamp 1623302037236\n",
      "21/06/10 14:14:47 INFO Utils: Fetching spark://192.168.15.53:36201/jars/interface-1.0.3.jar to /tmp/spark-1dcd54f4-e6ff-42c8-9236-849f5b204a68/userFiles-2adad0f1-897b-45d9-967a-b7efef557be4/fetchFileTemp12063792937652654046.tmp\n",
      "21/06/10 14:14:47 INFO Executor: Adding file:/tmp/spark-1dcd54f4-e6ff-42c8-9236-849f5b204a68/userFiles-2adad0f1-897b-45d9-967a-b7efef557be4/interface-1.0.3.jar to class loader\n",
      "21/06/10 14:14:47 INFO Executor: Fetching spark://192.168.15.53:36201/jars/ammonite-interp-api_2.12.12-2.3.8-36-1cce53f3.jar with timestamp 1623302037228\n",
      "21/06/10 14:14:47 INFO Utils: Fetching spark://192.168.15.53:36201/jars/ammonite-interp-api_2.12.12-2.3.8-36-1cce53f3.jar to /tmp/spark-1dcd54f4-e6ff-42c8-9236-849f5b204a68/userFiles-2adad0f1-897b-45d9-967a-b7efef557be4/fetchFileTemp15937753424701938189.tmp\n",
      "21/06/10 14:14:47 INFO Executor: Adding file:/tmp/spark-1dcd54f4-e6ff-42c8-9236-849f5b204a68/userFiles-2adad0f1-897b-45d9-967a-b7efef557be4/ammonite-interp-api_2.12.12-2.3.8-36-1cce53f3.jar to class loader\n",
      "21/06/10 14:14:47 INFO Executor: Fetching spark://192.168.15.53:36201/jars/scala-kernel-api_2.12.12-0.11.1.jar with timestamp 1623302037239\n",
      "21/06/10 14:14:47 INFO Utils: Fetching spark://192.168.15.53:36201/jars/scala-kernel-api_2.12.12-0.11.1.jar to /tmp/spark-1dcd54f4-e6ff-42c8-9236-849f5b204a68/userFiles-2adad0f1-897b-45d9-967a-b7efef557be4/fetchFileTemp7541619214961915111.tmp\n",
      "21/06/10 14:14:47 INFO Executor: Adding file:/tmp/spark-1dcd54f4-e6ff-42c8-9236-849f5b204a68/userFiles-2adad0f1-897b-45d9-967a-b7efef557be4/scala-kernel-api_2.12.12-0.11.1.jar to class loader\n",
      "21/06/10 14:14:47 INFO Executor: Fetching spark://192.168.15.53:36201/jars/jetty-util-8.2.0.v20160908.jar with timestamp 1623302037242\n",
      "21/06/10 14:14:47 INFO Utils: Fetching spark://192.168.15.53:36201/jars/jetty-util-8.2.0.v20160908.jar to /tmp/spark-1dcd54f4-e6ff-42c8-9236-849f5b204a68/userFiles-2adad0f1-897b-45d9-967a-b7efef557be4/fetchFileTemp1648097588300377725.tmp\n",
      "21/06/10 14:14:47 INFO Executor: Adding file:/tmp/spark-1dcd54f4-e6ff-42c8-9236-849f5b204a68/userFiles-2adad0f1-897b-45d9-967a-b7efef557be4/jetty-util-8.2.0.v20160908.jar to class loader\n",
      "21/06/10 14:14:47 INFO FileScanRDD: Reading File path: file:///home/yoichiro/develop/analysis/data/econ/clustering/country_data.csv, range: 0-9229, partition values: [empty row]\n",
      "21/06/10 14:14:47 INFO CodeGenerator: Code generated in 152.9227 ms\n",
      "21/06/10 14:14:47 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1355 bytes result sent to driver\n",
      "21/06/10 14:14:47 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1526 ms on localhost (executor driver) (1/1)\n",
      "21/06/10 14:14:47 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool \n",
      "21/06/10 14:14:47 INFO DAGScheduler: ResultStage 0 (load at cmd51.sc:1) finished in 1.700 s\n",
      "21/06/10 14:14:47 INFO DAGScheduler: Job 0 finished: load at cmd51.sc:1, took 1.775482 s\n",
      "21/06/10 14:14:47 INFO FileSourceStrategy: Pruning directories with: \n",
      "21/06/10 14:14:47 INFO FileSourceStrategy: Post-Scan Filters: \n",
      "21/06/10 14:14:47 INFO FileSourceStrategy: Output Data Schema: struct<value: string>\n",
      "21/06/10 14:14:47 INFO FileSourceScanExec: Pushed Filters: \n",
      "21/06/10 14:14:47 INFO CodeGenerator: Code generated in 9.5626 ms\n",
      "21/06/10 14:14:47 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 121.9 KB, free 1001.7 MB)\n",
      "21/06/10 14:14:48 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 23.1 KB, free 1001.7 MB)\n",
      "21/06/10 14:14:48 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 192.168.15.53:41049 (size: 23.1 KB, free: 1002.0 MB)\n",
      "21/06/10 14:14:48 INFO SparkContext: Created broadcast 2 from load at cmd51.sc:1\n",
      "21/06/10 14:14:48 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "21/06/10 14:14:48 INFO SparkContext: Starting job: load at cmd51.sc:1\n",
      "21/06/10 14:14:48 INFO DAGScheduler: Got job 1 (load at cmd51.sc:1) with 2 output partitions\n",
      "21/06/10 14:14:48 INFO DAGScheduler: Final stage: ResultStage 1 (load at cmd51.sc:1)\n",
      "21/06/10 14:14:48 INFO DAGScheduler: Parents of final stage: List()\n",
      "21/06/10 14:14:48 INFO DAGScheduler: Missing parents: List()\n",
      "21/06/10 14:14:48 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[8] at load at cmd51.sc:1), which has no missing parents\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "  <span style=\"float: left;\">load at cmd51.sc:1</span>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"progress\">\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: blue; width: 100%; word-wrap: normal; white-space: nowrap; text-align: center; color: white\" aria-valuenow=\"100\" aria-valuemin=\"0\" aria-valuemax=\"100\">\n",
       "    2 / 2\n",
       "  </div>\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: red; width: 0%\" aria-valuenow=\"0\" aria-valuemin=\"0\" aria-valuemax=\"100\"></div>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/06/10 14:14:48 INFO ContextCleaner: Cleaned accumulator 26\n",
      "21/06/10 14:14:48 INFO ContextCleaner: Cleaned accumulator 7\n",
      "21/06/10 14:14:48 INFO ContextCleaner: Cleaned accumulator 3\n",
      "21/06/10 14:14:48 INFO ContextCleaner: Cleaned accumulator 15\n",
      "21/06/10 14:14:48 INFO ContextCleaner: Cleaned accumulator 5\n",
      "21/06/10 14:14:48 INFO ContextCleaner: Cleaned accumulator 13\n",
      "21/06/10 14:14:48 INFO ContextCleaner: Cleaned accumulator 24\n",
      "21/06/10 14:14:48 INFO ContextCleaner: Cleaned accumulator 0\n",
      "21/06/10 14:14:48 INFO ContextCleaner: Cleaned accumulator 19\n",
      "21/06/10 14:14:48 INFO ContextCleaner: Cleaned accumulator 4\n",
      "21/06/10 14:14:48 INFO ContextCleaner: Cleaned accumulator 1\n",
      "21/06/10 14:14:48 INFO ContextCleaner: Cleaned accumulator 16\n",
      "21/06/10 14:14:48 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 192.168.15.53:41049 in memory (size: 5.0 KB, free: 1002.0 MB)\n",
      "21/06/10 14:14:48 INFO ContextCleaner: Cleaned accumulator 28\n",
      "21/06/10 14:14:48 INFO ContextCleaner: Cleaned accumulator 21\n",
      "21/06/10 14:14:48 INFO ContextCleaner: Cleaned accumulator 23\n",
      "21/06/10 14:14:48 INFO ContextCleaner: Cleaned accumulator 8\n",
      "21/06/10 14:14:48 INFO ContextCleaner: Cleaned accumulator 22\n",
      "21/06/10 14:14:48 INFO ContextCleaner: Cleaned accumulator 25\n",
      "21/06/10 14:14:48 INFO ContextCleaner: Cleaned accumulator 27\n",
      "21/06/10 14:14:48 INFO ContextCleaner: Cleaned accumulator 17\n",
      "21/06/10 14:14:48 INFO ContextCleaner: Cleaned accumulator 30\n",
      "21/06/10 14:14:48 INFO ContextCleaner: Cleaned accumulator 20\n",
      "21/06/10 14:14:48 INFO ContextCleaner: Cleaned accumulator 29\n",
      "21/06/10 14:14:48 INFO ContextCleaner: Cleaned accumulator 14\n",
      "21/06/10 14:14:48 INFO ContextCleaner: Cleaned accumulator 6\n",
      "21/06/10 14:14:48 INFO ContextCleaner: Cleaned accumulator 18\n",
      "21/06/10 14:14:48 INFO ContextCleaner: Cleaned accumulator 12\n",
      "21/06/10 14:14:48 INFO ContextCleaner: Cleaned accumulator 10\n",
      "21/06/10 14:14:48 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 192.168.15.53:41049 in memory (size: 23.1 KB, free: 1002.0 MB)\n",
      "21/06/10 14:14:48 INFO ContextCleaner: Cleaned accumulator 9\n",
      "21/06/10 14:14:48 INFO ContextCleaner: Cleaned accumulator 11\n",
      "21/06/10 14:14:48 INFO ContextCleaner: Cleaned accumulator 2\n",
      "21/06/10 14:14:48 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 15.2 KB, free 1001.8 MB)\n",
      "21/06/10 14:14:48 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 7.7 KB, free 1001.8 MB)\n",
      "21/06/10 14:14:48 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 192.168.15.53:41049 (size: 7.7 KB, free: 1002.0 MB)\n",
      "21/06/10 14:14:48 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1161\n",
      "21/06/10 14:14:48 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (MapPartitionsRDD[8] at load at cmd51.sc:1) (first 15 tasks are for partitions Vector(0, 1))\n",
      "21/06/10 14:14:48 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks\n",
      "21/06/10 14:14:48 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 7805 bytes)\n",
      "21/06/10 14:14:48 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 2, localhost, executor driver, partition 1, PROCESS_LOCAL, 7805 bytes)\n",
      "21/06/10 14:14:48 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)\n",
      "21/06/10 14:14:48 INFO Executor: Running task 1.0 in stage 1.0 (TID 2)\n",
      "21/06/10 14:14:48 INFO FileScanRDD: Reading File path: file:///home/yoichiro/develop/analysis/data/econ/clustering/country_data.csv, range: 0-9229, partition values: [empty row]\n",
      "21/06/10 14:14:48 INFO FileScanRDD: Reading File path: file:///home/yoichiro/develop/analysis/data/econ/clustering/country_data.csv, range: 0-9229, partition values: [empty row]\n",
      "21/06/10 14:14:48 INFO Executor: Finished task 1.0 in stage 1.0 (TID 2). 1627 bytes result sent to driver\n",
      "21/06/10 14:14:48 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1584 bytes result sent to driver\n",
      "21/06/10 14:14:48 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 2) in 139 ms on localhost (executor driver) (1/2)\n",
      "21/06/10 14:14:48 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 143 ms on localhost (executor driver) (2/2)\n",
      "21/06/10 14:14:48 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool \n",
      "21/06/10 14:14:48 INFO DAGScheduler: ResultStage 1 (load at cmd51.sc:1) finished in 0.253 s\n",
      "21/06/10 14:14:48 INFO DAGScheduler: Job 1 finished: load at cmd51.sc:1, took 0.258402 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mdf\u001b[39m: \u001b[32mDataFrame\u001b[39m = [country: string, child_mort: double ... 8 more fields]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val df= spark.read.format(\"csv\").option(\"header\", \"true\").option(\"inferSchema\",\"true\").load(\"./data/econ/clustering/country_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6e397b8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mclass\u001b[39m \u001b[36mRichDF\u001b[39m"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "implicit class RichDF(val ds:DataFrame) {\n",
    "    def showHTML(limit:Int = 20, truncate: Int = 20) = {\n",
    "        import xml.Utility.escape\n",
    "        val data = ds.take(limit)\n",
    "        val header = ds.schema.fieldNames.toSeq        \n",
    "        val rows: Seq[Seq[String]] = data.map { row =>\n",
    "          row.toSeq.map { cell =>\n",
    "            val str = cell match {\n",
    "              case null => \"null\"\n",
    "              case binary: Array[Byte] => binary.map(\"%02X\".format(_)).mkString(\"[\", \" \", \"]\")\n",
    "              case array: Array[_] => array.mkString(\"[\", \", \", \"]\")\n",
    "              case seq: Seq[_] => seq.mkString(\"[\", \", \", \"]\")\n",
    "              case _ => cell.toString\n",
    "            }\n",
    "            if (truncate > 0 && str.length > truncate) {\n",
    "              // do not show ellipses for strings shorter than 4 characters.\n",
    "              if (truncate < 4) str.substring(0, truncate)\n",
    "              else str.substring(0, truncate - 3) + \"...\"\n",
    "            } else {\n",
    "              str\n",
    "            }\n",
    "          }: Seq[String]\n",
    "        }\n",
    "\n",
    "        publish.html(s\"\"\" <table>\n",
    "                <tr>\n",
    "                 ${header.map(h => s\"<th>${escape(h)}</th>\").mkString}\n",
    "                </tr>\n",
    "                ${rows.map { row =>\n",
    "                  s\"<tr>${row.map{c => s\"<td>${escape(c)}</td>\" }.mkString}</tr>\"\n",
    "                }.mkString}\n",
    "            </table>\n",
    "        \"\"\")        \n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "46034a89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/06/10 14:17:02 INFO FileSourceStrategy: Pruning directories with: \n",
      "21/06/10 14:17:02 INFO FileSourceStrategy: Post-Scan Filters: \n",
      "21/06/10 14:17:02 INFO FileSourceStrategy: Output Data Schema: struct<country: string, child_mort: double, exports: double, health: double, imports: double ... 8 more fields>\n",
      "21/06/10 14:17:02 INFO FileSourceScanExec: Pushed Filters: \n",
      "21/06/10 14:17:02 INFO CodeGenerator: Code generated in 27.5785 ms\n",
      "21/06/10 14:17:02 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 121.9 KB, free 1001.9 MB)\n",
      "21/06/10 14:17:02 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 23.1 KB, free 1001.9 MB)\n",
      "21/06/10 14:17:02 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 192.168.15.53:41049 (size: 23.1 KB, free: 1002.0 MB)\n",
      "21/06/10 14:17:02 INFO SparkContext: Created broadcast 4 from take at cmd52.sc:4\n",
      "21/06/10 14:17:02 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "21/06/10 14:17:02 INFO SparkContext: Starting job: take at cmd52.sc:4\n",
      "21/06/10 14:17:02 INFO DAGScheduler: Got job 2 (take at cmd52.sc:4) with 1 output partitions\n",
      "21/06/10 14:17:02 INFO DAGScheduler: Final stage: ResultStage 2 (take at cmd52.sc:4)\n",
      "21/06/10 14:17:02 INFO DAGScheduler: Parents of final stage: List()\n",
      "21/06/10 14:17:02 INFO DAGScheduler: Missing parents: List()\n",
      "21/06/10 14:17:02 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at take at cmd52.sc:4), which has no missing parents\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "  <span style=\"float: left;\">take at cmd52.sc:4</span>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"progress\">\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: blue; width: 100%; word-wrap: normal; white-space: nowrap; text-align: center; color: white\" aria-valuenow=\"100\" aria-valuemin=\"0\" aria-valuemax=\"100\">\n",
       "    1 / 1\n",
       "  </div>\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: red; width: 0%\" aria-valuenow=\"0\" aria-valuemin=\"0\" aria-valuemax=\"100\"></div>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/06/10 14:17:03 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 12.1 KB, free 1001.8 MB)\n",
      "21/06/10 14:17:03 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 6.4 KB, free 1001.8 MB)\n",
      "21/06/10 14:17:03 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 192.168.15.53:41049 (size: 6.4 KB, free: 1002.0 MB)\n",
      "21/06/10 14:17:03 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1161\n",
      "21/06/10 14:17:03 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at take at cmd52.sc:4) (first 15 tasks are for partitions Vector(0))\n",
      "21/06/10 14:17:03 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks\n",
      "21/06/10 14:17:03 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 3, localhost, executor driver, partition 0, PROCESS_LOCAL, 7805 bytes)\n",
      "21/06/10 14:17:03 INFO Executor: Running task 0.0 in stage 2.0 (TID 3)\n",
      "21/06/10 14:17:03 INFO FileScanRDD: Reading File path: file:///home/yoichiro/develop/analysis/data/econ/clustering/country_data.csv, range: 0-9229, partition values: [empty row]\n",
      "21/06/10 14:17:03 INFO CodeGenerator: Code generated in 51.7951 ms\n",
      "21/06/10 14:17:03 INFO Executor: Finished task 0.0 in stage 2.0 (TID 3). 2435 bytes result sent to driver\n",
      "21/06/10 14:17:03 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 3) in 127 ms on localhost (executor driver) (1/1)\n",
      "21/06/10 14:17:03 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool \n",
      "21/06/10 14:17:03 INFO DAGScheduler: ResultStage 2 (take at cmd52.sc:4) finished in 0.170 s\n",
      "21/06/10 14:17:03 INFO DAGScheduler: Job 2 finished: take at cmd52.sc:4, took 0.178165 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       " <table>\n",
       "                <tr>\n",
       "                 <th>country</th><th>child_mort</th><th>exports</th><th>health</th><th>imports</th><th>income</th><th>inflation</th><th>life_expec</th><th>total_fer</th><th>gdpp</th>\n",
       "                </tr>\n",
       "                <tr><td>Afghanistan</td><td>90.2</td><td>10.0</td><td>7.58</td><td>44.9</td><td>1610</td><td>9.44</td><td>56.2</td><td>5.82</td><td>553</td></tr><tr><td>Albania</td><td>16.6</td><td>28.0</td><td>6.55</td><td>48.6</td><td>9930</td><td>4.49</td><td>76.3</td><td>1.65</td><td>4090</td></tr><tr><td>Algeria</td><td>27.3</td><td>38.4</td><td>4.17</td><td>31.4</td><td>12900</td><td>16.1</td><td>76.5</td><td>2.89</td><td>4460</td></tr><tr><td>Angola</td><td>119.0</td><td>62.3</td><td>2.85</td><td>42.9</td><td>5900</td><td>22.4</td><td>60.1</td><td>6.16</td><td>3530</td></tr><tr><td>Antigua and Barbuda</td><td>10.3</td><td>45.5</td><td>6.03</td><td>58.9</td><td>19100</td><td>1.44</td><td>76.8</td><td>2.13</td><td>12200</td></tr><tr><td>Argentina</td><td>14.5</td><td>18.9</td><td>8.1</td><td>16.0</td><td>18700</td><td>20.9</td><td>75.8</td><td>2.37</td><td>10300</td></tr><tr><td>Armenia</td><td>18.1</td><td>20.8</td><td>4.4</td><td>45.3</td><td>6700</td><td>7.77</td><td>73.3</td><td>1.69</td><td>3220</td></tr><tr><td>Australia</td><td>4.8</td><td>19.8</td><td>8.73</td><td>20.9</td><td>41400</td><td>1.16</td><td>82.0</td><td>1.93</td><td>51900</td></tr><tr><td>Austria</td><td>4.3</td><td>51.3</td><td>11.0</td><td>47.8</td><td>43200</td><td>0.873</td><td>80.5</td><td>1.44</td><td>46900</td></tr><tr><td>Azerbaijan</td><td>39.2</td><td>54.3</td><td>5.88</td><td>20.7</td><td>16000</td><td>13.8</td><td>69.1</td><td>1.92</td><td>5840</td></tr><tr><td>Bahamas</td><td>13.8</td><td>35.0</td><td>7.89</td><td>43.7</td><td>22900</td><td>-0.393</td><td>73.8</td><td>1.86</td><td>28000</td></tr><tr><td>Bahrain</td><td>8.6</td><td>69.5</td><td>4.97</td><td>50.9</td><td>41100</td><td>7.44</td><td>76.0</td><td>2.16</td><td>20700</td></tr><tr><td>Bangladesh</td><td>49.4</td><td>16.0</td><td>3.52</td><td>21.8</td><td>2440</td><td>7.14</td><td>70.4</td><td>2.33</td><td>758</td></tr><tr><td>Barbados</td><td>14.2</td><td>39.5</td><td>7.97</td><td>48.7</td><td>15300</td><td>0.321</td><td>76.7</td><td>1.78</td><td>16000</td></tr><tr><td>Belarus</td><td>5.5</td><td>51.4</td><td>5.61</td><td>64.5</td><td>16200</td><td>15.1</td><td>70.4</td><td>1.49</td><td>6030</td></tr><tr><td>Belgium</td><td>4.5</td><td>76.4</td><td>10.7</td><td>74.7</td><td>41100</td><td>1.88</td><td>80.0</td><td>1.86</td><td>44400</td></tr><tr><td>Belize</td><td>18.8</td><td>58.2</td><td>5.2</td><td>57.5</td><td>7880</td><td>1.14</td><td>71.4</td><td>2.71</td><td>4340</td></tr><tr><td>Benin</td><td>111.0</td><td>23.8</td><td>4.1</td><td>37.2</td><td>1820</td><td>0.885</td><td>61.8</td><td>5.36</td><td>758</td></tr><tr><td>Bhutan</td><td>42.7</td><td>42.5</td><td>5.2</td><td>70.7</td><td>6420</td><td>5.99</td><td>72.1</td><td>2.38</td><td>2180</td></tr><tr><td>Bolivia</td><td>46.6</td><td>41.2</td><td>4.84</td><td>34.3</td><td>5410</td><td>8.78</td><td>71.6</td><td>3.2</td><td>1980</td></tr>\n",
       "            </table>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.showHTML()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "74e2c9fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(console):4:20 expected (Semis | &\"}\" | end-of-input)\n",
      "Displayers.register(classOf[Row], (row: Row) => {\n",
      "                   ^"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "(console):4:20 expected (Semis | &\"}\" | end-of-input)\nDisplayers.register(classOf[Row], (row: Row) => {\n                   ^"
     ]
    }
   ],
   "source": [
    "import jupyter.Displayer, jupyter.Displayers\n",
    "import scala.collection.JavaConverters._\n",
    "import almond.api.helpers.Display.\n",
    "Displayers.register(classOf[Row], (row: Row) => {\n",
    "  Map(\n",
    "    \"text/html\" -> {\n",
    "      table(cls:=\"table\")(\n",
    "        tr(th(\"Name\")),\n",
    "        for (0<- row.length-1) yield tr(\n",
    "          td(row(0)),\n",
    "        )\n",
    "      ).render\n",
    "    }\n",
    "  ).asJava\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f76aabf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cmd52.sc:1: value showHTML is not a member of org.apache.spark.sql.DataFrame\n",
      "val res52 = df.describe().showHTML()\n",
      "                          ^Compilation Failed"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "Compilation Failed"
     ]
    }
   ],
   "source": [
    "df.describe().showHTML()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9f0c674b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/06/10 02:20:49 INFO FileSourceStrategy: Pruning directories with: \n",
      "21/06/10 02:20:49 INFO FileSourceStrategy: Post-Scan Filters: \n",
      "21/06/10 02:20:49 INFO FileSourceStrategy: Output Data Schema: struct<country: string, child_mort: string, exports: string, health: string, imports: string ... 8 more fields>\n",
      "21/06/10 02:20:49 INFO FileSourceScanExec: Pushed Filters: \n",
      "21/06/10 02:20:50 INFO MemoryStore: Block broadcast_23 stored as values in memory (estimated size 121.8 KB, free 1001.9 MB)\n",
      "21/06/10 02:20:50 INFO ContextCleaner: Cleaned accumulator 372\n",
      "21/06/10 02:20:50 INFO MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 23.1 KB, free 1001.9 MB)\n",
      "21/06/10 02:20:50 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on 192.168.15.53:46349 (size: 23.1 KB, free: 1002.0 MB)\n",
      "21/06/10 02:20:50 INFO SparkContext: Created broadcast 23 from summary at cmd19.sc:1\n",
      "21/06/10 02:20:50 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "21/06/10 02:20:50 INFO SparkContext: Starting job: summary at cmd19.sc:1\n",
      "21/06/10 02:20:50 INFO DAGScheduler: Registering RDD 55 (summary at cmd19.sc:1)\n",
      "21/06/10 02:20:50 INFO DAGScheduler: Got job 9 (summary at cmd19.sc:1) with 1 output partitions\n",
      "21/06/10 02:20:50 INFO DAGScheduler: Final stage: ResultStage 13 (summary at cmd19.sc:1)\n",
      "21/06/10 02:20:50 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 12)\n",
      "21/06/10 02:20:50 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 12)\n",
      "21/06/10 02:20:50 INFO DAGScheduler: Submitting ShuffleMapStage 12 (MapPartitionsRDD[55] at summary at cmd19.sc:1), which has no missing parents\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "  <span style=\"float: left;\">summary at cmd19.sc:1</span>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"progress\">\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: blue; width: 100%; word-wrap: normal; white-space: nowrap; text-align: center; color: white\" aria-valuenow=\"100\" aria-valuemin=\"0\" aria-valuemax=\"100\">\n",
       "    1 / 1\n",
       "  </div>\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: red; width: 0%\" aria-valuenow=\"0\" aria-valuemin=\"0\" aria-valuemax=\"100\"></div>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/06/10 02:20:50 INFO MemoryStore: Block broadcast_24 stored as values in memory (estimated size 42.5 KB, free 1001.8 MB)\n",
      "21/06/10 02:20:50 INFO MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 16.6 KB, free 1001.8 MB)\n",
      "21/06/10 02:20:50 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on 192.168.15.53:46349 (size: 16.6 KB, free: 1002.0 MB)\n",
      "21/06/10 02:20:50 INFO SparkContext: Created broadcast 24 from broadcast at DAGScheduler.scala:1161\n",
      "21/06/10 02:20:50 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 12 (MapPartitionsRDD[55] at summary at cmd19.sc:1) (first 15 tasks are for partitions Vector(0))\n",
      "21/06/10 02:20:50 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks\n",
      "21/06/10 02:20:50 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 12, localhost, executor driver, partition 0, PROCESS_LOCAL, 7794 bytes)\n",
      "21/06/10 02:20:50 INFO Executor: Running task 0.0 in stage 12.0 (TID 12)\n",
      "21/06/10 02:20:50 INFO FileScanRDD: Reading File path: file:///home/yoichiro/develop/analysis/data/econ/clustering/country_data.csv, range: 0-9229, partition values: [empty row]\n",
      "21/06/10 02:20:50 INFO Executor: Finished task 0.0 in stage 12.0 (TID 12). 1800 bytes result sent to driver\n",
      "21/06/10 02:20:50 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 12) in 180 ms on localhost (executor driver) (1/1)\n",
      "21/06/10 02:20:50 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool \n",
      "21/06/10 02:20:50 INFO DAGScheduler: ShuffleMapStage 12 (summary at cmd19.sc:1) finished in 0.199 s\n",
      "21/06/10 02:20:50 INFO DAGScheduler: looking for newly runnable stages\n",
      "21/06/10 02:20:50 INFO DAGScheduler: running: Set()\n",
      "21/06/10 02:20:50 INFO DAGScheduler: waiting: Set(ResultStage 13)\n",
      "21/06/10 02:20:50 INFO DAGScheduler: failed: Set()\n",
      "21/06/10 02:20:50 INFO DAGScheduler: Submitting ResultStage 13 (MapPartitionsRDD[57] at summary at cmd19.sc:1), which has no missing parents\n",
      "21/06/10 02:20:50 INFO MemoryStore: Block broadcast_25 stored as values in memory (estimated size 57.0 KB, free 1001.7 MB)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "  <span style=\"float: left;\">summary at cmd19.sc:1</span>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"progress\">\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: blue; width: 100%; word-wrap: normal; white-space: nowrap; text-align: center; color: white\" aria-valuenow=\"100\" aria-valuemin=\"0\" aria-valuemax=\"100\">\n",
       "    1 / 1\n",
       "  </div>\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: red; width: 0%\" aria-valuenow=\"0\" aria-valuemin=\"0\" aria-valuemax=\"100\"></div>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/06/10 02:20:50 INFO MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 20.2 KB, free 1001.7 MB)\n",
      "21/06/10 02:20:50 INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on 192.168.15.53:46349 (size: 20.2 KB, free: 1001.9 MB)\n",
      "21/06/10 02:20:50 INFO SparkContext: Created broadcast 25 from broadcast at DAGScheduler.scala:1161\n",
      "21/06/10 02:20:50 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 13 (MapPartitionsRDD[57] at summary at cmd19.sc:1) (first 15 tasks are for partitions Vector(0))\n",
      "21/06/10 02:20:50 INFO TaskSchedulerImpl: Adding task set 13.0 with 1 tasks\n",
      "21/06/10 02:20:50 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 13, localhost, executor driver, partition 0, ANY, 7246 bytes)\n",
      "21/06/10 02:20:50 INFO Executor: Running task 0.0 in stage 13.0 (TID 13)\n",
      "21/06/10 02:20:50 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks\n",
      "21/06/10 02:20:50 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms\n",
      "21/06/10 02:20:50 INFO Executor: Finished task 0.0 in stage 13.0 (TID 13). 3705 bytes result sent to driver\n",
      "21/06/10 02:20:50 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 13) in 147 ms on localhost (executor driver) (1/1)\n",
      "21/06/10 02:20:50 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool \n",
      "21/06/10 02:20:50 INFO DAGScheduler: ResultStage 13 (summary at cmd19.sc:1) finished in 0.157 s\n",
      "21/06/10 02:20:50 INFO DAGScheduler: Job 9 finished: summary at cmd19.sc:1, took 0.361811 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       " <table>\n",
       "                <tr>\n",
       "                 <th>summary</th><th>country</th><th>child_mort</th><th>exports</th><th>health</th><th>imports</th><th>income</th><th>inflation</th><th>life_expec</th><th>total_fer</th><th>gdpp</th>\n",
       "                </tr>\n",
       "                <tr><td>count</td><td>167</td><td>167</td><td>167</td><td>167</td><td>167</td><td>167</td><td>167</td><td>167</td><td>167</td><td>167</td></tr><tr><td>mean</td><td>null</td><td>38.270059880239515</td><td>41.1089760479042</td><td>6.815688622754495</td><td>46.89021497005987</td><td>17144.688622754493</td><td>7.781832335329342</td><td>70.55568862275449</td><td>2.9479640718562874</td><td>12964.155688622754</td></tr><tr><td>stddev</td><td>null</td><td>40.32893145927617</td><td>27.41201011142416</td><td>2.7468374978890795</td><td>24.209588976108698</td><td>19278.06769765768</td><td>10.570703901430559</td><td>8.893171908900404</td><td>1.5138475432630467</td><td>18328.704808675564</td></tr><tr><td>min</td><td>Afghanistan</td><td>10</td><td>0.109</td><td>1.81</td><td>0.0659</td><td>1030</td><td>-0.046</td><td>32.1</td><td>1.15</td><td>1000</td></tr><tr><td>25%</td><td>null</td><td>7.9</td><td>23.8</td><td>4.91</td><td>30.0</td><td>3340.0</td><td>1.77</td><td>65.3</td><td>1.79</td><td>1310.0</td></tr><tr><td>50%</td><td>null</td><td>19.3</td><td>35.0</td><td>6.32</td><td>43.3</td><td>9960.0</td><td>5.39</td><td>73.1</td><td>2.41</td><td>4660.0</td></tr><tr><td>75%</td><td>null</td><td>62.2</td><td>51.4</td><td>8.65</td><td>58.9</td><td>22900.0</td><td>10.9</td><td>76.8</td><td>3.91</td><td>14600.0</td></tr><tr><td>max</td><td>Zambia</td><td>99.7</td><td>93.8</td><td>9.64</td><td>92.6</td><td>9960</td><td>9.81</td><td>82.8</td><td>7.49</td><td>988</td></tr>\n",
       "            </table>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.summary().showHTML()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "81cd4995",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createGlobalTempView(\"tmp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "af2fb57d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mres42\u001b[39m: \u001b[32mArray\u001b[39m[(\u001b[32mString\u001b[39m, \u001b[32mString\u001b[39m)] = \u001b[33mArray\u001b[39m(\n",
       "  (\u001b[32m\"country\"\u001b[39m, \u001b[32m\"StringType\"\u001b[39m),\n",
       "  (\u001b[32m\"child_mort\"\u001b[39m, \u001b[32m\"DoubleType\"\u001b[39m),\n",
       "  (\u001b[32m\"exports\"\u001b[39m, \u001b[32m\"DoubleType\"\u001b[39m),\n",
       "  (\u001b[32m\"health\"\u001b[39m, \u001b[32m\"DoubleType\"\u001b[39m),\n",
       "  (\u001b[32m\"imports\"\u001b[39m, \u001b[32m\"DoubleType\"\u001b[39m),\n",
       "  (\u001b[32m\"income\"\u001b[39m, \u001b[32m\"IntegerType\"\u001b[39m),\n",
       "  (\u001b[32m\"inflation\"\u001b[39m, \u001b[32m\"DoubleType\"\u001b[39m),\n",
       "  (\u001b[32m\"life_expec\"\u001b[39m, \u001b[32m\"DoubleType\"\u001b[39m),\n",
       "  (\u001b[32m\"total_fer\"\u001b[39m, \u001b[32m\"DoubleType\"\u001b[39m),\n",
       "  (\u001b[32m\"gdpp\"\u001b[39m, \u001b[32m\"IntegerType\"\u001b[39m)\n",
       ")"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "aa3677e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/06/10 02:41:34 INFO FileSourceStrategy: Pruning directories with: \n",
      "21/06/10 02:41:34 INFO FileSourceStrategy: Post-Scan Filters: \n",
      "21/06/10 02:41:34 INFO FileSourceStrategy: Output Data Schema: struct<>\n",
      "21/06/10 02:41:34 INFO FileSourceScanExec: Pushed Filters: \n",
      "21/06/10 02:41:34 INFO CodeGenerator: Code generated in 9.4525 ms\n",
      "21/06/10 02:41:34 INFO MemoryStore: Block broadcast_60 stored as values in memory (estimated size 176.9 KB, free 1001.7 MB)\n",
      "21/06/10 02:41:34 INFO MemoryStore: Block broadcast_60_piece0 stored as bytes in memory (estimated size 23.2 KB, free 1001.7 MB)\n",
      "21/06/10 02:41:34 INFO BlockManagerInfo: Added broadcast_60_piece0 in memory on 192.168.15.53:46349 (size: 23.2 KB, free: 1002.0 MB)\n",
      "21/06/10 02:41:34 INFO SparkContext: Created broadcast 60 from count at cmd43.sc:2\n",
      "21/06/10 02:41:34 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "21/06/10 02:41:34 INFO SparkContext: Starting job: count at cmd43.sc:2\n",
      "21/06/10 02:41:34 INFO DAGScheduler: Registering RDD 134 (count at cmd43.sc:2)\n",
      "21/06/10 02:41:34 INFO DAGScheduler: Got job 26 (count at cmd43.sc:2) with 1 output partitions\n",
      "21/06/10 02:41:34 INFO DAGScheduler: Final stage: ResultStage 32 (count at cmd43.sc:2)\n",
      "21/06/10 02:41:34 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 31)\n",
      "21/06/10 02:41:34 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 31)\n",
      "21/06/10 02:41:34 INFO DAGScheduler: Submitting ShuffleMapStage 31 (MapPartitionsRDD[134] at count at cmd43.sc:2), which has no missing parents\n",
      "21/06/10 02:41:34 INFO MemoryStore: Block broadcast_61 stored as values in memory (estimated size 13.8 KB, free 1001.6 MB)\n",
      "21/06/10 02:41:34 INFO MemoryStore: Block broadcast_61_piece0 stored as bytes in memory (estimated size 7.2 KB, free 1001.6 MB)\n",
      "21/06/10 02:41:34 INFO BlockManagerInfo: Added broadcast_61_piece0 in memory on 192.168.15.53:46349 (size: 7.2 KB, free: 1001.9 MB)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "  <span style=\"float: left;\">count at cmd43.sc:2</span>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"progress\">\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: blue; width: 100%; word-wrap: normal; white-space: nowrap; text-align: center; color: white\" aria-valuenow=\"100\" aria-valuemin=\"0\" aria-valuemax=\"100\">\n",
       "    1 / 1\n",
       "  </div>\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: red; width: 0%\" aria-valuenow=\"0\" aria-valuemin=\"0\" aria-valuemax=\"100\"></div>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/06/10 02:41:34 INFO SparkContext: Created broadcast 61 from broadcast at DAGScheduler.scala:1161\n",
      "21/06/10 02:41:34 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 31 (MapPartitionsRDD[134] at count at cmd43.sc:2) (first 15 tasks are for partitions Vector(0))\n",
      "21/06/10 02:41:34 INFO TaskSchedulerImpl: Adding task set 31.0 with 1 tasks\n",
      "21/06/10 02:41:34 INFO TaskSetManager: Starting task 0.0 in stage 31.0 (TID 33, localhost, executor driver, partition 0, PROCESS_LOCAL, 7794 bytes)\n",
      "21/06/10 02:41:34 INFO Executor: Running task 0.0 in stage 31.0 (TID 33)\n",
      "21/06/10 02:41:34 INFO FileScanRDD: Reading File path: file:///home/yoichiro/develop/analysis/data/econ/clustering/country_data.csv, range: 0-9229, partition values: [empty row]\n",
      "21/06/10 02:41:34 INFO Executor: Finished task 0.0 in stage 31.0 (TID 33). 1599 bytes result sent to driver\n",
      "21/06/10 02:41:34 INFO TaskSetManager: Finished task 0.0 in stage 31.0 (TID 33) in 44 ms on localhost (executor driver) (1/1)\n",
      "21/06/10 02:41:34 INFO TaskSchedulerImpl: Removed TaskSet 31.0, whose tasks have all completed, from pool \n",
      "21/06/10 02:41:34 INFO DAGScheduler: ShuffleMapStage 31 (count at cmd43.sc:2) finished in 0.052 s\n",
      "21/06/10 02:41:34 INFO DAGScheduler: looking for newly runnable stages\n",
      "21/06/10 02:41:34 INFO DAGScheduler: running: Set()\n",
      "21/06/10 02:41:34 INFO DAGScheduler: waiting: Set(ResultStage 32)\n",
      "21/06/10 02:41:34 INFO DAGScheduler: failed: Set()\n",
      "21/06/10 02:41:34 INFO DAGScheduler: Submitting ResultStage 32 (MapPartitionsRDD[137] at count at cmd43.sc:2), which has no missing parents\n",
      "21/06/10 02:41:34 INFO MemoryStore: Block broadcast_62 stored as values in memory (estimated size 8.5 KB, free 1001.6 MB)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "  <span style=\"float: left;\">count at cmd43.sc:2</span>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"progress\">\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: blue; width: 100%; word-wrap: normal; white-space: nowrap; text-align: center; color: white\" aria-valuenow=\"100\" aria-valuemin=\"0\" aria-valuemax=\"100\">\n",
       "    1 / 1\n",
       "  </div>\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: red; width: 0%\" aria-valuenow=\"0\" aria-valuemin=\"0\" aria-valuemax=\"100\"></div>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/06/10 02:41:34 INFO MemoryStore: Block broadcast_62_piece0 stored as bytes in memory (estimated size 4.4 KB, free 1001.6 MB)\n",
      "21/06/10 02:41:34 INFO BlockManagerInfo: Added broadcast_62_piece0 in memory on 192.168.15.53:46349 (size: 4.4 KB, free: 1001.9 MB)\n",
      "21/06/10 02:41:34 INFO SparkContext: Created broadcast 62 from broadcast at DAGScheduler.scala:1161\n",
      "21/06/10 02:41:34 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 32 (MapPartitionsRDD[137] at count at cmd43.sc:2) (first 15 tasks are for partitions Vector(0))\n",
      "21/06/10 02:41:34 INFO TaskSchedulerImpl: Adding task set 32.0 with 1 tasks\n",
      "21/06/10 02:41:34 INFO TaskSetManager: Starting task 0.0 in stage 32.0 (TID 34, localhost, executor driver, partition 0, ANY, 7246 bytes)\n",
      "21/06/10 02:41:34 INFO Executor: Running task 0.0 in stage 32.0 (TID 34)\n",
      "21/06/10 02:41:34 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks\n",
      "21/06/10 02:41:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "21/06/10 02:41:34 INFO Executor: Finished task 0.0 in stage 32.0 (TID 34). 1749 bytes result sent to driver\n",
      "21/06/10 02:41:34 INFO TaskSetManager: Finished task 0.0 in stage 32.0 (TID 34) in 12 ms on localhost (executor driver) (1/1)\n",
      "21/06/10 02:41:34 INFO TaskSchedulerImpl: Removed TaskSet 32.0, whose tasks have all completed, from pool \n",
      "21/06/10 02:41:34 INFO DAGScheduler: ResultStage 32 (count at cmd43.sc:2) finished in 0.023 s\n",
      "21/06/10 02:41:34 INFO DAGScheduler: Job 26 finished: count at cmd43.sc:2, took 0.081009 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mres43_1\u001b[39m: \u001b[32mLong\u001b[39m = \u001b[32m167L\u001b[39m"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.createTempView(\"country_table\")\n",
    "spark.sql(\" SELECT * FROM country_table\").count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7c42ba41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.sql._\n",
       "\u001b[39m\n",
       "defined \u001b[32mclass\u001b[39m \u001b[36mData\u001b[39m\n",
       "\u001b[36mcolumns\u001b[39m: \u001b[32mSeq\u001b[39m[\u001b[32mString\u001b[39m] = \u001b[33mList\u001b[39m(\u001b[32m\"language\"\u001b[39m, \u001b[32m\"users_count\"\u001b[39m, \u001b[32m\"extremely_long_string\"\u001b[39m)\n",
       "\u001b[36mdata\u001b[39m: \u001b[32mSeq\u001b[39m[(\u001b[32mData\u001b[39m, \u001b[32mData\u001b[39m, \u001b[32mData\u001b[39m)] = \u001b[33mList\u001b[39m(\n",
       "  (\u001b[33mData\u001b[39m(\u001b[32m\"java\"\u001b[39m), \u001b[33mData\u001b[39m(\u001b[32m\"20000\"\u001b[39m), \u001b[33mData\u001b[39m(\u001b[32m\"short text\"\u001b[39m)),\n",
       "  (\u001b[33mData\u001b[39m(\u001b[32m\"python\"\u001b[39m), \u001b[33mData\u001b[39m(\u001b[32m\"1000000\"\u001b[39m), \u001b[33mData\u001b[39m(\u001b[32m\"medium text\"\u001b[39m))\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "case class Data(value: String)\n",
    "val columns = Seq(\"language\",\"users_count\",\"extremely_long_string\")\n",
    "val data = Seq(\n",
    "    (Data(\"java\"),Data(\"20000\"),Data(\"short text\")),\n",
    "    (Data(\"python\"),Data(\"1000000\"),Data(\"medium text\"))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2266ebfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mrdd\u001b[39m: \u001b[32morg\u001b[39m.\u001b[32mapache\u001b[39m.\u001b[32mspark\u001b[39m.\u001b[32mrdd\u001b[39m.\u001b[32mRDD\u001b[39m[(\u001b[32mData\u001b[39m, \u001b[32mData\u001b[39m, \u001b[32mData\u001b[39m)] = ParallelCollectionRDD[6] at parallelize at cmd28.sc:1"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val rdd= spark.sparkContext.parallelize(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ea4a2970",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36mspark.implicits._\n",
       "\u001b[39m"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spark.implicits._\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2f48fd3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/04/03 03:32:50 INFO CodeGenerator: Code generated in 475.6251 ms\n",
      "21/04/03 03:32:50 INFO CodeGenerator: Code generated in 130.8659 ms\n",
      "21/04/03 03:32:50 INFO SparkContext: Starting job: show at cmd30.sc:2\n",
      "21/04/03 03:32:50 INFO DAGScheduler: Got job 0 (show at cmd30.sc:2) with 1 output partitions\n",
      "21/04/03 03:32:50 INFO DAGScheduler: Final stage: ResultStage 0 (show at cmd30.sc:2)\n",
      "21/04/03 03:32:50 INFO DAGScheduler: Parents of final stage: List()\n",
      "21/04/03 03:32:50 INFO DAGScheduler: Missing parents: List()\n",
      "21/04/03 03:32:50 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[10] at show at cmd30.sc:2), which has no missing parents\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<script>\n",
       "var comm = Jupyter.notebook.kernel.comm_manager.new_comm('cancel-stage-5c3ce9a4-79d1-470a-97ba-d7082472020f', {});\n",
       "\n",
       "function cancelStage(stageId) {\n",
       "  console.log('Cancelling stage ' + stageId);\n",
       "  comm.send({ 'stageId': stageId });\n",
       "}\n",
       "</script>\n",
       "          "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "  <span style=\"float: left;\">show at cmd30.sc:2</span>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"progress\">\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: blue; width: 100%; word-wrap: normal; white-space: nowrap; text-align: center; color: white\" aria-valuenow=\"100\" aria-valuemin=\"0\" aria-valuemax=\"100\">\n",
       "    1 / 1\n",
       "  </div>\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: red; width: 0%\" aria-valuenow=\"0\" aria-valuemin=\"0\" aria-valuemax=\"100\"></div>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<script>\n",
       "var comm = Jupyter.notebook.kernel.comm_manager.new_comm('cancel-stage-c6a1ddd4-217c-4d75-9032-e90f9340d6a8', {});\n",
       "\n",
       "function cancelStage(stageId) {\n",
       "  console.log('Cancelling stage ' + stageId);\n",
       "  comm.send({ 'stageId': stageId });\n",
       "}\n",
       "</script>\n",
       "          "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "  <span style=\"float: left;\">show at cmd30.sc:2</span>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"progress\">\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: blue; width: 100%; word-wrap: normal; white-space: nowrap; text-align: center; color: white\" aria-valuenow=\"100\" aria-valuemin=\"0\" aria-valuemax=\"100\">\n",
       "    1 / 1\n",
       "  </div>\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: red; width: 0%\" aria-valuenow=\"0\" aria-valuemin=\"0\" aria-valuemax=\"100\"></div>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<script>\n",
       "var comm = Jupyter.notebook.kernel.comm_manager.new_comm('cancel-stage-1aab1fbd-bc84-4643-92bc-2148c5b5cef8', {});\n",
       "\n",
       "function cancelStage(stageId) {\n",
       "  console.log('Cancelling stage ' + stageId);\n",
       "  comm.send({ 'stageId': stageId });\n",
       "}\n",
       "</script>\n",
       "          "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "  <span style=\"float: left;\">show at cmd30.sc:2</span>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"progress\">\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: blue; width: 100%; word-wrap: normal; white-space: nowrap; text-align: center; color: white\" aria-valuenow=\"100\" aria-valuemin=\"0\" aria-valuemax=\"100\">\n",
       "    1 / 1\n",
       "  </div>\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: red; width: 0%\" aria-valuenow=\"0\" aria-valuemin=\"0\" aria-valuemax=\"100\"></div>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<script>\n",
       "var comm = Jupyter.notebook.kernel.comm_manager.new_comm('cancel-stage-a2ccaa6f-969b-4ba2-803e-e0770e0aaf8e', {});\n",
       "\n",
       "function cancelStage(stageId) {\n",
       "  console.log('Cancelling stage ' + stageId);\n",
       "  comm.send({ 'stageId': stageId });\n",
       "}\n",
       "</script>\n",
       "          "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "  <span style=\"float: left;\">show at cmd30.sc:2</span>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"progress\">\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: blue; width: 100%; word-wrap: normal; white-space: nowrap; text-align: center; color: white\" aria-valuenow=\"100\" aria-valuemin=\"0\" aria-valuemax=\"100\">\n",
       "    1 / 1\n",
       "  </div>\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: red; width: 0%\" aria-valuenow=\"0\" aria-valuemin=\"0\" aria-valuemax=\"100\"></div>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/04/03 03:32:50 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 21.6 KB, free 1719.6 MB)\n",
      "21/04/03 03:32:50 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 6.8 KB, free 1719.6 MB)\n",
      "21/04/03 03:32:50 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.23.191.244:37033 (size: 6.8 KB, free: 1719.6 MB)\n",
      "21/04/03 03:32:51 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1161\n",
      "21/04/03 03:32:51 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[10] at show at cmd30.sc:2) (first 15 tasks are for partitions Vector(0))\n",
      "21/04/03 03:32:51 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks\n",
      "21/04/03 03:32:51 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 7315 bytes)\n",
      "21/04/03 03:32:51 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)\n",
      "21/04/03 03:32:51 INFO Executor: Fetching spark://172.23.191.244:35459/jars/ammonite-repl-api_2.12.12-2.3.8-36-1cce53f3.jar with timestamp 1617387609755\n",
      "21/04/03 03:32:51 INFO TransportClientFactory: Successfully created connection to /172.23.191.244:35459 after 92 ms (0 ms spent in bootstraps)\n",
      "21/04/03 03:32:51 INFO Utils: Fetching spark://172.23.191.244:35459/jars/ammonite-repl-api_2.12.12-2.3.8-36-1cce53f3.jar to /tmp/spark-3b36f2b5-0161-4093-a4b1-a5a84b889935/userFiles-cf106a32-aa21-4539-9d94-7dd159511573/fetchFileTemp8681802780683659832.tmp\n",
      "21/04/03 03:32:51 INFO Executor: Adding file:/tmp/spark-3b36f2b5-0161-4093-a4b1-a5a84b889935/userFiles-cf106a32-aa21-4539-9d94-7dd159511573/ammonite-repl-api_2.12.12-2.3.8-36-1cce53f3.jar to class loader\n",
      "21/04/03 03:32:51 INFO Executor: Fetching spark://172.23.191.244:35459/jars/interpreter-api_2.12-0.11.1-sources.jar with timestamp 1617387609792\n",
      "21/04/03 03:32:51 INFO Utils: Fetching spark://172.23.191.244:35459/jars/interpreter-api_2.12-0.11.1-sources.jar to /tmp/spark-3b36f2b5-0161-4093-a4b1-a5a84b889935/userFiles-cf106a32-aa21-4539-9d94-7dd159511573/fetchFileTemp14770049719014648211.tmp\n",
      "21/04/03 03:32:51 INFO Executor: Adding file:/tmp/spark-3b36f2b5-0161-4093-a4b1-a5a84b889935/userFiles-cf106a32-aa21-4539-9d94-7dd159511573/interpreter-api_2.12-0.11.1-sources.jar to class loader\n",
      "21/04/03 03:32:51 INFO Executor: Fetching spark://172.23.191.244:35459/jars/geny_2.12-0.6.5.jar with timestamp 1617387609766\n",
      "21/04/03 03:32:51 INFO Utils: Fetching spark://172.23.191.244:35459/jars/geny_2.12-0.6.5.jar to /tmp/spark-3b36f2b5-0161-4093-a4b1-a5a84b889935/userFiles-cf106a32-aa21-4539-9d94-7dd159511573/fetchFileTemp17928816408171453860.tmp\n",
      "21/04/03 03:32:51 INFO Executor: Adding file:/tmp/spark-3b36f2b5-0161-4093-a4b1-a5a84b889935/userFiles-cf106a32-aa21-4539-9d94-7dd159511573/geny_2.12-0.6.5.jar to class loader\n",
      "21/04/03 03:32:51 INFO Executor: Fetching spark://172.23.191.244:35459/jars/scala-xml_2.12-2.0.0-M3.jar with timestamp 1617387609787\n",
      "21/04/03 03:32:51 INFO Utils: Fetching spark://172.23.191.244:35459/jars/scala-xml_2.12-2.0.0-M3.jar to /tmp/spark-3b36f2b5-0161-4093-a4b1-a5a84b889935/userFiles-cf106a32-aa21-4539-9d94-7dd159511573/fetchFileTemp13949880029575547667.tmp\n",
      "21/04/03 03:32:51 INFO Executor: Adding file:/tmp/spark-3b36f2b5-0161-4093-a4b1-a5a84b889935/userFiles-cf106a32-aa21-4539-9d94-7dd159511573/scala-xml_2.12-2.0.0-M3.jar to class loader\n",
      "21/04/03 03:32:51 INFO Executor: Fetching spark://172.23.191.244:35459/jars/fansi_2.12-0.2.9.jar with timestamp 1617387609763\n",
      "21/04/03 03:32:51 INFO Utils: Fetching spark://172.23.191.244:35459/jars/fansi_2.12-0.2.9.jar to /tmp/spark-3b36f2b5-0161-4093-a4b1-a5a84b889935/userFiles-cf106a32-aa21-4539-9d94-7dd159511573/fetchFileTemp14475930052100338425.tmp\n",
      "21/04/03 03:32:51 INFO Executor: Adding file:/tmp/spark-3b36f2b5-0161-4093-a4b1-a5a84b889935/userFiles-cf106a32-aa21-4539-9d94-7dd159511573/fansi_2.12-0.2.9.jar to class loader\n",
      "21/04/03 03:32:51 INFO Executor: Fetching spark://172.23.191.244:35459/jars/javaparser-core-3.2.5.jar with timestamp 1617387609750\n",
      "21/04/03 03:32:51 INFO Utils: Fetching spark://172.23.191.244:35459/jars/javaparser-core-3.2.5.jar to /tmp/spark-3b36f2b5-0161-4093-a4b1-a5a84b889935/userFiles-cf106a32-aa21-4539-9d94-7dd159511573/fetchFileTemp15265757487271479985.tmp\n",
      "21/04/03 03:32:51 INFO Executor: Adding file:/tmp/spark-3b36f2b5-0161-4093-a4b1-a5a84b889935/userFiles-cf106a32-aa21-4539-9d94-7dd159511573/javaparser-core-3.2.5.jar to class loader\n",
      "21/04/03 03:32:51 INFO Executor: Fetching spark://172.23.191.244:35459/jars/fastparse_2.12-2.3.0-sources.jar with timestamp 1617387609764\n",
      "21/04/03 03:32:51 INFO Utils: Fetching spark://172.23.191.244:35459/jars/fastparse_2.12-2.3.0-sources.jar to /tmp/spark-3b36f2b5-0161-4093-a4b1-a5a84b889935/userFiles-cf106a32-aa21-4539-9d94-7dd159511573/fetchFileTemp11805635331723696444.tmp\n",
      "21/04/03 03:32:51 INFO Executor: Adding file:/tmp/spark-3b36f2b5-0161-4093-a4b1-a5a84b889935/userFiles-cf106a32-aa21-4539-9d94-7dd159511573/fastparse_2.12-2.3.0-sources.jar to class loader\n",
      "21/04/03 03:32:51 INFO Executor: Fetching spark://172.23.191.244:35459/jars/jvm-repr-0.4.0-sources.jar with timestamp 1617387609747\n",
      "21/04/03 03:32:51 INFO Utils: Fetching spark://172.23.191.244:35459/jars/jvm-repr-0.4.0-sources.jar to /tmp/spark-3b36f2b5-0161-4093-a4b1-a5a84b889935/userFiles-cf106a32-aa21-4539-9d94-7dd159511573/fetchFileTemp11716759475032645212.tmp\n",
      "21/04/03 03:32:52 INFO Executor: Adding file:/tmp/spark-3b36f2b5-0161-4093-a4b1-a5a84b889935/userFiles-cf106a32-aa21-4539-9d94-7dd159511573/jvm-repr-0.4.0-sources.jar to class loader\n",
      "21/04/03 03:32:52 INFO Executor: Fetching spark://172.23.191.244:35459/jars/os-lib_2.12-0.7.1.jar with timestamp 1617387609768\n",
      "21/04/03 03:32:52 INFO Utils: Fetching spark://172.23.191.244:35459/jars/os-lib_2.12-0.7.1.jar to /tmp/spark-3b36f2b5-0161-4093-a4b1-a5a84b889935/userFiles-cf106a32-aa21-4539-9d94-7dd159511573/fetchFileTemp9232658685469105085.tmp\n",
      "21/04/03 03:32:52 INFO Executor: Adding file:/tmp/spark-3b36f2b5-0161-4093-a4b1-a5a84b889935/userFiles-cf106a32-aa21-4539-9d94-7dd159511573/os-lib_2.12-0.7.1.jar to class loader\n",
      "21/04/03 03:32:52 INFO Executor: Fetching spark://172.23.191.244:35459/jars/interface-1.0.3.jar with timestamp 1617387609783\n",
      "21/04/03 03:32:52 INFO Utils: Fetching spark://172.23.191.244:35459/jars/interface-1.0.3.jar to /tmp/spark-3b36f2b5-0161-4093-a4b1-a5a84b889935/userFiles-cf106a32-aa21-4539-9d94-7dd159511573/fetchFileTemp10724753611019735250.tmp\n",
      "21/04/03 03:32:52 INFO Executor: Adding file:/tmp/spark-3b36f2b5-0161-4093-a4b1-a5a84b889935/userFiles-cf106a32-aa21-4539-9d94-7dd159511573/interface-1.0.3.jar to class loader\n",
      "21/04/03 03:32:52 INFO Executor: Fetching spark://172.23.191.244:35459/jars/jetty-http-8.2.0.v20160908.jar with timestamp 1617387609812\n",
      "21/04/03 03:32:52 INFO Utils: Fetching spark://172.23.191.244:35459/jars/jetty-http-8.2.0.v20160908.jar to /tmp/spark-3b36f2b5-0161-4093-a4b1-a5a84b889935/userFiles-cf106a32-aa21-4539-9d94-7dd159511573/fetchFileTemp17278011116981585957.tmp\n",
      "21/04/03 03:32:52 INFO Executor: Adding file:/tmp/spark-3b36f2b5-0161-4093-a4b1-a5a84b889935/userFiles-cf106a32-aa21-4539-9d94-7dd159511573/jetty-http-8.2.0.v20160908.jar to class loader\n",
      "21/04/03 03:32:52 INFO Executor: Fetching spark://172.23.191.244:35459/jars/sourcecode_2.12-0.2.3-sources.jar with timestamp 1617387609771\n",
      "21/04/03 03:32:52 INFO Utils: Fetching spark://172.23.191.244:35459/jars/sourcecode_2.12-0.2.3-sources.jar to /tmp/spark-3b36f2b5-0161-4093-a4b1-a5a84b889935/userFiles-cf106a32-aa21-4539-9d94-7dd159511573/fetchFileTemp2853105579990495815.tmp\n",
      "21/04/03 03:32:52 INFO Executor: Adding file:/tmp/spark-3b36f2b5-0161-4093-a4b1-a5a84b889935/userFiles-cf106a32-aa21-4539-9d94-7dd159511573/sourcecode_2.12-0.2.3-sources.jar to class loader\n",
      "21/04/03 03:32:52 INFO Executor: Fetching spark://172.23.191.244:35459/jars/os-lib_2.12-0.7.1-sources.jar with timestamp 1617387609768\n",
      "21/04/03 03:32:52 INFO Utils: Fetching spark://172.23.191.244:35459/jars/os-lib_2.12-0.7.1-sources.jar to /tmp/spark-3b36f2b5-0161-4093-a4b1-a5a84b889935/userFiles-cf106a32-aa21-4539-9d94-7dd159511573/fetchFileTemp17076323846018925582.tmp\n",
      "21/04/03 03:32:52 INFO Executor: Adding file:/tmp/spark-3b36f2b5-0161-4093-a4b1-a5a84b889935/userFiles-cf106a32-aa21-4539-9d94-7dd159511573/os-lib_2.12-0.7.1-sources.jar to class loader\n",
      "21/04/03 03:32:52 INFO Executor: Fetching spark://172.23.191.244:35459/jars/fastparse_2.12-2.3.0.jar with timestamp 1617387609765\n",
      "21/04/03 03:32:52 INFO Utils: Fetching spark://172.23.191.244:35459/jars/fastparse_2.12-2.3.0.jar to /tmp/spark-3b36f2b5-0161-4093-a4b1-a5a84b889935/userFiles-cf106a32-aa21-4539-9d94-7dd159511573/fetchFileTemp17966715994450907659.tmp\n",
      "21/04/03 03:32:52 INFO Executor: Adding file:/tmp/spark-3b36f2b5-0161-4093-a4b1-a5a84b889935/userFiles-cf106a32-aa21-4539-9d94-7dd159511573/fastparse_2.12-2.3.0.jar to class loader\n",
      "21/04/03 03:32:52 INFO Executor: Fetching spark://172.23.191.244:35459/jars/jupyter-api_2.12-0.11.1.jar with timestamp 1617387609799\n",
      "21/04/03 03:32:52 INFO Utils: Fetching spark://172.23.191.244:35459/jars/jupyter-api_2.12-0.11.1.jar to /tmp/spark-3b36f2b5-0161-4093-a4b1-a5a84b889935/userFiles-cf106a32-aa21-4539-9d94-7dd159511573/fetchFileTemp4864437472818302957.tmp\n",
      "21/04/03 03:32:52 INFO Executor: Adding file:/tmp/spark-3b36f2b5-0161-4093-a4b1-a5a84b889935/userFiles-cf106a32-aa21-4539-9d94-7dd159511573/jupyter-api_2.12-0.11.1.jar to class loader\n",
      "21/04/03 03:32:52 INFO Executor: Fetching spark://172.23.191.244:35459/jars/ammonite-ops_2.12-2.3.8-36-1cce53f3.jar with timestamp 1617387609754\n",
      "21/04/03 03:32:52 INFO Utils: Fetching spark://172.23.191.244:35459/jars/ammonite-ops_2.12-2.3.8-36-1cce53f3.jar to /tmp/spark-3b36f2b5-0161-4093-a4b1-a5a84b889935/userFiles-cf106a32-aa21-4539-9d94-7dd159511573/fetchFileTemp18112760281780284053.tmp\n",
      "21/04/03 03:32:52 INFO Executor: Adding file:/tmp/spark-3b36f2b5-0161-4093-a4b1-a5a84b889935/userFiles-cf106a32-aa21-4539-9d94-7dd159511573/ammonite-ops_2.12-2.3.8-36-1cce53f3.jar to class loader\n",
      "21/04/03 03:32:52 INFO Executor: Fetching spark://172.23.191.244:35459/jars/geny_2.12-0.6.5-sources.jar with timestamp 1617387609765\n",
      "21/04/03 03:32:52 INFO Utils: Fetching spark://172.23.191.244:35459/jars/geny_2.12-0.6.5-sources.jar to /tmp/spark-3b36f2b5-0161-4093-a4b1-a5a84b889935/userFiles-cf106a32-aa21-4539-9d94-7dd159511573/fetchFileTemp17417135691751935761.tmp\n",
      "21/04/03 03:32:52 INFO Executor: Adding file:/tmp/spark-3b36f2b5-0161-4093-a4b1-a5a84b889935/userFiles-cf106a32-aa21-4539-9d94-7dd159511573/geny_2.12-0.6.5-sources.jar to class loader\n",
      "21/04/03 03:32:52 INFO Executor: Fetching spark://172.23.191.244:35459/jars/almond-spark_2.12-0.3.0.jar with timestamp 1617387609802\n",
      "21/04/03 03:32:52 INFO Utils: Fetching spark://172.23.191.244:35459/jars/almond-spark_2.12-0.3.0.jar to /tmp/spark-3b36f2b5-0161-4093-a4b1-a5a84b889935/userFiles-cf106a32-aa21-4539-9d94-7dd159511573/fetchFileTemp4474024956311085093.tmp\n",
      "21/04/03 03:32:52 INFO Executor: Adding file:/tmp/spark-3b36f2b5-0161-4093-a4b1-a5a84b889935/userFiles-cf106a32-aa21-4539-9d94-7dd159511573/almond-spark_2.12-0.3.0.jar to class loader\n",
      "21/04/03 03:32:52 INFO Executor: Fetching spark://172.23.191.244:35459/jars/javaparser-core-3.2.5-sources.jar with timestamp 1617387609750\n",
      "21/04/03 03:32:52 INFO Utils: Fetching spark://172.23.191.244:35459/jars/javaparser-core-3.2.5-sources.jar to /tmp/spark-3b36f2b5-0161-4093-a4b1-a5a84b889935/userFiles-cf106a32-aa21-4539-9d94-7dd159511573/fetchFileTemp14935863088325984823.tmp\n",
      "21/04/03 03:32:52 INFO Executor: Adding file:/tmp/spark-3b36f2b5-0161-4093-a4b1-a5a84b889935/userFiles-cf106a32-aa21-4539-9d94-7dd159511573/javaparser-core-3.2.5-sources.jar to class loader\n",
      "21/04/03 03:32:52 INFO Executor: Fetching spark://172.23.191.244:35459/jars/ammonite-util_2.12-2.3.8-36-1cce53f3-sources.jar with timestamp 1617387609756\n",
      "21/04/03 03:32:52 INFO Utils: Fetching spark://172.23.191.244:35459/jars/ammonite-util_2.12-2.3.8-36-1cce53f3-sources.jar to /tmp/spark-3b36f2b5-0161-4093-a4b1-a5a84b889935/userFiles-cf106a32-aa21-4539-9d94-7dd159511573/fetchFileTemp9244978725013077786.tmp\n",
      "21/04/03 03:32:52 INFO Executor: Adding file:/tmp/spark-3b36f2b5-0161-4093-a4b1-a5a84b889935/userFiles-cf106a32-aa21-4539-9d94-7dd159511573/ammonite-util_2.12-2.3.8-36-1cce53f3-sources.jar to class loader\n",
      "21/04/03 03:32:52 INFO Executor: Fetching spark://172.23.191.244:35459/jars/scala-kernel-api_2.12.12-0.11.1.jar with timestamp 1617387609800\n",
      "21/04/03 03:32:52 INFO Utils: Fetching spark://172.23.191.244:35459/jars/scala-kernel-api_2.12.12-0.11.1.jar to /tmp/spark-3b36f2b5-0161-4093-a4b1-a5a84b889935/userFiles-cf106a32-aa21-4539-9d94-7dd159511573/fetchFileTemp2274346015610829819.tmp\n",
      "21/04/03 03:32:52 INFO Executor: Adding file:/tmp/spark-3b36f2b5-0161-4093-a4b1-a5a84b889935/userFiles-cf106a32-aa21-4539-9d94-7dd159511573/scala-kernel-api_2.12.12-0.11.1.jar to class loader\n",
      "21/04/03 03:32:52 INFO Executor: Fetching spark://172.23.191.244:35459/jars/pprint_2.12-0.6.0-sources.jar with timestamp 1617387609768\n",
      "21/04/03 03:32:52 INFO Utils: Fetching spark://172.23.191.244:35459/jars/pprint_2.12-0.6.0-sources.jar to /tmp/spark-3b36f2b5-0161-4093-a4b1-a5a84b889935/userFiles-cf106a32-aa21-4539-9d94-7dd159511573/fetchFileTemp2289501417955563906.tmp\n",
      "21/04/03 03:32:52 INFO Executor: Adding file:/tmp/spark-3b36f2b5-0161-4093-a4b1-a5a84b889935/userFiles-cf106a32-aa21-4539-9d94-7dd159511573/pprint_2.12-0.6.0-sources.jar to class loader\n",
      "21/04/03 03:32:52 INFO Executor: Fetching spark://172.23.191.244:35459/jars/scala-collection-compat_2.12-2.4.2.jar with timestamp 1617387609785\n",
      "21/04/03 03:32:52 INFO Utils: Fetching spark://172.23.191.244:35459/jars/scala-collection-compat_2.12-2.4.2.jar to /tmp/spark-3b36f2b5-0161-4093-a4b1-a5a84b889935/userFiles-cf106a32-aa21-4539-9d94-7dd159511573/fetchFileTemp16448790442316394556.tmp\n",
      "21/04/03 03:32:52 INFO Executor: Adding file:/tmp/spark-3b36f2b5-0161-4093-a4b1-a5a84b889935/userFiles-cf106a32-aa21-4539-9d94-7dd159511573/scala-collection-compat_2.12-2.4.2.jar to class loader\n",
      "21/04/03 03:32:52 INFO Executor: Fetching spark://172.23.191.244:35459/jars/interpreter-api_2.12-0.11.1.jar with timestamp 1617387609793\n",
      "21/04/03 03:32:52 INFO Utils: Fetching spark://172.23.191.244:35459/jars/interpreter-api_2.12-0.11.1.jar to /tmp/spark-3b36f2b5-0161-4093-a4b1-a5a84b889935/userFiles-cf106a32-aa21-4539-9d94-7dd159511573/fetchFileTemp14427965456054692410.tmp\n",
      "21/04/03 03:32:52 INFO Executor: Adding file:/tmp/spark-3b36f2b5-0161-4093-a4b1-a5a84b889935/userFiles-cf106a32-aa21-4539-9d94-7dd159511573/interpreter-api_2.12-0.11.1.jar to class loader\n",
      "21/04/03 03:32:52 INFO Executor: Fetching spark://172.23.191.244:35459/jars/ammonite-ops_2.12-2.3.8-36-1cce53f3-sources.jar with timestamp 1617387609753\n",
      "21/04/03 03:32:52 INFO Utils: Fetching spark://172.23.191.244:35459/jars/ammonite-ops_2.12-2.3.8-36-1cce53f3-sources.jar to /tmp/spark-3b36f2b5-0161-4093-a4b1-a5a84b889935/userFiles-cf106a32-aa21-4539-9d94-7dd159511573/fetchFileTemp16773057895109058935.tmp\n",
      "21/04/03 03:32:52 INFO Executor: Adding file:/tmp/spark-3b36f2b5-0161-4093-a4b1-a5a84b889935/userFiles-cf106a32-aa21-4539-9d94-7dd159511573/ammonite-ops_2.12-2.3.8-36-1cce53f3-sources.jar to class loader\n",
      "21/04/03 03:32:52 INFO Executor: Fetching spark://172.23.191.244:35459/jars/jvm-repr-0.4.0.jar with timestamp 1617387609749\n",
      "21/04/03 03:32:52 INFO Utils: Fetching spark://172.23.191.244:35459/jars/jvm-repr-0.4.0.jar to /tmp/spark-3b36f2b5-0161-4093-a4b1-a5a84b889935/userFiles-cf106a32-aa21-4539-9d94-7dd159511573/fetchFileTemp12888350954199542105.tmp\n",
      "21/04/03 03:32:52 INFO Executor: Adding file:/tmp/spark-3b36f2b5-0161-4093-a4b1-a5a84b889935/userFiles-cf106a32-aa21-4539-9d94-7dd159511573/jvm-repr-0.4.0.jar to class loader\n",
      "21/04/03 03:32:52 INFO Executor: Fetching spark://172.23.191.244:35459/jars/mainargs_2.12-0.1.4.jar with timestamp 1617387609767\n",
      "21/04/03 03:32:52 INFO Utils: Fetching spark://172.23.191.244:35459/jars/mainargs_2.12-0.1.4.jar to /tmp/spark-3b36f2b5-0161-4093-a4b1-a5a84b889935/userFiles-cf106a32-aa21-4539-9d94-7dd159511573/fetchFileTemp16547200263471051435.tmp\n",
      "21/04/03 03:32:52 INFO Executor: Adding file:/tmp/spark-3b36f2b5-0161-4093-a4b1-a5a84b889935/userFiles-cf106a32-aa21-4539-9d94-7dd159511573/mainargs_2.12-0.1.4.jar to class loader\n",
      "21/04/03 03:32:52 INFO Executor: Fetching spark://172.23.191.244:35459/jars/ammonite-spark_2.12-0.3.0.jar with timestamp 1617387609802\n",
      "21/04/03 03:32:52 INFO Utils: Fetching spark://172.23.191.244:35459/jars/ammonite-spark_2.12-0.3.0.jar to /tmp/spark-3b36f2b5-0161-4093-a4b1-a5a84b889935/userFiles-cf106a32-aa21-4539-9d94-7dd159511573/fetchFileTemp9151453462141537197.tmp\n",
      "21/04/03 03:32:52 INFO Executor: Adding file:/tmp/spark-3b36f2b5-0161-4093-a4b1-a5a84b889935/userFiles-cf106a32-aa21-4539-9d94-7dd159511573/ammonite-spark_2.12-0.3.0.jar to class loader\n",
      "21/04/03 03:32:52 INFO Executor: Fetching spark://172.23.191.244:35459/jars/scala-xml_2.12-2.0.0-M3-sources.jar with timestamp 1617387609786\n",
      "21/04/03 03:32:52 INFO Utils: Fetching spark://172.23.191.244:35459/jars/scala-xml_2.12-2.0.0-M3-sources.jar to /tmp/spark-3b36f2b5-0161-4093-a4b1-a5a84b889935/userFiles-cf106a32-aa21-4539-9d94-7dd159511573/fetchFileTemp7966691448027010358.tmp\n",
      "21/04/03 03:32:52 INFO Executor: Adding file:/tmp/spark-3b36f2b5-0161-4093-a4b1-a5a84b889935/userFiles-cf106a32-aa21-4539-9d94-7dd159511573/scala-xml_2.12-2.0.0-M3-sources.jar to class loader\n",
      "21/04/03 03:32:52 INFO Executor: Fetching spark://172.23.191.244:35459/jars/scala-collection-compat_2.12-2.4.2-sources.jar with timestamp 1617387609784\n",
      "21/04/03 03:32:52 INFO Utils: Fetching spark://172.23.191.244:35459/jars/scala-collection-compat_2.12-2.4.2-sources.jar to /tmp/spark-3b36f2b5-0161-4093-a4b1-a5a84b889935/userFiles-cf106a32-aa21-4539-9d94-7dd159511573/fetchFileTemp9952713083924211823.tmp\n",
      "21/04/03 03:32:52 INFO Executor: Adding file:/tmp/spark-3b36f2b5-0161-4093-a4b1-a5a84b889935/userFiles-cf106a32-aa21-4539-9d94-7dd159511573/scala-collection-compat_2.12-2.4.2-sources.jar to class loader\n",
      "21/04/03 03:32:52 INFO Executor: Fetching spark://172.23.191.244:35459/jars/scala-library-2.12.13.jar with timestamp 1617387609801\n",
      "21/04/03 03:32:52 INFO Utils: Fetching spark://172.23.191.244:35459/jars/scala-library-2.12.13.jar to /tmp/spark-3b36f2b5-0161-4093-a4b1-a5a84b889935/userFiles-cf106a32-aa21-4539-9d94-7dd159511573/fetchFileTemp6416506334895942404.tmp\n",
      "21/04/03 03:32:52 INFO Executor: Adding file:/tmp/spark-3b36f2b5-0161-4093-a4b1-a5a84b889935/userFiles-cf106a32-aa21-4539-9d94-7dd159511573/scala-library-2.12.13.jar to class loader\n",
      "21/04/03 03:32:52 INFO Executor: Fetching spark://172.23.191.244:35459/jars/scala-compiler-2.12.12-sources.jar with timestamp 1617387609787\n",
      "21/04/03 03:32:52 INFO Utils: Fetching spark://172.23.191.244:35459/jars/scala-compiler-2.12.12-sources.jar to /tmp/spark-3b36f2b5-0161-4093-a4b1-a5a84b889935/userFiles-cf106a32-aa21-4539-9d94-7dd159511573/fetchFileTemp15047839771627821985.tmp\n",
      "21/04/03 03:32:52 INFO Executor: Adding file:/tmp/spark-3b36f2b5-0161-4093-a4b1-a5a84b889935/userFiles-cf106a32-aa21-4539-9d94-7dd159511573/scala-compiler-2.12.12-sources.jar to class loader\n",
      "21/04/03 03:32:52 INFO Executor: Fetching spark://172.23.191.244:35459/jars/jetty-continuation-8.2.0.v20160908.jar with timestamp 1617387609806\n",
      "21/04/03 03:32:52 INFO Utils: Fetching spark://172.23.191.244:35459/jars/jetty-continuation-8.2.0.v20160908.jar to /tmp/spark-3b36f2b5-0161-4093-a4b1-a5a84b889935/userFiles-cf106a32-aa21-4539-9d94-7dd159511573/fetchFileTemp9252520528742512762.tmp\n",
      "21/04/03 03:32:52 INFO Executor: Adding file:/tmp/spark-3b36f2b5-0161-4093-a4b1-a5a84b889935/userFiles-cf106a32-aa21-4539-9d94-7dd159511573/jetty-continuation-8.2.0.v20160908.jar to class loader\n",
      "21/04/03 03:32:52 INFO Executor: Fetching spark://172.23.191.244:35459/jars/javassist-3.21.0-GA.jar with timestamp 1617387609784\n",
      "21/04/03 03:32:52 INFO Utils: Fetching spark://172.23.191.244:35459/jars/javassist-3.21.0-GA.jar to /tmp/spark-3b36f2b5-0161-4093-a4b1-a5a84b889935/userFiles-cf106a32-aa21-4539-9d94-7dd159511573/fetchFileTemp117271646111444388.tmp\n",
      "21/04/03 03:32:52 INFO Executor: Adding file:/tmp/spark-3b36f2b5-0161-4093-a4b1-a5a84b889935/userFiles-cf106a32-aa21-4539-9d94-7dd159511573/javassist-3.21.0-GA.jar to class loader\n",
      "21/04/03 03:32:52 INFO Executor: Fetching spark://172.23.191.244:35459/jars/sourcecode_2.12-0.2.3.jar with timestamp 1617387609778\n",
      "21/04/03 03:32:52 INFO Utils: Fetching spark://172.23.191.244:35459/jars/sourcecode_2.12-0.2.3.jar to /tmp/spark-3b36f2b5-0161-4093-a4b1-a5a84b889935/userFiles-cf106a32-aa21-4539-9d94-7dd159511573/fetchFileTemp12416556752810587678.tmp\n",
      "21/04/03 03:32:52 INFO Executor: Adding file:/tmp/spark-3b36f2b5-0161-4093-a4b1-a5a84b889935/userFiles-cf106a32-aa21-4539-9d94-7dd159511573/sourcecode_2.12-0.2.3.jar to class loader\n",
      "21/04/03 03:32:52 INFO Executor: Fetching spark://172.23.191.244:35459/jars/scalaparse_2.12-2.3.0-sources.jar with timestamp 1617387609769\n",
      "21/04/03 03:32:52 INFO Utils: Fetching spark://172.23.191.244:35459/jars/scalaparse_2.12-2.3.0-sources.jar to /tmp/spark-3b36f2b5-0161-4093-a4b1-a5a84b889935/userFiles-cf106a32-aa21-4539-9d94-7dd159511573/fetchFileTemp10099270027445798851.tmp\n",
      "21/04/03 03:32:52 INFO Executor: Adding file:/tmp/spark-3b36f2b5-0161-4093-a4b1-a5a84b889935/userFiles-cf106a32-aa21-4539-9d94-7dd159511573/scalaparse_2.12-2.3.0-sources.jar to class loader\n",
      "21/04/03 03:32:52 INFO Executor: Fetching spark://172.23.191.244:35459/jars/fansi_2.12-0.2.9-sources.jar with timestamp 1617387609762\n",
      "21/04/03 03:32:52 INFO Utils: Fetching spark://172.23.191.244:35459/jars/fansi_2.12-0.2.9-sources.jar to /tmp/spark-3b36f2b5-0161-4093-a4b1-a5a84b889935/userFiles-cf106a32-aa21-4539-9d94-7dd159511573/fetchFileTemp4987685052964795357.tmp\n",
      "21/04/03 03:32:52 INFO Executor: Adding file:/tmp/spark-3b36f2b5-0161-4093-a4b1-a5a84b889935/userFiles-cf106a32-aa21-4539-9d94-7dd159511573/fansi_2.12-0.2.9-sources.jar to class loader\n",
      "21/04/03 03:32:52 INFO Executor: Fetching spark://172.23.191.244:35459/jars/argonaut-shapeless_6.2_2.12-1.2.0-M9.jar with timestamp 1617387609803\n",
      "21/04/03 03:32:52 INFO Utils: Fetching spark://172.23.191.244:35459/jars/argonaut-shapeless_6.2_2.12-1.2.0-M9.jar to /tmp/spark-3b36f2b5-0161-4093-a4b1-a5a84b889935/userFiles-cf106a32-aa21-4539-9d94-7dd159511573/fetchFileTemp6741644752771742109.tmp\n",
      "21/04/03 03:32:52 INFO Executor: Adding file:/tmp/spark-3b36f2b5-0161-4093-a4b1-a5a84b889935/userFiles-cf106a32-aa21-4539-9d94-7dd159511573/argonaut-shapeless_6.2_2.12-1.2.0-M9.jar to class loader\n",
      "21/04/03 03:32:52 INFO Executor: Fetching spark://172.23.191.244:35459/jars/jupyter-api_2.12-0.11.1-sources.jar with timestamp 1617387609797\n",
      "21/04/03 03:32:52 INFO Utils: Fetching spark://172.23.191.244:35459/jars/jupyter-api_2.12-0.11.1-sources.jar to /tmp/spark-3b36f2b5-0161-4093-a4b1-a5a84b889935/userFiles-cf106a32-aa21-4539-9d94-7dd159511573/fetchFileTemp7016418419617518341.tmp\n",
      "21/04/03 03:32:52 INFO Executor: Adding file:/tmp/spark-3b36f2b5-0161-4093-a4b1-a5a84b889935/userFiles-cf106a32-aa21-4539-9d94-7dd159511573/jupyter-api_2.12-0.11.1-sources.jar to class loader\n",
      "21/04/03 03:32:52 INFO Executor: Fetching spark://172.23.191.244:35459/jars/interface-1.0.3-sources.jar with timestamp 1617387609782\n",
      "21/04/03 03:32:52 INFO Utils: Fetching spark://172.23.191.244:35459/jars/interface-1.0.3-sources.jar to /tmp/spark-3b36f2b5-0161-4093-a4b1-a5a84b889935/userFiles-cf106a32-aa21-4539-9d94-7dd159511573/fetchFileTemp8217720885668166196.tmp\n",
      "21/04/03 03:32:53 INFO Executor: Adding file:/tmp/spark-3b36f2b5-0161-4093-a4b1-a5a84b889935/userFiles-cf106a32-aa21-4539-9d94-7dd159511573/interface-1.0.3-sources.jar to class loader\n",
      "21/04/03 03:32:53 INFO Executor: Fetching spark://172.23.191.244:35459/jars/scalaparse_2.12-2.3.0.jar with timestamp 1617387609770\n",
      "21/04/03 03:32:53 INFO Utils: Fetching spark://172.23.191.244:35459/jars/scalaparse_2.12-2.3.0.jar to /tmp/spark-3b36f2b5-0161-4093-a4b1-a5a84b889935/userFiles-cf106a32-aa21-4539-9d94-7dd159511573/fetchFileTemp4584799080735667516.tmp\n",
      "21/04/03 03:32:53 INFO Executor: Adding file:/tmp/spark-3b36f2b5-0161-4093-a4b1-a5a84b889935/userFiles-cf106a32-aa21-4539-9d94-7dd159511573/scalaparse_2.12-2.3.0.jar to class loader\n",
      "21/04/03 03:32:53 INFO Executor: Fetching spark://172.23.191.244:35459/jars/scala-library-2.12.12-sources.jar with timestamp 1617387609788\n",
      "21/04/03 03:32:53 INFO Utils: Fetching spark://172.23.191.244:35459/jars/scala-library-2.12.12-sources.jar to /tmp/spark-3b36f2b5-0161-4093-a4b1-a5a84b889935/userFiles-cf106a32-aa21-4539-9d94-7dd159511573/fetchFileTemp10120469589294765777.tmp\n",
      "21/04/03 03:32:53 INFO Executor: Adding file:/tmp/spark-3b36f2b5-0161-4093-a4b1-a5a84b889935/userFiles-cf106a32-aa21-4539-9d94-7dd159511573/scala-library-2.12.12-sources.jar to class loader\n",
      "21/04/03 03:32:53 INFO Executor: Fetching spark://172.23.191.244:35459/jars/jetty-util-8.2.0.v20160908.jar with timestamp 1617387609816\n",
      "21/04/03 03:32:53 INFO Utils: Fetching spark://172.23.191.244:35459/jars/jetty-util-8.2.0.v20160908.jar to /tmp/spark-3b36f2b5-0161-4093-a4b1-a5a84b889935/userFiles-cf106a32-aa21-4539-9d94-7dd159511573/fetchFileTemp9456324380457947470.tmp\n",
      "21/04/03 03:32:53 INFO Executor: Adding file:/tmp/spark-3b36f2b5-0161-4093-a4b1-a5a84b889935/userFiles-cf106a32-aa21-4539-9d94-7dd159511573/jetty-util-8.2.0.v20160908.jar to class loader\n",
      "21/04/03 03:32:53 INFO Executor: Fetching spark://172.23.191.244:35459/jars/ammonite-interp-api_2.12.12-2.3.8-36-1cce53f3-sources.jar with timestamp 1617387609752\n",
      "21/04/03 03:32:53 INFO Utils: Fetching spark://172.23.191.244:35459/jars/ammonite-interp-api_2.12.12-2.3.8-36-1cce53f3-sources.jar to /tmp/spark-3b36f2b5-0161-4093-a4b1-a5a84b889935/userFiles-cf106a32-aa21-4539-9d94-7dd159511573/fetchFileTemp2590463219051370431.tmp\n",
      "21/04/03 03:32:53 INFO Executor: Adding file:/tmp/spark-3b36f2b5-0161-4093-a4b1-a5a84b889935/userFiles-cf106a32-aa21-4539-9d94-7dd159511573/ammonite-interp-api_2.12.12-2.3.8-36-1cce53f3-sources.jar to class loader\n",
      "21/04/03 03:32:53 INFO Executor: Fetching spark://172.23.191.244:35459/jars/ammonite-compiler-interface_2.12-2.3.8-36-1cce53f3.jar with timestamp 1617387609751\n",
      "21/04/03 03:32:53 INFO Utils: Fetching spark://172.23.191.244:35459/jars/ammonite-compiler-interface_2.12-2.3.8-36-1cce53f3.jar to /tmp/spark-3b36f2b5-0161-4093-a4b1-a5a84b889935/userFiles-cf106a32-aa21-4539-9d94-7dd159511573/fetchFileTemp7762859669158556566.tmp\n",
      "21/04/03 03:32:53 INFO Executor: Adding file:/tmp/spark-3b36f2b5-0161-4093-a4b1-a5a84b889935/userFiles-cf106a32-aa21-4539-9d94-7dd159511573/ammonite-compiler-interface_2.12-2.3.8-36-1cce53f3.jar to class loader\n",
      "21/04/03 03:32:53 INFO Executor: Fetching spark://172.23.191.244:35459/jars/javax.servlet-3.0.0.v201112011016.jar with timestamp 1617387609806\n",
      "21/04/03 03:32:53 INFO Utils: Fetching spark://172.23.191.244:35459/jars/javax.servlet-3.0.0.v201112011016.jar to /tmp/spark-3b36f2b5-0161-4093-a4b1-a5a84b889935/userFiles-cf106a32-aa21-4539-9d94-7dd159511573/fetchFileTemp10913526209154515171.tmp\n",
      "21/04/03 03:32:53 INFO Executor: Adding file:/tmp/spark-3b36f2b5-0161-4093-a4b1-a5a84b889935/userFiles-cf106a32-aa21-4539-9d94-7dd159511573/javax.servlet-3.0.0.v201112011016.jar to class loader\n",
      "21/04/03 03:32:53 INFO Executor: Fetching spark://172.23.191.244:35459/jars/macro-compat_2.12-1.1.1.jar with timestamp 1617387609813\n",
      "21/04/03 03:32:53 INFO Utils: Fetching spark://172.23.191.244:35459/jars/macro-compat_2.12-1.1.1.jar to /tmp/spark-3b36f2b5-0161-4093-a4b1-a5a84b889935/userFiles-cf106a32-aa21-4539-9d94-7dd159511573/fetchFileTemp7088711417739917134.tmp\n",
      "21/04/03 03:32:53 INFO Executor: Adding file:/tmp/spark-3b36f2b5-0161-4093-a4b1-a5a84b889935/userFiles-cf106a32-aa21-4539-9d94-7dd159511573/macro-compat_2.12-1.1.1.jar to class loader\n",
      "21/04/03 03:32:53 INFO Executor: Fetching spark://172.23.191.244:35459/jars/ammonite-compiler_2.12.12-2.3.8-36-1cce53f3-sources.jar with timestamp 1617387609751\n",
      "21/04/03 03:32:53 INFO Utils: Fetching spark://172.23.191.244:35459/jars/ammonite-compiler_2.12.12-2.3.8-36-1cce53f3-sources.jar to /tmp/spark-3b36f2b5-0161-4093-a4b1-a5a84b889935/userFiles-cf106a32-aa21-4539-9d94-7dd159511573/fetchFileTemp10977386387050910161.tmp\n",
      "21/04/03 03:32:53 INFO Executor: Adding file:/tmp/spark-3b36f2b5-0161-4093-a4b1-a5a84b889935/userFiles-cf106a32-aa21-4539-9d94-7dd159511573/ammonite-compiler_2.12.12-2.3.8-36-1cce53f3-sources.jar to class loader\n",
      "21/04/03 03:32:53 INFO Executor: Fetching spark://172.23.191.244:35459/jars/ammonite-compiler_2.12.12-2.3.8-36-1cce53f3.jar with timestamp 1617387609752\n",
      "21/04/03 03:32:53 INFO Utils: Fetching spark://172.23.191.244:35459/jars/ammonite-compiler_2.12.12-2.3.8-36-1cce53f3.jar to /tmp/spark-3b36f2b5-0161-4093-a4b1-a5a84b889935/userFiles-cf106a32-aa21-4539-9d94-7dd159511573/fetchFileTemp487531410749444094.tmp\n",
      "21/04/03 03:32:53 INFO Executor: Adding file:/tmp/spark-3b36f2b5-0161-4093-a4b1-a5a84b889935/userFiles-cf106a32-aa21-4539-9d94-7dd159511573/ammonite-compiler_2.12.12-2.3.8-36-1cce53f3.jar to class loader\n",
      "21/04/03 03:32:53 INFO Executor: Fetching spark://172.23.191.244:35459/jars/ammonite-interp-api_2.12.12-2.3.8-36-1cce53f3.jar with timestamp 1617387609753\n",
      "21/04/03 03:32:53 INFO Utils: Fetching spark://172.23.191.244:35459/jars/ammonite-interp-api_2.12.12-2.3.8-36-1cce53f3.jar to /tmp/spark-3b36f2b5-0161-4093-a4b1-a5a84b889935/userFiles-cf106a32-aa21-4539-9d94-7dd159511573/fetchFileTemp433632119774443457.tmp\n",
      "21/04/03 03:32:53 INFO Executor: Adding file:/tmp/spark-3b36f2b5-0161-4093-a4b1-a5a84b889935/userFiles-cf106a32-aa21-4539-9d94-7dd159511573/ammonite-interp-api_2.12.12-2.3.8-36-1cce53f3.jar to class loader\n",
      "21/04/03 03:32:53 INFO Executor: Fetching spark://172.23.191.244:35459/jars/jetty-server-8.2.0.v20160908.jar with timestamp 1617387609804\n",
      "21/04/03 03:32:53 INFO Utils: Fetching spark://172.23.191.244:35459/jars/jetty-server-8.2.0.v20160908.jar to /tmp/spark-3b36f2b5-0161-4093-a4b1-a5a84b889935/userFiles-cf106a32-aa21-4539-9d94-7dd159511573/fetchFileTemp12549622803058008912.tmp\n",
      "21/04/03 03:32:53 INFO Executor: Adding file:/tmp/spark-3b36f2b5-0161-4093-a4b1-a5a84b889935/userFiles-cf106a32-aa21-4539-9d94-7dd159511573/jetty-server-8.2.0.v20160908.jar to class loader\n",
      "21/04/03 03:32:53 INFO Executor: Fetching spark://172.23.191.244:35459/jars/mainargs_2.12-0.1.4-sources.jar with timestamp 1617387609766\n",
      "21/04/03 03:32:53 INFO Utils: Fetching spark://172.23.191.244:35459/jars/mainargs_2.12-0.1.4-sources.jar to /tmp/spark-3b36f2b5-0161-4093-a4b1-a5a84b889935/userFiles-cf106a32-aa21-4539-9d94-7dd159511573/fetchFileTemp6926739892588649463.tmp\n",
      "21/04/03 03:32:53 INFO Executor: Adding file:/tmp/spark-3b36f2b5-0161-4093-a4b1-a5a84b889935/userFiles-cf106a32-aa21-4539-9d94-7dd159511573/mainargs_2.12-0.1.4-sources.jar to class loader\n",
      "21/04/03 03:32:53 INFO Executor: Fetching spark://172.23.191.244:35459/jars/scala-reflect-2.12.12-sources.jar with timestamp 1617387609789\n",
      "21/04/03 03:32:53 INFO Utils: Fetching spark://172.23.191.244:35459/jars/scala-reflect-2.12.12-sources.jar to /tmp/spark-3b36f2b5-0161-4093-a4b1-a5a84b889935/userFiles-cf106a32-aa21-4539-9d94-7dd159511573/fetchFileTemp14832195104093149087.tmp\n",
      "21/04/03 03:32:53 INFO Executor: Adding file:/tmp/spark-3b36f2b5-0161-4093-a4b1-a5a84b889935/userFiles-cf106a32-aa21-4539-9d94-7dd159511573/scala-reflect-2.12.12-sources.jar to class loader\n",
      "21/04/03 03:32:53 INFO Executor: Fetching spark://172.23.191.244:35459/jars/ammonite-compiler-interface_2.12-2.3.8-36-1cce53f3-sources.jar with timestamp 1617387609750\n",
      "21/04/03 03:32:53 INFO Utils: Fetching spark://172.23.191.244:35459/jars/ammonite-compiler-interface_2.12-2.3.8-36-1cce53f3-sources.jar to /tmp/spark-3b36f2b5-0161-4093-a4b1-a5a84b889935/userFiles-cf106a32-aa21-4539-9d94-7dd159511573/fetchFileTemp16010440248067953471.tmp\n",
      "21/04/03 03:32:53 INFO Executor: Adding file:/tmp/spark-3b36f2b5-0161-4093-a4b1-a5a84b889935/userFiles-cf106a32-aa21-4539-9d94-7dd159511573/ammonite-compiler-interface_2.12-2.3.8-36-1cce53f3-sources.jar to class loader\n",
      "21/04/03 03:32:53 INFO Executor: Fetching spark://172.23.191.244:35459/jars/shapeless_2.12-2.3.3.jar with timestamp 1617387609805\n",
      "21/04/03 03:32:53 INFO Utils: Fetching spark://172.23.191.244:35459/jars/shapeless_2.12-2.3.3.jar to /tmp/spark-3b36f2b5-0161-4093-a4b1-a5a84b889935/userFiles-cf106a32-aa21-4539-9d94-7dd159511573/fetchFileTemp3326963897230378529.tmp\n",
      "21/04/03 03:32:53 INFO Executor: Adding file:/tmp/spark-3b36f2b5-0161-4093-a4b1-a5a84b889935/userFiles-cf106a32-aa21-4539-9d94-7dd159511573/shapeless_2.12-2.3.3.jar to class loader\n",
      "21/04/03 03:32:53 INFO Executor: Fetching spark://172.23.191.244:35459/jars/scala-kernel-api_2.12.12-0.11.1-sources.jar with timestamp 1617387609799\n",
      "21/04/03 03:32:53 INFO Utils: Fetching spark://172.23.191.244:35459/jars/scala-kernel-api_2.12.12-0.11.1-sources.jar to /tmp/spark-3b36f2b5-0161-4093-a4b1-a5a84b889935/userFiles-cf106a32-aa21-4539-9d94-7dd159511573/fetchFileTemp13760902941070049532.tmp\n",
      "21/04/03 03:32:53 INFO Executor: Adding file:/tmp/spark-3b36f2b5-0161-4093-a4b1-a5a84b889935/userFiles-cf106a32-aa21-4539-9d94-7dd159511573/scala-kernel-api_2.12.12-0.11.1-sources.jar to class loader\n",
      "21/04/03 03:32:53 INFO Executor: Fetching spark://172.23.191.244:35459/jars/pprint_2.12-0.6.0.jar with timestamp 1617387609769\n",
      "21/04/03 03:32:53 INFO Utils: Fetching spark://172.23.191.244:35459/jars/pprint_2.12-0.6.0.jar to /tmp/spark-3b36f2b5-0161-4093-a4b1-a5a84b889935/userFiles-cf106a32-aa21-4539-9d94-7dd159511573/fetchFileTemp9998863476126330687.tmp\n",
      "21/04/03 03:32:53 INFO Executor: Adding file:/tmp/spark-3b36f2b5-0161-4093-a4b1-a5a84b889935/userFiles-cf106a32-aa21-4539-9d94-7dd159511573/pprint_2.12-0.6.0.jar to class loader\n",
      "21/04/03 03:32:53 INFO Executor: Fetching spark://172.23.191.244:35459/jars/argonaut_2.12-6.2.2.jar with timestamp 1617387609804\n",
      "21/04/03 03:32:53 INFO Utils: Fetching spark://172.23.191.244:35459/jars/argonaut_2.12-6.2.2.jar to /tmp/spark-3b36f2b5-0161-4093-a4b1-a5a84b889935/userFiles-cf106a32-aa21-4539-9d94-7dd159511573/fetchFileTemp6228208948654336041.tmp\n",
      "21/04/03 03:32:53 INFO Executor: Adding file:/tmp/spark-3b36f2b5-0161-4093-a4b1-a5a84b889935/userFiles-cf106a32-aa21-4539-9d94-7dd159511573/argonaut_2.12-6.2.2.jar to class loader\n",
      "21/04/03 03:32:53 INFO Executor: Fetching spark://172.23.191.244:35459/jars/javassist-3.21.0-GA-sources.jar with timestamp 1617387609783\n",
      "21/04/03 03:32:53 INFO Utils: Fetching spark://172.23.191.244:35459/jars/javassist-3.21.0-GA-sources.jar to /tmp/spark-3b36f2b5-0161-4093-a4b1-a5a84b889935/userFiles-cf106a32-aa21-4539-9d94-7dd159511573/fetchFileTemp10506983753195988257.tmp\n",
      "21/04/03 03:32:53 INFO Executor: Adding file:/tmp/spark-3b36f2b5-0161-4093-a4b1-a5a84b889935/userFiles-cf106a32-aa21-4539-9d94-7dd159511573/javassist-3.21.0-GA-sources.jar to class loader\n",
      "21/04/03 03:32:53 INFO Executor: Fetching spark://172.23.191.244:35459/jars/ammonite-repl-api_2.12.12-2.3.8-36-1cce53f3-sources.jar with timestamp 1617387609754\n",
      "21/04/03 03:32:53 INFO Utils: Fetching spark://172.23.191.244:35459/jars/ammonite-repl-api_2.12.12-2.3.8-36-1cce53f3-sources.jar to /tmp/spark-3b36f2b5-0161-4093-a4b1-a5a84b889935/userFiles-cf106a32-aa21-4539-9d94-7dd159511573/fetchFileTemp2385103844254457623.tmp\n",
      "21/04/03 03:32:53 INFO Executor: Adding file:/tmp/spark-3b36f2b5-0161-4093-a4b1-a5a84b889935/userFiles-cf106a32-aa21-4539-9d94-7dd159511573/ammonite-repl-api_2.12.12-2.3.8-36-1cce53f3-sources.jar to class loader\n",
      "21/04/03 03:32:53 INFO Executor: Fetching spark://172.23.191.244:35459/jars/ammonite-util_2.12-2.3.8-36-1cce53f3.jar with timestamp 1617387609757\n",
      "21/04/03 03:32:53 INFO Utils: Fetching spark://172.23.191.244:35459/jars/ammonite-util_2.12-2.3.8-36-1cce53f3.jar to /tmp/spark-3b36f2b5-0161-4093-a4b1-a5a84b889935/userFiles-cf106a32-aa21-4539-9d94-7dd159511573/fetchFileTemp16381293775770114775.tmp\n",
      "21/04/03 03:32:53 INFO Executor: Adding file:/tmp/spark-3b36f2b5-0161-4093-a4b1-a5a84b889935/userFiles-cf106a32-aa21-4539-9d94-7dd159511573/ammonite-util_2.12-2.3.8-36-1cce53f3.jar to class loader\n",
      "21/04/03 03:32:53 INFO Executor: Fetching spark://172.23.191.244:35459/jars/jetty-io-8.2.0.v20160908.jar with timestamp 1617387609815\n",
      "21/04/03 03:32:53 INFO Utils: Fetching spark://172.23.191.244:35459/jars/jetty-io-8.2.0.v20160908.jar to /tmp/spark-3b36f2b5-0161-4093-a4b1-a5a84b889935/userFiles-cf106a32-aa21-4539-9d94-7dd159511573/fetchFileTemp12908998135381262785.tmp\n",
      "21/04/03 03:32:53 INFO Executor: Adding file:/tmp/spark-3b36f2b5-0161-4093-a4b1-a5a84b889935/userFiles-cf106a32-aa21-4539-9d94-7dd159511573/jetty-io-8.2.0.v20160908.jar to class loader\n",
      "21/04/03 03:32:53 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1060 bytes result sent to driver\n",
      "21/04/03 03:32:53 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 2613 ms on localhost (executor driver) (1/1)\n",
      "21/04/03 03:32:53 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool \n",
      "21/04/03 03:32:53 INFO DAGScheduler: ResultStage 0 (show at cmd30.sc:2) finished in 3.129 s\n",
      "21/04/03 03:32:53 INFO DAGScheduler: Job 0 finished: show at cmd30.sc:2, took 3.241336 s\n",
      "21/04/03 03:32:53 INFO SparkContext: Starting job: show at cmd30.sc:2\n",
      "21/04/03 03:32:53 INFO DAGScheduler: Got job 1 (show at cmd30.sc:2) with 4 output partitions\n",
      "21/04/03 03:32:53 INFO DAGScheduler: Final stage: ResultStage 1 (show at cmd30.sc:2)\n",
      "21/04/03 03:32:53 INFO DAGScheduler: Parents of final stage: List()\n",
      "21/04/03 03:32:53 INFO DAGScheduler: Missing parents: List()\n",
      "21/04/03 03:32:53 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[10] at show at cmd30.sc:2), which has no missing parents\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "  <span style=\"float: left;\">show at cmd30.sc:2</span>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"progress\">\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: blue; width: 100%; word-wrap: normal; white-space: nowrap; text-align: center; color: white\" aria-valuenow=\"100\" aria-valuemin=\"0\" aria-valuemax=\"100\">\n",
       "    4 / 4\n",
       "  </div>\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: red; width: 0%\" aria-valuenow=\"0\" aria-valuemin=\"0\" aria-valuemax=\"100\"></div>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "  <span style=\"float: left;\">show at cmd30.sc:2</span>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"progress\">\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: blue; width: 100%; word-wrap: normal; white-space: nowrap; text-align: center; color: white\" aria-valuenow=\"100\" aria-valuemin=\"0\" aria-valuemax=\"100\">\n",
       "    4 / 4\n",
       "  </div>\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: red; width: 0%\" aria-valuenow=\"0\" aria-valuemin=\"0\" aria-valuemax=\"100\"></div>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "  <span style=\"float: left;\">show at cmd30.sc:2</span>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"progress\">\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: blue; width: 100%; word-wrap: normal; white-space: nowrap; text-align: center; color: white\" aria-valuenow=\"100\" aria-valuemin=\"0\" aria-valuemax=\"100\">\n",
       "    4 / 4\n",
       "  </div>\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: red; width: 0%\" aria-valuenow=\"0\" aria-valuemin=\"0\" aria-valuemax=\"100\"></div>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "  <span style=\"float: left;\">show at cmd30.sc:2</span>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"progress\">\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: blue; width: 100%; word-wrap: normal; white-space: nowrap; text-align: center; color: white\" aria-valuenow=\"100\" aria-valuemin=\"0\" aria-valuemax=\"100\">\n",
       "    4 / 4\n",
       "  </div>\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: red; width: 0%\" aria-valuenow=\"0\" aria-valuemin=\"0\" aria-valuemax=\"100\"></div>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/04/03 03:32:53 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 21.6 KB, free 1719.6 MB)\n",
      "21/04/03 03:32:53 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.8 KB, free 1719.5 MB)\n",
      "21/04/03 03:32:53 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.23.191.244:37033 (size: 6.8 KB, free: 1719.6 MB)\n",
      "21/04/03 03:32:53 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1161\n",
      "21/04/03 03:32:53 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 1 (MapPartitionsRDD[10] at show at cmd30.sc:2) (first 15 tasks are for partitions Vector(1, 2, 3, 4))\n",
      "21/04/03 03:32:53 INFO TaskSchedulerImpl: Adding task set 1.0 with 4 tasks\n",
      "21/04/03 03:32:53 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 1, PROCESS_LOCAL, 7315 bytes)\n",
      "21/04/03 03:32:53 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 2, localhost, executor driver, partition 2, PROCESS_LOCAL, 7315 bytes)\n",
      "21/04/03 03:32:53 INFO TaskSetManager: Starting task 2.0 in stage 1.0 (TID 3, localhost, executor driver, partition 3, PROCESS_LOCAL, 7918 bytes)\n",
      "21/04/03 03:32:53 INFO TaskSetManager: Starting task 3.0 in stage 1.0 (TID 4, localhost, executor driver, partition 4, PROCESS_LOCAL, 7315 bytes)\n",
      "21/04/03 03:32:53 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)\n",
      "21/04/03 03:32:53 INFO Executor: Running task 2.0 in stage 1.0 (TID 3)\n",
      "21/04/03 03:32:53 INFO Executor: Running task 3.0 in stage 1.0 (TID 4)\n",
      "21/04/03 03:32:53 INFO Executor: Running task 1.0 in stage 1.0 (TID 2)\n",
      "21/04/03 03:32:53 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1103 bytes result sent to driver\n",
      "21/04/03 03:32:53 INFO Executor: Finished task 1.0 in stage 1.0 (TID 2). 1060 bytes result sent to driver\n",
      "21/04/03 03:32:53 INFO Executor: Finished task 3.0 in stage 1.0 (TID 4). 1060 bytes result sent to driver\n",
      "21/04/03 03:32:53 INFO Executor: Finished task 2.0 in stage 1.0 (TID 3). 1126 bytes result sent to driver\n",
      "21/04/03 03:32:53 INFO TaskSetManager: Finished task 2.0 in stage 1.0 (TID 3) in 79 ms on localhost (executor driver) (1/4)\n",
      "21/04/03 03:32:53 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 84 ms on localhost (executor driver) (2/4)\n",
      "21/04/03 03:32:53 INFO TaskSetManager: Finished task 3.0 in stage 1.0 (TID 4) in 69 ms on localhost (executor driver) (3/4)\n",
      "21/04/03 03:32:53 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 2) in 86 ms on localhost (executor driver) (4/4)\n",
      "21/04/03 03:32:53 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool \n",
      "21/04/03 03:32:53 INFO DAGScheduler: ResultStage 1 (show at cmd30.sc:2) finished in 0.118 s\n",
      "21/04/03 03:32:53 INFO DAGScheduler: Job 1 finished: show at cmd30.sc:2, took 0.127259 s\n",
      "21/04/03 03:32:53 INFO SparkContext: Starting job: show at cmd30.sc:2\n",
      "21/04/03 03:32:54 INFO DAGScheduler: Got job 2 (show at cmd30.sc:2) with 3 output partitions\n",
      "21/04/03 03:32:54 INFO DAGScheduler: Final stage: ResultStage 2 (show at cmd30.sc:2)\n",
      "21/04/03 03:32:54 INFO DAGScheduler: Parents of final stage: List()\n",
      "21/04/03 03:32:54 INFO DAGScheduler: Missing parents: List()\n",
      "21/04/03 03:32:54 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[10] at show at cmd30.sc:2), which has no missing parents\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "  <span style=\"float: left;\">show at cmd30.sc:2</span>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"progress\">\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: blue; width: 100%; word-wrap: normal; white-space: nowrap; text-align: center; color: white\" aria-valuenow=\"100\" aria-valuemin=\"0\" aria-valuemax=\"100\">\n",
       "    3 / 3\n",
       "  </div>\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: red; width: 0%\" aria-valuenow=\"0\" aria-valuemin=\"0\" aria-valuemax=\"100\"></div>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "  <span style=\"float: left;\">show at cmd30.sc:2</span>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"progress\">\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: blue; width: 100%; word-wrap: normal; white-space: nowrap; text-align: center; color: white\" aria-valuenow=\"100\" aria-valuemin=\"0\" aria-valuemax=\"100\">\n",
       "    3 / 3\n",
       "  </div>\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: red; width: 0%\" aria-valuenow=\"0\" aria-valuemin=\"0\" aria-valuemax=\"100\"></div>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "  <span style=\"float: left;\">show at cmd30.sc:2</span>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"progress\">\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: blue; width: 100%; word-wrap: normal; white-space: nowrap; text-align: center; color: white\" aria-valuenow=\"100\" aria-valuemin=\"0\" aria-valuemax=\"100\">\n",
       "    3 / 3\n",
       "  </div>\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: red; width: 0%\" aria-valuenow=\"0\" aria-valuemin=\"0\" aria-valuemax=\"100\"></div>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "  <span style=\"float: left;\">show at cmd30.sc:2</span>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"progress\">\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: blue; width: 100%; word-wrap: normal; white-space: nowrap; text-align: center; color: white\" aria-valuenow=\"100\" aria-valuemin=\"0\" aria-valuemax=\"100\">\n",
       "    3 / 3\n",
       "  </div>\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: red; width: 0%\" aria-valuenow=\"0\" aria-valuemin=\"0\" aria-valuemax=\"100\"></div>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/04/03 03:32:54 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 21.6 KB, free 1719.5 MB)\n",
      "21/04/03 03:32:54 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 6.8 KB, free 1719.5 MB)\n",
      "21/04/03 03:32:54 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 172.23.191.244:37033 (size: 6.8 KB, free: 1719.6 MB)\n",
      "21/04/03 03:32:54 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1161\n",
      "21/04/03 03:32:54 INFO DAGScheduler: Submitting 3 missing tasks from ResultStage 2 (MapPartitionsRDD[10] at show at cmd30.sc:2) (first 15 tasks are for partitions Vector(5, 6, 7))\n",
      "21/04/03 03:32:54 INFO TaskSchedulerImpl: Adding task set 2.0 with 3 tasks\n",
      "21/04/03 03:32:54 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 5, localhost, executor driver, partition 5, PROCESS_LOCAL, 7315 bytes)\n",
      "21/04/03 03:32:54 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 6, localhost, executor driver, partition 6, PROCESS_LOCAL, 7315 bytes)\n",
      "21/04/03 03:32:54 INFO TaskSetManager: Starting task 2.0 in stage 2.0 (TID 7, localhost, executor driver, partition 7, PROCESS_LOCAL, 7918 bytes)\n",
      "21/04/03 03:32:54 INFO Executor: Running task 0.0 in stage 2.0 (TID 5)\n",
      "21/04/03 03:32:54 INFO Executor: Running task 1.0 in stage 2.0 (TID 6)\n",
      "21/04/03 03:32:54 INFO Executor: Running task 2.0 in stage 2.0 (TID 7)\n",
      "21/04/03 03:32:54 INFO Executor: Finished task 2.0 in stage 2.0 (TID 7). 1172 bytes result sent to driver\n",
      "21/04/03 03:32:54 INFO Executor: Finished task 1.0 in stage 2.0 (TID 6). 1060 bytes result sent to driver\n",
      "21/04/03 03:32:54 INFO TaskSetManager: Finished task 2.0 in stage 2.0 (TID 7) in 33 ms on localhost (executor driver) (1/3)\n",
      "21/04/03 03:32:54 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 6) in 38 ms on localhost (executor driver) (2/3)\n",
      "21/04/03 03:32:54 INFO Executor: Finished task 0.0 in stage 2.0 (TID 5). 1060 bytes result sent to driver\n",
      "21/04/03 03:32:54 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 5) in 48 ms on localhost (executor driver) (3/3)\n",
      "21/04/03 03:32:54 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool \n",
      "21/04/03 03:32:54 INFO DAGScheduler: ResultStage 2 (show at cmd30.sc:2) finished in 0.108 s\n",
      "21/04/03 03:32:54 INFO DAGScheduler: Job 2 finished: show at cmd30.sc:2, took 0.119272 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+---------------------+\n",
      "|language|users_count|extremely_long_string|\n",
      "+--------+-----------+---------------------+\n",
      "|[java]  |[20000]    |[short text]         |\n",
      "|[python]|[1000000]  |[medium text]        |\n",
      "+--------+-----------+---------------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mdf\u001b[39m: \u001b[32mDataFrame\u001b[39m = [language: struct<value: string>, users_count: struct<value: string> ... 1 more field]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val df = spark.createDataFrame(rdd).toDF(columns:_*)\n",
    "df.show(false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f60bbfc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36malmond.display._\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36malmond.input._\u001b[39m"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import almond.display._\n",
    "import almond.input._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7d91d6c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " hello world\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mres17\u001b[39m: \u001b[32mString\u001b[39m = \u001b[32m\"hello world\"\u001b[39m"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "Input().withPrompt(\"\").request()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "653a9288",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36malmond.api._\u001b[39m"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import almond.api._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c9224d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import java.util.UUID\n",
    "import scala.util.Random\n",
    "\n",
    "implicit class ProgressIndicatable[T](content:Iterable[T]) {\n",
    "    val id = UUID.randomUUID().toString\n",
    "    \n",
    "    kernel.publish.html(\"start\",id)\n",
    "\n",
    "    val update = (i:Int,_:Unit) => {\n",
    "        kernel.publish.updateHtml((1 to i).map(_=>\"||\").mkString,id)\n",
    "    }\n",
    "    def zipWithProgressBar:Iterable[(T,Unit=>Unit)]={\n",
    "        content.zipWithIndex.map{ case (e,i) =>\n",
    "          (e,update.curried(i))\n",
    "        }\n",
    "    }\n",
    "\n",
    "}\n",
    "(1 to 100).zipWithProgressBar.map{case (e,callback)=>\n",
    "  Thread.sleep(100)\n",
    "  callback()\n",
    "  e\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7d6a29f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://repo1.maven.org/maven2/org/plotly-scala/plotly-almond_2.12/0.7.0/plotly-almond_2.12-0.7.0.pom\n",
      "Downloaded https://repo1.maven.org/maven2/org/plotly-scala/plotly-almond_2.12/0.7.0/plotly-almond_2.12-0.7.0.pom\n",
      "Downloading https://repo1.maven.org/maven2/org/plotly-scala/plotly-render_2.12/0.7.0/plotly-render_2.12-0.7.0.pom\n",
      "Downloading https://repo1.maven.org/maven2/org/plotly-scala/plotly-core_2.12/0.7.0/plotly-core_2.12-0.7.0.pom\n",
      "Downloaded https://repo1.maven.org/maven2/org/plotly-scala/plotly-render_2.12/0.7.0/plotly-render_2.12-0.7.0.pom\n",
      "Downloaded https://repo1.maven.org/maven2/org/plotly-scala/plotly-core_2.12/0.7.0/plotly-core_2.12-0.7.0.pom\n",
      "Downloading https://repo1.maven.org/maven2/org/plotly-scala/plotly-render_2.12/0.7.0/plotly-render_2.12-0.7.0-sources.jar\n",
      "Downloading https://repo1.maven.org/maven2/org/plotly-scala/plotly-almond_2.12/0.7.0/plotly-almond_2.12-0.7.0-sources.jar\n",
      "Downloading https://repo1.maven.org/maven2/org/plotly-scala/plotly-core_2.12/0.7.0/plotly-core_2.12-0.7.0.jar\n",
      "Downloading https://repo1.maven.org/maven2/org/plotly-scala/plotly-render_2.12/0.7.0/plotly-render_2.12-0.7.0.jar\n",
      "Downloading https://repo1.maven.org/maven2/org/plotly-scala/plotly-almond_2.12/0.7.0/plotly-almond_2.12-0.7.0.jar\n",
      "Downloading https://repo1.maven.org/maven2/org/plotly-scala/plotly-core_2.12/0.7.0/plotly-core_2.12-0.7.0-sources.jar\n",
      "Downloaded https://repo1.maven.org/maven2/org/plotly-scala/plotly-render_2.12/0.7.0/plotly-render_2.12-0.7.0-sources.jar\n",
      "Downloaded https://repo1.maven.org/maven2/org/plotly-scala/plotly-core_2.12/0.7.0/plotly-core_2.12-0.7.0-sources.jar\n",
      "Downloaded https://repo1.maven.org/maven2/org/plotly-scala/plotly-almond_2.12/0.7.0/plotly-almond_2.12-0.7.0-sources.jar\n",
      "Downloaded https://repo1.maven.org/maven2/org/plotly-scala/plotly-almond_2.12/0.7.0/plotly-almond_2.12-0.7.0.jar\n",
      "Downloaded https://repo1.maven.org/maven2/org/plotly-scala/plotly-core_2.12/0.7.0/plotly-core_2.12-0.7.0.jar\n",
      "Still downloading:\n",
      "https://repo1.maven.org/maven2/org/plotly-scala/plotly-render_2.12/0.7.0/plotly-render_2.12-0.7.0.jar (18.72 %, 945898 / 5052851)\n",
      "\n",
      "Still downloading:\n",
      "https://repo1.maven.org/maven2/org/plotly-scala/plotly-render_2.12/0.7.0/plotly-render_2.12-0.7.0.jar (32.01 %, 1617642 / 5052851)\n",
      "\n",
      "Still downloading:\n",
      "https://repo1.maven.org/maven2/org/plotly-scala/plotly-render_2.12/0.7.0/plotly-render_2.12-0.7.0.jar (44.66 %, 2256618 / 5052851)\n",
      "\n",
      "Still downloading:\n",
      "https://repo1.maven.org/maven2/org/plotly-scala/plotly-render_2.12/0.7.0/plotly-render_2.12-0.7.0.jar (57.40 %, 2900330 / 5052851)\n",
      "\n",
      "Still downloading:\n",
      "https://repo1.maven.org/maven2/org/plotly-scala/plotly-render_2.12/0.7.0/plotly-render_2.12-0.7.0.jar (70.87 %, 3580778 / 5052851)\n",
      "\n",
      "Still downloading:\n",
      "https://repo1.maven.org/maven2/org/plotly-scala/plotly-render_2.12/0.7.0/plotly-render_2.12-0.7.0.jar (81.24 %, 4105002 / 5052851)\n",
      "\n",
      "Still downloading:\n",
      "https://repo1.maven.org/maven2/org/plotly-scala/plotly-render_2.12/0.7.0/plotly-render_2.12-0.7.0.jar (91.54 %, 4625450 / 5052851)\n",
      "\n",
      "Downloaded https://repo1.maven.org/maven2/org/plotly-scala/plotly-render_2.12/0.7.0/plotly-render_2.12-0.7.0.jar\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31mjava.lang.NoSuchMethodError: 'argonaut.JsonIdentity argonaut.Argonaut$.ToJsonIdentity(java.lang.Object)'\u001b[39m\n  plotly.Plotly$.$anonfun$jsSnippet$2(\u001b[32mPlotly.scala\u001b[39m:\u001b[32m39\u001b[39m)\n  scala.collection.TraversableLike$WithFilter.$anonfun$foreach$1(\u001b[32mTraversableLike.scala\u001b[39m:\u001b[32m924\u001b[39m)\n  scala.collection.immutable.List.foreach(\u001b[32mList.scala\u001b[39m:\u001b[32m431\u001b[39m)\n  scala.collection.TraversableLike$WithFilter.foreach(\u001b[32mTraversableLike.scala\u001b[39m:\u001b[32m923\u001b[39m)\n  plotly.Plotly$.jsSnippet(\u001b[32mPlotly.scala\u001b[39m:\u001b[32m37\u001b[39m)\n  plotly.Almond$.plotJs(\u001b[32mAlmond.scala\u001b[39m:\u001b[32m74\u001b[39m)\n  plotly.Almond$.plot(\u001b[32mAlmond.scala\u001b[39m:\u001b[32m117\u001b[39m)\n  plotly.Almond$DataOps$.plot$extension1(\u001b[32mAlmond.scala\u001b[39m:\u001b[32m191\u001b[39m)\n  plotly.Almond$DataOps$.plot$extension0(\u001b[32mAlmond.scala\u001b[39m:\u001b[32m153\u001b[39m)\n  ammonite.$sess.cmd63$Helper.<init>(\u001b[32mcmd63.sc\u001b[39m:\u001b[32m10\u001b[39m)\n  ammonite.$sess.cmd63$.<init>(\u001b[32mcmd63.sc\u001b[39m:\u001b[32m7\u001b[39m)\n  ammonite.$sess.cmd63$.<clinit>(\u001b[32mcmd63.sc\u001b[39m:\u001b[32m-1\u001b[39m)"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5f6bfacd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mres62\u001b[39m: \u001b[32mString\u001b[39m = \u001b[32m\"0.11.1\"\u001b[39m"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2edb9490",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala (2.12)",
   "language": "scala",
   "name": "scala212"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".sc",
   "mimetype": "text/x-scala",
   "name": "scala",
   "nbconvert_exporter": "script",
   "version": "2.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
