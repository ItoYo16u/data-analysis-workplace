import $ivy.`org.apache.spark::spark-sql:2.4.0` 
import $ivy.`sh.almond::almond-spark:0.3.0`


import org.apache.spark.sql._
case class Data(value: String)
val columns = Seq("language","users_count","extremely_long_string")
val data = Seq(
    (Data("java"),Data("20000"),Data("short text")),
    (Data("python"),Data("1000000"),Data("medium text"))
)



val spark = NotebookSparkSession.builder().master("local[*]").getOrCreate()


val rdd= spark.sparkContext.parallelize(data)


import spark.implicits._



val df = spark.createDataFrame(rdd).toDF(columns:_*)
df.show(false)



